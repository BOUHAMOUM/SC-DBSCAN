18/09/25 23:10:30 INFO SparkContext: Running Spark version 2.2.1
18/09/25 23:10:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/25 23:10:30 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/25 23:10:30 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/25 23:10:30 INFO SecurityManager: Changing view acls to: redouane
18/09/25 23:10:30 INFO SecurityManager: Changing modify acls to: redouane
18/09/25 23:10:30 INFO SecurityManager: Changing view acls groups to: 
18/09/25 23:10:30 INFO SecurityManager: Changing modify acls groups to: 
18/09/25 23:10:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/25 23:10:31 INFO Utils: Successfully started service 'sparkDriver' on port 37324.
18/09/25 23:10:31 INFO SparkEnv: Registering MapOutputTracker
18/09/25 23:10:31 INFO SparkEnv: Registering BlockManagerMaster
18/09/25 23:10:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/25 23:10:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-9bf8add2-839c-4097-99cf-2a7092b2add3
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-cb9e1498-feb2-4f35-8602-41c2882b3b7a
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-5d8a1c34-a845-4bf4-a448-5d1a962cad75
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-a6f3147d-8ed6-4a04-a220-5cdfda454868
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-54777984-b8c9-4030-9d76-3ded7a1e571f
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-9e2237e8-705b-4ed8-904c-81e012426736
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-bc94574e-2fde-4dcc-b4bb-9848558396ba
18/09/25 23:10:31 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-3eaa354a-21f7-45a3-9af0-54056beccbc1
18/09/25 23:10:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/25 23:10:31 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/25 23:10:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/25 23:10:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/25 23:10:31 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:37324/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537909831807
18/09/25 23:10:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/25 23:10:31 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 26 ms (0 ms spent in bootstraps)
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180925231032-0244
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/0 on worker-20180719103621-192.168.33.15-45392 (192.168.33.15:45392) with 24 cores
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/0 on hostPort 192.168.33.15:45392 with 24 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/1 on worker-20180719103620-192.168.33.10-42471 (192.168.33.10:42471) with 24 cores
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/1 on hostPort 192.168.33.10:42471 with 24 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/2 on worker-20180719103621-192.168.33.14-35807 (192.168.33.14:35807) with 8 cores
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/2 on hostPort 192.168.33.14:35807 with 8 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/3 on worker-20180719103621-192.168.33.13-45593 (192.168.33.13:45593) with 8 cores
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/3 on hostPort 192.168.33.13:45593 with 8 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/4 on worker-20180719103621-192.168.33.11-40443 (192.168.33.11:40443) with 8 cores
18/09/25 23:10:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43108.
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/4 on hostPort 192.168.33.11:40443 with 8 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180925231032-0244/5 on worker-20180719103621-192.168.33.12-44230 (192.168.33.12:44230) with 8 cores
18/09/25 23:10:32 INFO NettyBlockTransferService: Server created on 192.168.33.10:43108
18/09/25 23:10:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20180925231032-0244/5 on hostPort 192.168.33.12:44230 with 8 cores, 30.0 GB RAM
18/09/25 23:10:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/25 23:10:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 43108, None)
18/09/25 23:10:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:43108 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 43108, None)
18/09/25 23:10:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 43108, None)
18/09/25 23:10:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 43108, None)
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/1 is now RUNNING
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/0 is now RUNNING
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/2 is now RUNNING
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/3 is now RUNNING
18/09/25 23:10:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/5 is now RUNNING
18/09/25 23:10:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180925231032-0244/4 is now RUNNING
18/09/25 23:10:33 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180925231032-0244
18/09/25 23:10:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/25 23:10:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/25 23:10:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/25 23:10:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:43108 (size: 27.9 KB, free: 366.3 MB)
18/09/25 23:10:33 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/25 23:10:34 INFO FileInputFormat: Total input files to process : 409
18/09/25 23:10:34 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/25 23:10:34 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/25 23:10:34 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/25 23:10:34 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/25 23:10:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/25 23:10:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/25 23:10:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/25 23:10:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/25 23:10:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/25 23:10:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:43108 (size: 2.5 KB, free: 366.3 MB)
18/09/25 23:10:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/25 23:10:34 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/25 23:10:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/25 23:10:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:44718) with ID 1
18/09/25 23:10:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.10, executor 1, partition 0, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.10, executor 1, partition 1, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.10, executor 1, partition 2, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.10, executor 1, partition 3, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.10, executor 1, partition 4, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.10, executor 1, partition 5, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.10, executor 1, partition 6, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.10, executor 1, partition 7, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.10, executor 1, partition 8, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.10, executor 1, partition 9, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.10, executor 1, partition 10, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.10, executor 1, partition 11, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.10, executor 1, partition 12, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.10, executor 1, partition 13, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.10, executor 1, partition 14, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.10, executor 1, partition 15, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.10, executor 1, partition 16, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.10, executor 1, partition 17, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.10, executor 1, partition 18, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.10, executor 1, partition 19, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.10, executor 1, partition 20, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.10, executor 1, partition 21, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.10, executor 1, partition 22, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.10, executor 1, partition 23, ANY, 4879 bytes)
18/09/25 23:10:34 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:40136 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 40136, None)
18/09/25 23:10:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:38488) with ID 0
18/09/25 23:10:34 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.15, executor 0, partition 24, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.15, executor 0, partition 25, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.15, executor 0, partition 26, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.15, executor 0, partition 27, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.15, executor 0, partition 28, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.15, executor 0, partition 29, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.15, executor 0, partition 30, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.15, executor 0, partition 33, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.15, executor 0, partition 35, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.15, executor 0, partition 39, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.15, executor 0, partition 41, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.15, executor 0, partition 45, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/25 23:10:34 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.15, executor 0, partition 47, ANY, 4879 bytes)
18/09/25 23:10:34 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:44939 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 44939, None)
18/09/25 23:10:35 INFO SparkContext: Invoking stop() from shutdown hook
18/09/25 23:10:35 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/25 23:10:36 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 1,735958 s
18/09/25 23:10:36 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) failed in 1,557 s due to Stage cancelled because SparkContext was shut down
18/09/25 23:10:36 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/25 23:10:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/25 23:10:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/25 23:10:36 INFO MemoryStore: MemoryStore cleared
18/09/25 23:10:36 INFO BlockManager: BlockManager stopped
18/09/25 23:10:36 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/25 23:10:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/25 23:10:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:38492; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
18/09/25 23:10:36 INFO SparkContext: Successfully stopped SparkContext
18/09/25 23:10:36 INFO ShutdownHookManager: Shutdown hook called
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-9ae32063-2e73-4754-b06b-dae0030cf65c
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-5c9a53ee-169a-4c59-ac61-bc53da5e69e2
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-82b96b6c-8b72-4214-ba50-d86afc390125
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-39179f53-d622-4bf9-9a0d-9425ba527a95
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-1666ad9b-f43c-4c95-8e51-9591a454f3ae
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-ea7de848-71b3-4bc3-862d-56cf6a7e2200
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-db2d4345-00f4-4f11-a356-8f656795afd7
18/09/25 23:10:36 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-c18e7339-2498-4a42-b34e-040c9e4b0a1c
18/09/26 09:39:23 INFO SparkContext: Running Spark version 2.2.1
18/09/26 09:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 09:39:24 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 09:39:24 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 09:39:24 INFO SecurityManager: Changing view acls to: redouane
18/09/26 09:39:24 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 09:39:24 INFO SecurityManager: Changing view acls groups to: 
18/09/26 09:39:24 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 09:39:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 09:39:24 INFO Utils: Successfully started service 'sparkDriver' on port 40114.
18/09/26 09:39:24 INFO SparkEnv: Registering MapOutputTracker
18/09/26 09:39:24 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 09:39:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 09:39:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-fca8806e-4bec-424a-b74d-3d10df776ccd
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-6d73f659-fcf9-426f-b1e5-9a9e5b879a1f
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-bfd8ac1d-9276-4c78-990f-fedd5c89810d
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-fa14dd06-906b-47d0-a8fa-203e530df62a
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-814acaee-7200-422f-9686-4fbf2f9dca09
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-a1a67fee-81d9-4efe-901b-ff6677b6af96
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-48a6ba12-0ac7-413c-84f8-d89fc2eaa2a4
18/09/26 09:39:24 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-869f9cfe-b183-4200-94d7-f6d3afeb5278
18/09/26 09:39:24 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 09:39:24 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 09:39:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 09:39:25 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 09:39:25 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:40114/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537947565230
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 09:39:25 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 29 ms (0 ms spent in bootstraps)
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926093925-0245
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/0 on worker-20180719103621-192.168.33.15-45392 (192.168.33.15:45392) with 24 cores
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/0 on hostPort 192.168.33.15:45392 with 24 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/1 on worker-20180719103620-192.168.33.10-42471 (192.168.33.10:42471) with 24 cores
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/1 on hostPort 192.168.33.10:42471 with 24 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/2 on worker-20180719103621-192.168.33.14-35807 (192.168.33.14:35807) with 8 cores
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/2 on hostPort 192.168.33.14:35807 with 8 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/3 on worker-20180719103621-192.168.33.13-45593 (192.168.33.13:45593) with 8 cores
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/3 on hostPort 192.168.33.13:45593 with 8 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/4 on worker-20180719103621-192.168.33.11-40443 (192.168.33.11:40443) with 8 cores
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/4 on hostPort 192.168.33.11:40443 with 8 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34494.
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926093925-0245/5 on worker-20180719103621-192.168.33.12-44230 (192.168.33.12:44230) with 8 cores
18/09/26 09:39:25 INFO NettyBlockTransferService: Server created on 192.168.33.10:34494
18/09/26 09:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926093925-0245/5 on hostPort 192.168.33.12:44230 with 8 cores, 30.0 GB RAM
18/09/26 09:39:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 09:39:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 34494, None)
18/09/26 09:39:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:34494 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 34494, None)
18/09/26 09:39:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 34494, None)
18/09/26 09:39:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 34494, None)
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/0 is now RUNNING
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/1 is now RUNNING
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/4 is now RUNNING
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/2 is now RUNNING
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/5 is now RUNNING
18/09/26 09:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926093925-0245/3 is now RUNNING
18/09/26 09:39:26 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926093925-0245
18/09/26 09:39:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 09:39:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 09:39:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 09:39:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:34494 (size: 27.9 KB, free: 366.3 MB)
18/09/26 09:39:27 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 09:39:27 INFO FileInputFormat: Total input files to process : 409
18/09/26 09:39:27 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/26 09:39:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:40984) with ID 0
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/26 09:39:27 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/26 09:39:27 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/26 09:39:27 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/26 09:39:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/26 09:39:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/26 09:39:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 09:39:27 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:44622 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 44622, None)
18/09/26 09:39:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/26 09:39:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 09:39:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:34494 (size: 2.5 KB, free: 366.3 MB)
18/09/26 09:39:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/26 09:39:27 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 09:39:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/26 09:39:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:55054) with ID 1
18/09/26 09:39:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.15, executor 0, partition 0, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.10, executor 1, partition 1, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.15, executor 0, partition 2, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.10, executor 1, partition 3, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.15, executor 0, partition 4, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.10, executor 1, partition 5, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.15, executor 0, partition 6, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.10, executor 1, partition 7, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.15, executor 0, partition 8, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.10, executor 1, partition 9, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.15, executor 0, partition 10, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.10, executor 1, partition 11, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.15, executor 0, partition 12, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.10, executor 1, partition 13, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.15, executor 0, partition 14, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.10, executor 1, partition 15, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.15, executor 0, partition 16, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.10, executor 1, partition 17, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.15, executor 0, partition 18, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.10, executor 1, partition 19, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.15, executor 0, partition 20, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.10, executor 1, partition 21, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.15, executor 0, partition 22, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.10, executor 1, partition 23, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.15, executor 0, partition 24, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.10, executor 1, partition 25, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.15, executor 0, partition 26, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.10, executor 1, partition 27, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.15, executor 0, partition 28, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.10, executor 1, partition 29, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.15, executor 0, partition 30, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.10, executor 1, partition 31, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.10, executor 1, partition 33, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.10, executor 1, partition 35, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.10, executor 1, partition 37, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.10, executor 1, partition 39, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.10, executor 1, partition 41, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.10, executor 1, partition 43, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.10, executor 1, partition 45, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.10, executor 1, partition 47, ANY, 4879 bytes)
18/09/26 09:39:28 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:42177 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 42177, None)
18/09/26 09:39:28 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40988; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, 192.168.33.15, executor 0, partition 48, ANY, 4879 bytes)
18/09/26 09:39:28 WARN TaskSetManager: Lost task 42.0 in stage 0.0 (TID 42, 192.168.33.15, executor 0): java.io.IOException: Aucun espace disponible sur le périphérique
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.util.Utils$.downloadFile(Utils.scala:526)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:656)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:708)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:700)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:700)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:311)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 09:39:28 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40990; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 42.1 in stage 0.0 (TID 49, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Lost task 44.0 in stage 0.0 (TID 44) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 1]
18/09/26 09:39:28 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40992; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:28 INFO TaskSetManager: Starting task 44.1 in stage 0.0 (TID 50, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:39:28 INFO TaskSetManager: Lost task 16.0 in stage 0.0 (TID 16) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 2]
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40996; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:28 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40994; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 16.1 in stage 0.0 (TID 51, 192.168.33.15, executor 0, partition 16, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 32.0 in stage 0.0 (TID 32) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 3]
18/09/26 09:39:29 INFO TaskSetManager: Starting task 32.1 in stage 0.0 (TID 52, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 4]
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:40998; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 53, 192.168.33.15, executor 0, partition 0, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 10.0 in stage 0.0 (TID 10) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 5]
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41000; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 10.1 in stage 0.0 (TID 54, 192.168.33.15, executor 0, partition 10, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 12.0 in stage 0.0 (TID 12) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 6]
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41002; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 12.1 in stage 0.0 (TID 55, 192.168.33.15, executor 0, partition 12, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 34.0 in stage 0.0 (TID 34) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 7]
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41004; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:34570) with ID 2
18/09/26 09:39:29 INFO TaskSetManager: Starting task 34.1 in stage 0.0 (TID 56, 192.168.33.14, executor 2, partition 34, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 57, 192.168.33.14, executor 2, partition 49, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 58, 192.168.33.14, executor 2, partition 50, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 59, 192.168.33.14, executor 2, partition 51, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 60, 192.168.33.14, executor 2, partition 52, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 61, 192.168.33.14, executor 2, partition 53, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 62, 192.168.33.14, executor 2, partition 54, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 63, 192.168.33.14, executor 2, partition 55, ANY, 4879 bytes)
18/09/26 09:39:29 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:46783 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.14, 46783, None)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 64, 192.168.33.15, executor 0, partition 56, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 2.0 in stage 0.0 (TID 2) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 8]
18/09/26 09:39:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:42177 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:39:29 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41006; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:29 INFO TaskSetManager: Starting task 2.1 in stage 0.0 (TID 65, 192.168.33.15, executor 0, partition 2, ANY, 4879 bytes)
18/09/26 09:39:29 INFO TaskSetManager: Lost task 6.0 in stage 0.0 (TID 6) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 9]
18/09/26 09:39:30 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41008; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:42177 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 6.1 in stage 0.0 (TID 66, 192.168.33.15, executor 0, partition 6, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Lost task 28.0 in stage 0.0 (TID 28) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 10]
18/09/26 09:39:30 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41010; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 28.1 in stage 0.0 (TID 67, 192.168.33.15, executor 0, partition 28, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Lost task 22.0 in stage 0.0 (TID 22) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 11]
18/09/26 09:39:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:49832) with ID 3
18/09/26 09:39:30 INFO TaskSetManager: Starting task 22.1 in stage 0.0 (TID 68, 192.168.33.13, executor 3, partition 22, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 69, 192.168.33.13, executor 3, partition 57, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 70, 192.168.33.13, executor 3, partition 58, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 71, 192.168.33.13, executor 3, partition 59, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 72, 192.168.33.13, executor 3, partition 60, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 73, 192.168.33.13, executor 3, partition 61, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 74, 192.168.33.13, executor 3, partition 62, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 75, 192.168.33.13, executor 3, partition 63, ANY, 4879 bytes)
18/09/26 09:39:30 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:32917 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.13, 32917, None)
18/09/26 09:39:30 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41012; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:30 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 76, 192.168.33.15, executor 0, partition 64, ANY, 4879 bytes)
18/09/26 09:39:30 INFO TaskSetManager: Lost task 8.0 in stage 0.0 (TID 8) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 12]
18/09/26 09:39:31 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41014; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 8.1 in stage 0.0 (TID 77, 192.168.33.15, executor 0, partition 8, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 13]
18/09/26 09:39:31 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41016; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 4.1 in stage 0.0 (TID 78, 192.168.33.15, executor 0, partition 4, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Lost task 46.0 in stage 0.0 (TID 46) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 14]
18/09/26 09:39:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:51944) with ID 5
18/09/26 09:39:31 INFO TaskSetManager: Starting task 46.1 in stage 0.0 (TID 79, 192.168.33.12, executor 5, partition 46, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 80, 192.168.33.12, executor 5, partition 65, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 81, 192.168.33.12, executor 5, partition 66, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 82, 192.168.33.12, executor 5, partition 67, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 83, 192.168.33.12, executor 5, partition 68, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 84, 192.168.33.12, executor 5, partition 69, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 85, 192.168.33.12, executor 5, partition 70, ANY, 4879 bytes)
18/09/26 09:39:31 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 86, 192.168.33.12, executor 5, partition 71, ANY, 4879 bytes)
18/09/26 09:39:31 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:38782 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.12, 38782, None)
18/09/26 09:39:32 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41018; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:32 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 87, 192.168.33.15, executor 0, partition 72, ANY, 4879 bytes)
18/09/26 09:39:32 INFO TaskSetManager: Lost task 14.0 in stage 0.0 (TID 14) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 15]
18/09/26 09:39:32 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41020; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:32 INFO TaskSetManager: Starting task 14.1 in stage 0.0 (TID 88, 192.168.33.15, executor 0, partition 14, ANY, 4879 bytes)
18/09/26 09:39:32 INFO TaskSetManager: Lost task 36.0 in stage 0.0 (TID 36) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 16]
18/09/26 09:39:32 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41022; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
18/09/26 09:39:32 INFO TaskSetManager: Starting task 36.1 in stage 0.0 (TID 89, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:39:32 INFO TaskSetManager: Lost task 30.0 in stage 0.0 (TID 30) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 17]
18/09/26 09:39:33 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41024; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:33 INFO TaskSetManager: Starting task 30.1 in stage 0.0 (TID 90, 192.168.33.15, executor 0, partition 30, ANY, 4879 bytes)
18/09/26 09:39:33 INFO TaskSetManager: Lost task 24.0 in stage 0.0 (TID 24) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 18]
18/09/26 09:39:33 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41026; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:33 INFO TaskSetManager: Starting task 24.1 in stage 0.0 (TID 91, 192.168.33.15, executor 0, partition 24, ANY, 4879 bytes)
18/09/26 09:39:33 INFO TaskSetManager: Lost task 18.0 in stage 0.0 (TID 18) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 19]
18/09/26 09:39:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:46783 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:39:34 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41028; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:34 INFO TaskSetManager: Starting task 18.1 in stage 0.0 (TID 92, 192.168.33.15, executor 0, partition 18, ANY, 4879 bytes)
18/09/26 09:39:34 INFO TaskSetManager: Lost task 20.0 in stage 0.0 (TID 20) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 20]
18/09/26 09:39:34 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41030; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:46783 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:39:34 INFO TaskSetManager: Starting task 20.1 in stage 0.0 (TID 93, 192.168.33.15, executor 0, partition 20, ANY, 4879 bytes)
18/09/26 09:39:34 INFO TaskSetManager: Lost task 38.0 in stage 0.0 (TID 38) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 21]
18/09/26 09:39:34 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41032; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:34 INFO TaskSetManager: Starting task 38.1 in stage 0.0 (TID 94, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:39:34 INFO TaskSetManager: Lost task 26.0 in stage 0.0 (TID 26) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 22]
18/09/26 09:39:34 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41034; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:34 INFO TaskSetManager: Starting task 26.1 in stage 0.0 (TID 95, 192.168.33.15, executor 0, partition 26, ANY, 4879 bytes)
18/09/26 09:39:34 INFO TaskSetManager: Lost task 40.0 in stage 0.0 (TID 40) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 23]
18/09/26 09:39:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.13:32917 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41036; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 40.1 in stage 0.0 (TID 96, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 38.1 in stage 0.0 (TID 94) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 24]
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41038; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 38.2 in stage 0.0 (TID 97, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 20.1 in stage 0.0 (TID 93) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 25]
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41040; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.13:32917 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 20.2 in stage 0.0 (TID 98, 192.168.33.15, executor 0, partition 20, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 18.1 in stage 0.0 (TID 92) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 26]
18/09/26 09:39:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:40848) with ID 4
18/09/26 09:39:35 INFO TaskSetManager: Starting task 18.2 in stage 0.0 (TID 99, 192.168.33.11, executor 4, partition 18, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 100, 192.168.33.11, executor 4, partition 73, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 101, 192.168.33.11, executor 4, partition 74, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 102, 192.168.33.11, executor 4, partition 75, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 103, 192.168.33.11, executor 4, partition 76, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 104, 192.168.33.11, executor 4, partition 77, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 105, 192.168.33.11, executor 4, partition 78, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 106, 192.168.33.11, executor 4, partition 79, ANY, 4879 bytes)
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41042; closing connection
java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 107, 192.168.33.15, executor 0, partition 80, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 24.1 in stage 0.0 (TID 91) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 27]
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41044; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:32839 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.11, 32839, None)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 30.1 in stage 0.0 (TID 90) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 28]
18/09/26 09:39:35 INFO TaskSetManager: Starting task 30.2 in stage 0.0 (TID 108, 192.168.33.15, executor 0, partition 30, ANY, 4879 bytes)
18/09/26 09:39:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:38782 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:39:35 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41046; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:35 INFO TaskSetManager: Starting task 24.2 in stage 0.0 (TID 109, 192.168.33.15, executor 0, partition 24, ANY, 4879 bytes)
18/09/26 09:39:35 INFO TaskSetManager: Lost task 36.1 in stage 0.0 (TID 89) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 29]
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41048; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:36 INFO TaskSetManager: Starting task 36.2 in stage 0.0 (TID 110, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:39:36 INFO TaskSetManager: Lost task 14.1 in stage 0.0 (TID 88) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 30]
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41050; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:38782 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:39:36 INFO TaskSetManager: Starting task 14.2 in stage 0.0 (TID 111, 192.168.33.15, executor 0, partition 14, ANY, 4879 bytes)
18/09/26 09:39:36 INFO TaskSetManager: Lost task 72.0 in stage 0.0 (TID 87) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 31]
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41052; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:36 INFO TaskSetManager: Starting task 72.1 in stage 0.0 (TID 112, 192.168.33.15, executor 0, partition 72, ANY, 4879 bytes)
18/09/26 09:39:36 INFO TaskSetManager: Lost task 4.1 in stage 0.0 (TID 78) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 32]
18/09/26 09:39:36 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 09:39:36 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41054; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:39:36 INFO TaskSetManager: Starting task 4.2 in stage 0.0 (TID 113, 192.168.33.15, executor 0, partition 4, ANY, 4879 bytes)
18/09/26 09:39:36 INFO TaskSetManager: Lost task 8.1 in stage 0.0 (TID 77) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 33]
18/09/26 09:39:36 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 8,897623 s
18/09/26 09:39:36 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) failed in 8,711 s due to Stage cancelled because SparkContext was shut down
18/09/26 09:39:36 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 09:39:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 09:39:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:41056; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
18/09/26 09:39:36 INFO MemoryStore: MemoryStore cleared
18/09/26 09:39:36 INFO BlockManager: BlockManager stopped
18/09/26 09:39:36 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 09:39:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 09:39:36 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.11:40852; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(...)(Unknown Source)
18/09/26 09:39:36 INFO SparkContext: Successfully stopped SparkContext
18/09/26 09:39:36 INFO ShutdownHookManager: Shutdown hook called
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-cb533f11-6dd4-43e7-998a-281672436c10
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-448aae34-216b-4513-b4f8-f5afe5443864
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-4cf481dc-76a3-4819-9921-30611e9a5066
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-1b6d5ce4-6264-46c3-adb0-039ef3327da2
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-0e023676-0d49-41c6-bb53-2772963bb5f5
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-7b5a5857-58a6-49e2-b144-8b501db90538
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-9130ae98-b745-40aa-9af3-361faf2908fa
18/09/26 09:39:36 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-04073c3b-26eb-4905-98a0-88cfec4a2523
18/09/26 09:40:54 INFO SparkContext: Running Spark version 2.2.1
18/09/26 09:40:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 09:40:55 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 09:40:55 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 09:40:55 INFO SecurityManager: Changing view acls to: redouane
18/09/26 09:40:55 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 09:40:55 INFO SecurityManager: Changing view acls groups to: 
18/09/26 09:40:55 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 09:40:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 09:40:55 INFO Utils: Successfully started service 'sparkDriver' on port 34169.
18/09/26 09:40:55 INFO SparkEnv: Registering MapOutputTracker
18/09/26 09:40:55 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 09:40:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 09:40:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-e29ce8ff-3642-4f5d-93d3-46136b73da18
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-44a3cca2-db5e-415e-9dfb-de2906a0483a
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-231c2813-34b1-4641-8b75-ed4509e04f7e
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-159f7457-e994-4a4d-a232-a0cf88de6c91
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-4689d7f4-f7ef-4d85-9ca9-b1deba76bd05
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-d8f0d672-e5d9-4248-a0f3-e6c7546e839f
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-407eb12a-0f44-41a1-ba39-6f7bb34badc8
18/09/26 09:40:55 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-0b74348a-10b9-4bae-be01-f46b067af6ba
18/09/26 09:40:55 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 09:40:55 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 09:40:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 09:40:56 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 09:40:56 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:34169/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537947656257
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 09:40:56 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 27 ms (0 ms spent in bootstraps)
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926094056-0246
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/0 on worker-20180719103621-192.168.33.15-45392 (192.168.33.15:45392) with 24 cores
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/0 on hostPort 192.168.33.15:45392 with 24 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/1 on worker-20180719103620-192.168.33.10-42471 (192.168.33.10:42471) with 24 cores
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/1 on hostPort 192.168.33.10:42471 with 24 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/2 on worker-20180719103621-192.168.33.14-35807 (192.168.33.14:35807) with 8 cores
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/2 on hostPort 192.168.33.14:35807 with 8 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/3 on worker-20180719103621-192.168.33.13-45593 (192.168.33.13:45593) with 8 cores
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/3 on hostPort 192.168.33.13:45593 with 8 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/4 on worker-20180719103621-192.168.33.11-40443 (192.168.33.11:40443) with 8 cores
18/09/26 09:40:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43849.
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/4 on hostPort 192.168.33.11:40443 with 8 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926094056-0246/5 on worker-20180719103621-192.168.33.12-44230 (192.168.33.12:44230) with 8 cores
18/09/26 09:40:56 INFO NettyBlockTransferService: Server created on 192.168.33.10:43849
18/09/26 09:40:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 09:40:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926094056-0246/5 on hostPort 192.168.33.12:44230 with 8 cores, 30.0 GB RAM
18/09/26 09:40:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 43849, None)
18/09/26 09:40:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:43849 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 43849, None)
18/09/26 09:40:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 43849, None)
18/09/26 09:40:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 43849, None)
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/0 is now RUNNING
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/1 is now RUNNING
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/4 is now RUNNING
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/2 is now RUNNING
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/3 is now RUNNING
18/09/26 09:40:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926094056-0246/5 is now RUNNING
18/09/26 09:40:57 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926094056-0246
18/09/26 09:40:57 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 09:40:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 09:40:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 09:40:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:43849 (size: 27.9 KB, free: 366.3 MB)
18/09/26 09:40:58 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 09:40:58 INFO FileInputFormat: Total input files to process : 409
18/09/26 09:40:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:36018) with ID 0
18/09/26 09:40:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:44714) with ID 4
18/09/26 09:40:58 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:37258 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.11, 37258, None)
18/09/26 09:40:58 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:36066 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 36066, None)
18/09/26 09:40:58 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/26 09:40:58 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/26 09:40:58 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/26 09:40:58 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/26 09:40:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/26 09:40:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/26 09:40:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 09:40:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:47368) with ID 2
18/09/26 09:40:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/26 09:40:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 09:40:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:43849 (size: 2.5 KB, free: 366.3 MB)
18/09/26 09:40:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/26 09:40:58 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:38459 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.14, 38459, None)
18/09/26 09:40:59 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 09:40:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:42740) with ID 5
18/09/26 09:40:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/26 09:40:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.11, executor 4, partition 0, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.14, executor 2, partition 1, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.12, executor 5, partition 2, ANY, 4879 bytes)
18/09/26 09:40:59 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:43381 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.12, 43381, None)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.15, executor 0, partition 3, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.11, executor 4, partition 4, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.14, executor 2, partition 5, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.12, executor 5, partition 6, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.11, executor 4, partition 8, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.14, executor 2, partition 9, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.12, executor 5, partition 10, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.15, executor 0, partition 11, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.11, executor 4, partition 12, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.14, executor 2, partition 13, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.12, executor 5, partition 14, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.15, executor 0, partition 15, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.11, executor 4, partition 16, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.14, executor 2, partition 17, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.12, executor 5, partition 18, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.11, executor 4, partition 20, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.14, executor 2, partition 21, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.12, executor 5, partition 22, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.15, executor 0, partition 23, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.11, executor 4, partition 24, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.14, executor 2, partition 25, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.12, executor 5, partition 26, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.15, executor 0, partition 27, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.11, executor 4, partition 28, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.14, executor 2, partition 29, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.12, executor 5, partition 30, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.15, executor 0, partition 33, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.15, executor 0, partition 35, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.15, executor 0, partition 39, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.15, executor 0, partition 41, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.15, executor 0, partition 45, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.15, executor 0, partition 47, ANY, 4879 bytes)
18/09/26 09:40:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:55750) with ID 3
18/09/26 09:40:59 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, 192.168.33.13, executor 3, partition 48, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, 192.168.33.13, executor 3, partition 49, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50, 192.168.33.13, executor 3, partition 50, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51, 192.168.33.13, executor 3, partition 51, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52, 192.168.33.13, executor 3, partition 52, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53, 192.168.33.13, executor 3, partition 53, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54, 192.168.33.13, executor 3, partition 54, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55, 192.168.33.13, executor 3, partition 55, ANY, 4879 bytes)
18/09/26 09:40:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:37138) with ID 1
18/09/26 09:40:59 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56, 192.168.33.10, executor 1, partition 56, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57, 192.168.33.10, executor 1, partition 57, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58, 192.168.33.10, executor 1, partition 58, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59, 192.168.33.10, executor 1, partition 59, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60, 192.168.33.10, executor 1, partition 60, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61, 192.168.33.10, executor 1, partition 61, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62, 192.168.33.10, executor 1, partition 62, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63, 192.168.33.10, executor 1, partition 63, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64, 192.168.33.10, executor 1, partition 64, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65, 192.168.33.10, executor 1, partition 65, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66, 192.168.33.10, executor 1, partition 66, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67, 192.168.33.10, executor 1, partition 67, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68, 192.168.33.10, executor 1, partition 68, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69, 192.168.33.10, executor 1, partition 69, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70, 192.168.33.10, executor 1, partition 70, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71, 192.168.33.10, executor 1, partition 71, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72, 192.168.33.10, executor 1, partition 72, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73, 192.168.33.10, executor 1, partition 73, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74, 192.168.33.10, executor 1, partition 74, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75, 192.168.33.10, executor 1, partition 75, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76, 192.168.33.10, executor 1, partition 76, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77, 192.168.33.10, executor 1, partition 77, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78, 192.168.33.10, executor 1, partition 78, ANY, 4879 bytes)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79, 192.168.33.10, executor 1, partition 79, ANY, 4879 bytes)
18/09/26 09:40:59 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:46832 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.13, 46832, None)
18/09/26 09:40:59 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:38350 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 38350, None)
18/09/26 09:40:59 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36022; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:40:59 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80, 192.168.33.15, executor 0, partition 80, ANY, 4879 bytes)
18/09/26 09:40:59 WARN TaskSetManager: Lost task 3.0 in stage 0.0 (TID 3, 192.168.33.15, executor 0): java.io.IOException: Aucun espace disponible sur le périphérique
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.util.Utils$.downloadFile(Utils.scala:526)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:656)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:708)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:700)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:700)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:311)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 09:40:59 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36024; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:00 INFO TaskSetManager: Starting task 3.1 in stage 0.0 (TID 81, 192.168.33.15, executor 0, partition 3, ANY, 4879 bytes)
18/09/26 09:41:00 INFO TaskSetManager: Lost task 42.0 in stage 0.0 (TID 42) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 1]
18/09/26 09:41:00 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36026; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:00 INFO TaskSetManager: Starting task 42.1 in stage 0.0 (TID 82, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:41:00 INFO TaskSetManager: Lost task 36.0 in stage 0.0 (TID 36) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 2]
18/09/26 09:41:00 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36028; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:00 INFO TaskSetManager: Starting task 36.1 in stage 0.0 (TID 83, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:41:00 INFO TaskSetManager: Lost task 41.0 in stage 0.0 (TID 41) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 3]
18/09/26 09:41:00 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36030; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:38350 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:41:01 INFO TaskSetManager: Starting task 41.1 in stage 0.0 (TID 84, 192.168.33.15, executor 0, partition 41, ANY, 4879 bytes)
18/09/26 09:41:01 INFO TaskSetManager: Lost task 34.0 in stage 0.0 (TID 34) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 4]
18/09/26 09:41:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:38350 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:41:01 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36032; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:01 INFO TaskSetManager: Starting task 34.1 in stage 0.0 (TID 85, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 09:41:01 INFO TaskSetManager: Lost task 47.0 in stage 0.0 (TID 47) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 5]
18/09/26 09:41:01 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36034; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:01 INFO TaskSetManager: Starting task 47.1 in stage 0.0 (TID 86, 192.168.33.15, executor 0, partition 47, ANY, 4879 bytes)
18/09/26 09:41:01 INFO TaskSetManager: Lost task 31.0 in stage 0.0 (TID 31) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 6]
18/09/26 09:41:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36036; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:02 INFO TaskSetManager: Starting task 31.1 in stage 0.0 (TID 87, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 09:41:02 INFO TaskSetManager: Lost task 15.0 in stage 0.0 (TID 15) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 7]
18/09/26 09:41:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36038; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:02 INFO TaskSetManager: Starting task 15.1 in stage 0.0 (TID 88, 192.168.33.15, executor 0, partition 15, ANY, 4879 bytes)
18/09/26 09:41:02 INFO TaskSetManager: Lost task 27.0 in stage 0.0 (TID 27) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 8]
18/09/26 09:41:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36040; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:02 INFO TaskSetManager: Starting task 27.1 in stage 0.0 (TID 89, 192.168.33.15, executor 0, partition 27, ANY, 4879 bytes)
18/09/26 09:41:02 INFO TaskSetManager: Lost task 32.0 in stage 0.0 (TID 32) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 9]
18/09/26 09:41:03 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36042; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:03 INFO TaskSetManager: Starting task 32.1 in stage 0.0 (TID 90, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:41:03 INFO TaskSetManager: Lost task 44.0 in stage 0.0 (TID 44) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 10]
18/09/26 09:41:03 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36044; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:03 INFO TaskSetManager: Starting task 44.1 in stage 0.0 (TID 91, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:41:03 INFO TaskSetManager: Lost task 40.0 in stage 0.0 (TID 40) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 11]
18/09/26 09:41:03 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36046; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:03 INFO TaskSetManager: Starting task 40.1 in stage 0.0 (TID 92, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:41:03 INFO TaskSetManager: Lost task 35.0 in stage 0.0 (TID 35) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 12]
18/09/26 09:41:04 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36048; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:04 INFO TaskSetManager: Starting task 35.1 in stage 0.0 (TID 93, 192.168.33.15, executor 0, partition 35, ANY, 4879 bytes)
18/09/26 09:41:04 INFO TaskSetManager: Lost task 11.0 in stage 0.0 (TID 11) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 13]
18/09/26 09:41:04 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36050; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:04 INFO TaskSetManager: Starting task 11.1 in stage 0.0 (TID 94, 192.168.33.15, executor 0, partition 11, ANY, 4879 bytes)
18/09/26 09:41:04 INFO TaskSetManager: Lost task 43.0 in stage 0.0 (TID 43) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 14]
18/09/26 09:41:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.13:46832 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:41:04 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36052; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:04 INFO TaskSetManager: Starting task 43.1 in stage 0.0 (TID 95, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 09:41:04 INFO TaskSetManager: Lost task 23.0 in stage 0.0 (TID 23) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 15]
18/09/26 09:41:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.13:46832 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:41:05 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36054; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:38459 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:41:05 INFO TaskSetManager: Starting task 23.1 in stage 0.0 (TID 96, 192.168.33.15, executor 0, partition 23, ANY, 4879 bytes)
18/09/26 09:41:05 INFO TaskSetManager: Lost task 7.0 in stage 0.0 (TID 7) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 16]
18/09/26 09:41:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:38459 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:41:05 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36056; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:05 INFO TaskSetManager: Starting task 7.1 in stage 0.0 (TID 97, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 09:41:05 INFO TaskSetManager: Lost task 19.0 in stage 0.0 (TID 19) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 17]
18/09/26 09:41:05 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36058; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 19.1 in stage 0.0 (TID 98, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 33.0 in stage 0.0 (TID 33) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 18]
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36060; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 33.1 in stage 0.0 (TID 99, 192.168.33.15, executor 0, partition 33, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 38.0 in stage 0.0 (TID 38) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 19]
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36062; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:43381 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 38.1 in stage 0.0 (TID 100, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 37.0 in stage 0.0 (TID 37) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 20]
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36064; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 37.1 in stage 0.0 (TID 101, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 45.0 in stage 0.0 (TID 45) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 21]
18/09/26 09:41:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.11:37258 (size: 2.5 KB, free: 15.8 GB)
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36067; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:43381 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 45.1 in stage 0.0 (TID 102, 192.168.33.15, executor 0, partition 45, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 46.0 in stage 0.0 (TID 46) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 22]
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36068; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 46.1 in stage 0.0 (TID 103, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 39.0 in stage 0.0 (TID 39) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 23]
18/09/26 09:41:06 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36070; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:06 INFO TaskSetManager: Starting task 39.1 in stage 0.0 (TID 104, 192.168.33.15, executor 0, partition 39, ANY, 4879 bytes)
18/09/26 09:41:06 INFO TaskSetManager: Lost task 45.1 in stage 0.0 (TID 102) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 24]
18/09/26 09:41:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.11:37258 (size: 27.9 KB, free: 15.8 GB)
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36072; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 45.2 in stage 0.0 (TID 105, 192.168.33.15, executor 0, partition 45, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 37.1 in stage 0.0 (TID 101) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 25]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36074; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 37.2 in stage 0.0 (TID 106, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 38.1 in stage 0.0 (TID 100) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 26]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36076; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 38.2 in stage 0.0 (TID 107, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 33.1 in stage 0.0 (TID 99) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 27]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36078; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 33.2 in stage 0.0 (TID 108, 192.168.33.15, executor 0, partition 33, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 19.1 in stage 0.0 (TID 98) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 28]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36080; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 19.2 in stage 0.0 (TID 109, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 7.1 in stage 0.0 (TID 97) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 29]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36082; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:07 INFO TaskSetManager: Starting task 7.2 in stage 0.0 (TID 110, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 09:41:07 INFO TaskSetManager: Lost task 23.1 in stage 0.0 (TID 96) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 30]
18/09/26 09:41:07 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36084; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 23.2 in stage 0.0 (TID 111, 192.168.33.15, executor 0, partition 23, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 43.1 in stage 0.0 (TID 95) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 31]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36086; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 43.2 in stage 0.0 (TID 112, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 11.1 in stage 0.0 (TID 94) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 32]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36088; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 11.2 in stage 0.0 (TID 113, 192.168.33.15, executor 0, partition 11, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 35.1 in stage 0.0 (TID 93) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 33]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36090; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 35.2 in stage 0.0 (TID 114, 192.168.33.15, executor 0, partition 35, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 40.1 in stage 0.0 (TID 92) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 34]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36092; closing connection
java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 40.2 in stage 0.0 (TID 115, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 44.1 in stage 0.0 (TID 91) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 35]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36094; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:08 INFO TaskSetManager: Starting task 44.2 in stage 0.0 (TID 116, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:41:08 INFO TaskSetManager: Lost task 32.1 in stage 0.0 (TID 90) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 36]
18/09/26 09:41:08 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36096; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 32.2 in stage 0.0 (TID 117, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:41:09 INFO TaskSetManager: Lost task 27.1 in stage 0.0 (TID 89) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 37]
18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36098; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 27.2 in stage 0.0 (TID 118, 192.168.33.15, executor 0, partition 27, ANY, 4879 bytes)
18/09/26 09:41:09 INFO TaskSetManager: Lost task 15.1 in stage 0.0 (TID 88) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 38]
18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36100; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 15.2 in stage 0.0 (TID 119, 192.168.33.15, executor 0, partition 15, ANY, 4879 bytes)
18/09/26 09:41:09 INFO TaskSetManager: Lost task 31.1 in stage 0.0 (TID 87) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 39]
18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36102; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 31.2 in stage 0.0 (TID 120, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 09:41:09 INFO TaskSetManager: Lost task 47.1 in stage 0.0 (TID 86) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 40]
18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36104; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 47.2 in stage 0.0 (TID 121, 192.168.33.15, executor 0, partition 47, ANY, 4879 bytes)
18/09/26 09:41:09 INFO TaskSetManager: Lost task 34.1 in stage 0.0 (TID 85) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 41]
18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36106; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:09 INFO TaskSetManager: Starting task 34.2 in stage 0.0 (TID 122, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 09:41:09 WARN TaskSetManager: Lost task 41.1 in stage 0.0 (TID 84, 192.168.33.15, executor 0): java.io.IOException: Aucun espace disponible sur le périphérique
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.util.Utils$.downloadFile(Utils.scala:526)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:656)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:708)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:700)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:700)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:311)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 09:41:09 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36108; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 41.2 in stage 0.0 (TID 123, 192.168.33.15, executor 0, partition 41, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 36.1 in stage 0.0 (TID 83) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 1]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36110; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 36.2 in stage 0.0 (TID 124, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 42.1 in stage 0.0 (TID 82) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 2]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36112; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 42.2 in stage 0.0 (TID 125, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 3.1 in stage 0.0 (TID 81) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 3]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36114; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 3.2 in stage 0.0 (TID 126, 192.168.33.15, executor 0, partition 3, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 80.0 in stage 0.0 (TID 80) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 4]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36116; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 80.1 in stage 0.0 (TID 127, 192.168.33.15, executor 0, partition 80, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 42.2 in stage 0.0 (TID 125) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 5]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36118; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 42.3 in stage 0.0 (TID 128, 192.168.33.15, executor 0, partition 42, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 36.2 in stage 0.0 (TID 124) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 6]
18/09/26 09:41:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36120; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:10 INFO TaskSetManager: Starting task 36.3 in stage 0.0 (TID 129, 192.168.33.15, executor 0, partition 36, ANY, 4879 bytes)
18/09/26 09:41:10 INFO TaskSetManager: Lost task 41.2 in stage 0.0 (TID 123) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 7]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36122; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 41.3 in stage 0.0 (TID 130, 192.168.33.15, executor 0, partition 41, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 34.2 in stage 0.0 (TID 122) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 8]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36124; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 34.3 in stage 0.0 (TID 131, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 47.2 in stage 0.0 (TID 121) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 9]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36126; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 47.3 in stage 0.0 (TID 132, 192.168.33.15, executor 0, partition 47, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 31.2 in stage 0.0 (TID 120) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 10]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36128; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 31.3 in stage 0.0 (TID 133, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 15.2 in stage 0.0 (TID 119) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 11]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36130; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 15.3 in stage 0.0 (TID 134, 192.168.33.15, executor 0, partition 15, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 27.2 in stage 0.0 (TID 118) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 12]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36132; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:11 INFO TaskSetManager: Starting task 27.3 in stage 0.0 (TID 135, 192.168.33.15, executor 0, partition 27, ANY, 4879 bytes)
18/09/26 09:41:11 INFO TaskSetManager: Lost task 32.2 in stage 0.0 (TID 117) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 13]
18/09/26 09:41:11 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36134; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 32.3 in stage 0.0 (TID 136, 192.168.33.15, executor 0, partition 32, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 44.2 in stage 0.0 (TID 116) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 14]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36138; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 44.3 in stage 0.0 (TID 137, 192.168.33.15, executor 0, partition 44, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 40.2 in stage 0.0 (TID 115) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 15]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36140; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 40.3 in stage 0.0 (TID 138, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 35.2 in stage 0.0 (TID 114) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 16]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36142; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 35.3 in stage 0.0 (TID 139, 192.168.33.15, executor 0, partition 35, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 11.2 in stage 0.0 (TID 113) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 17]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36144; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 11.3 in stage 0.0 (TID 140, 192.168.33.15, executor 0, partition 11, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 43.2 in stage 0.0 (TID 112) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 18]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36146; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 43.3 in stage 0.0 (TID 141, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 23.2 in stage 0.0 (TID 111) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 19]
18/09/26 09:41:12 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36148; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:12 INFO TaskSetManager: Starting task 23.3 in stage 0.0 (TID 142, 192.168.33.15, executor 0, partition 23, ANY, 4879 bytes)
18/09/26 09:41:12 INFO TaskSetManager: Lost task 7.2 in stage 0.0 (TID 110) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 20]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36150; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 7.3 in stage 0.0 (TID 143, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 19.2 in stage 0.0 (TID 109) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 21]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36152; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 19.3 in stage 0.0 (TID 144, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 33.2 in stage 0.0 (TID 108) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 22]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36154; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 33.3 in stage 0.0 (TID 145, 192.168.33.15, executor 0, partition 33, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 38.2 in stage 0.0 (TID 107) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 23]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36156; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 38.3 in stage 0.0 (TID 146, 192.168.33.15, executor 0, partition 38, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 37.2 in stage 0.0 (TID 106) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 24]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36158; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 37.3 in stage 0.0 (TID 147, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 45.2 in stage 0.0 (TID 105) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 25]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36160; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 45.3 in stage 0.0 (TID 148, 192.168.33.15, executor 0, partition 45, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 39.1 in stage 0.0 (TID 104) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 26]
18/09/26 09:41:13 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36162; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:13 INFO TaskSetManager: Starting task 39.2 in stage 0.0 (TID 149, 192.168.33.15, executor 0, partition 39, ANY, 4879 bytes)
18/09/26 09:41:13 INFO TaskSetManager: Lost task 46.1 in stage 0.0 (TID 103) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 27]
18/09/26 09:41:14 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36164; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:14 INFO TaskSetManager: Starting task 46.2 in stage 0.0 (TID 150, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/26 09:41:14 INFO TaskSetManager: Lost task 45.3 in stage 0.0 (TID 148) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 28]
18/09/26 09:41:14 ERROR TaskSetManager: Task 45 in stage 0.0 failed 4 times; aborting job
18/09/26 09:41:14 INFO TaskSchedulerImpl: Cancelling stage 0
18/09/26 09:41:14 INFO TaskSchedulerImpl: Stage 0 was cancelled
18/09/26 09:41:14 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) failed in 15,103 s due to Job aborted due to stage failure: Task 45 in stage 0.0 failed 4 times, most recent failure: Lost task 45.3 in stage 0.0 (TID 148, 192.168.33.15, executor 0): java.io.IOException: Aucun espace disponible sur le périphérique
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:342)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.util.Utils$.downloadFile(Utils.scala:526)
	at org.apache.spark.util.Utils$.doFetchFile(Utils.scala:656)
	at org.apache.spark.util.Utils$.fetchFile(Utils.scala:467)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:708)
	at org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Executor.scala:700)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$updateDependencies(Executor.scala:700)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:311)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
18/09/26 09:41:14 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 15,301049 s
18/09/26 09:41:14 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 09:41:14 WARN TaskSetManager: Lost task 76.0 in stage 0.0 (TID 76, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 75.0 in stage 0.0 (TID 75, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 65.0 in stage 0.0 (TID 65, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 79.0 in stage 0.0 (TID 79, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 78.0 in stage 0.0 (TID 78, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 69.0 in stage 0.0 (TID 69, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 70.0 in stage 0.0 (TID 70, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 59.0 in stage 0.0 (TID 59, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36166; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 58.0 in stage 0.0 (TID 58, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 64.0 in stage 0.0 (TID 64, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 72.0 in stage 0.0 (TID 72, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 74.0 in stage 0.0 (TID 74, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 77.0 in stage 0.0 (TID 77, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 61.0 in stage 0.0 (TID 61, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 09:41:14 WARN TaskSetManager: Lost task 57.0 in stage 0.0 (TID 57, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 09:41:14 INFO TaskSetManager: Lost task 37.3 in stage 0.0 (TID 147) on 192.168.33.15, executor 0: java.io.IOException (Aucun espace disponible sur le périphérique) [duplicate 29]
18/09/26 09:41:14 WARN TaskSetManager: Lost task 6.0 in stage 0.0 (TID 6, 192.168.33.12, executor 5): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 10.0 in stage 0.0 (TID 10, 192.168.33.12, executor 5): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 51.0 in stage 0.0 (TID 51, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 49.0 in stage 0.0 (TID 49, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 54.0 in stage 0.0 (TID 54, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 52.0 in stage 0.0 (TID 52, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 48.0 in stage 0.0 (TID 48, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 55.0 in stage 0.0 (TID 55, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 50.0 in stage 0.0 (TID 50, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 53.0 in stage 0.0 (TID 53, 192.168.33.13, executor 3): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 28.0 in stage 0.0 (TID 28, 192.168.33.11, executor 4): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4, 192.168.33.11, executor 4): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 16.0 in stage 0.0 (TID 16, 192.168.33.11, executor 4): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 9.0 in stage 0.0 (TID 9, 192.168.33.14, executor 2): TaskKilled (stage cancelled)
18/09/26 09:41:14 WARN TaskSetManager: Lost task 13.0 in stage 0.0 (TID 13, 192.168.33.14, executor 2): TaskKilled (stage cancelled)
18/09/26 09:41:14 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 09:41:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 09:41:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 09:41:14 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, byteCount=160305047, body=FileSegmentManagedBuffer{file=/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar, offset=0, length=160305047}} to /192.168.33.15:36168; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 09:41:14 INFO MemoryStore: MemoryStore cleared
18/09/26 09:41:14 INFO BlockManager: BlockManager stopped
18/09/26 09:41:14 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 09:41:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 09:41:14 INFO SparkContext: Successfully stopped SparkContext
18/09/26 09:41:14 INFO ShutdownHookManager: Shutdown hook called
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-6cfacd9a-4724-4b57-b4f6-4967b47302f8
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-587edf8e-b6d3-42e5-8ec3-0eb4a0451cf6
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-308678d4-df04-4477-b818-9b98be77fc7e
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-cbec45c7-c16a-4a81-9c5a-66cf0e262a12
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-eb0c7692-460a-4e56-979a-61a856c702a6
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-6439d899-cd32-4360-af5b-010d94e9c6f9
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-f9996cf3-3e0a-44f0-b20b-eeb4e4238686
18/09/26 09:41:14 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-7f98a5a3-c373-4f7e-8f91-a763add0be77
18/09/26 10:48:19 INFO SparkContext: Running Spark version 2.2.1
18/09/26 10:48:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 10:48:20 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 10:48:20 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 10:48:20 INFO SecurityManager: Changing view acls to: redouane
18/09/26 10:48:20 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 10:48:20 INFO SecurityManager: Changing view acls groups to: 
18/09/26 10:48:20 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 10:48:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 10:48:20 INFO Utils: Successfully started service 'sparkDriver' on port 41733.
18/09/26 10:48:20 INFO SparkEnv: Registering MapOutputTracker
18/09/26 10:48:20 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 10:48:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 10:48:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-3d4b59c1-6972-477e-95c0-055c389fa317
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-307611c1-60ba-420e-a6e0-cd09c38da000
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-629731a0-381b-47d1-a6f2-1a2c263ee1d4
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-4152d808-ae57-4fdd-9d6d-9889afa84eda
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-ebfc3fa8-43cc-4c18-bac1-8336cbf635f9
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-5a9ba246-27ac-43cc-8df1-7ff6705f164b
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-00d4ae0a-9425-481c-be98-f6a4b3815757
18/09/26 10:48:20 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-494b3f20-c222-447f-baac-05f470fc4f62
18/09/26 10:48:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 10:48:20 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 10:48:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 10:48:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 10:48:20 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:41733/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537951700983
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 10:48:21 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 27 ms (0 ms spent in bootstraps)
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926104821-0003
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41453.
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/26 10:48:21 INFO NettyBlockTransferService: Server created on 192.168.33.10:41453
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926104821-0003/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/26 10:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 10:48:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926104821-0003/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/26 10:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 41453, None)
18/09/26 10:48:21 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:41453 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 41453, None)
18/09/26 10:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 41453, None)
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/0 is now RUNNING
18/09/26 10:48:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 41453, None)
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/4 is now RUNNING
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/2 is now RUNNING
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/1 is now RUNNING
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/5 is now RUNNING
18/09/26 10:48:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926104821-0003/3 is now RUNNING
18/09/26 10:48:22 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926104821-0003
18/09/26 10:48:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 10:48:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 10:48:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 10:48:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:41453 (size: 27.9 KB, free: 366.3 MB)
18/09/26 10:48:23 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 10:48:23 INFO FileInputFormat: Total input files to process : 409
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:50934) with ID 3
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:43414) with ID 5
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:38750) with ID 2
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:34278) with ID 4
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:39580) with ID 0
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:44970 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.12, 44970, None)
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:33794 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.11, 33794, None)
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:40271 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.13, 40271, None)
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:38641 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.14, 38641, None)
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:44293 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 44293, None)
18/09/26 10:48:23 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/26 10:48:23 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/26 10:48:23 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/26 10:48:23 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/26 10:48:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/26 10:48:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:40606) with ID 1
18/09/26 10:48:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/26 10:48:23 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 10:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:40617 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 40617, None)
18/09/26 10:48:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/26 10:48:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 10:48:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:41453 (size: 2.5 KB, free: 366.3 MB)
18/09/26 10:48:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/26 10:48:23 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 10:48:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/26 10:48:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.10, executor 1, partition 0, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.15, executor 0, partition 1, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.14, executor 4, partition 2, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.13, executor 2, partition 3, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.12, executor 3, partition 4, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.11, executor 5, partition 5, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.10, executor 1, partition 6, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.14, executor 4, partition 8, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.13, executor 2, partition 9, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.12, executor 3, partition 10, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.11, executor 5, partition 11, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.10, executor 1, partition 12, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.15, executor 0, partition 13, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.14, executor 4, partition 14, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.13, executor 2, partition 15, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.12, executor 3, partition 16, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.11, executor 5, partition 17, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.10, executor 1, partition 18, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.14, executor 4, partition 20, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.13, executor 2, partition 21, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.12, executor 3, partition 22, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.11, executor 5, partition 23, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.10, executor 1, partition 24, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.15, executor 0, partition 25, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.14, executor 4, partition 26, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.13, executor 2, partition 27, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.12, executor 3, partition 28, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.11, executor 5, partition 29, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.10, executor 1, partition 30, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.14, executor 4, partition 32, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.13, executor 2, partition 33, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.12, executor 3, partition 34, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.11, executor 5, partition 35, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.10, executor 1, partition 36, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.14, executor 4, partition 38, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.13, executor 2, partition 39, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.12, executor 3, partition 40, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.11, executor 5, partition 41, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.10, executor 1, partition 42, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.14, executor 4, partition 44, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.13, executor 2, partition 45, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.12, executor 3, partition 46, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.11, executor 5, partition 47, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, 192.168.33.10, executor 1, partition 48, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, 192.168.33.15, executor 0, partition 49, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50, 192.168.33.10, executor 1, partition 50, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51, 192.168.33.15, executor 0, partition 51, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52, 192.168.33.10, executor 1, partition 52, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53, 192.168.33.15, executor 0, partition 53, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54, 192.168.33.10, executor 1, partition 54, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55, 192.168.33.15, executor 0, partition 55, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56, 192.168.33.10, executor 1, partition 56, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57, 192.168.33.15, executor 0, partition 57, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58, 192.168.33.10, executor 1, partition 58, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59, 192.168.33.15, executor 0, partition 59, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60, 192.168.33.10, executor 1, partition 60, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61, 192.168.33.15, executor 0, partition 61, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62, 192.168.33.10, executor 1, partition 62, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63, 192.168.33.15, executor 0, partition 63, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64, 192.168.33.10, executor 1, partition 64, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65, 192.168.33.15, executor 0, partition 65, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66, 192.168.33.10, executor 1, partition 66, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67, 192.168.33.15, executor 0, partition 67, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68, 192.168.33.10, executor 1, partition 68, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69, 192.168.33.15, executor 0, partition 69, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70, 192.168.33.10, executor 1, partition 70, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71, 192.168.33.15, executor 0, partition 71, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72, 192.168.33.10, executor 1, partition 72, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73, 192.168.33.15, executor 0, partition 73, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74, 192.168.33.10, executor 1, partition 74, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75, 192.168.33.15, executor 0, partition 75, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76, 192.168.33.10, executor 1, partition 76, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77, 192.168.33.15, executor 0, partition 77, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78, 192.168.33.10, executor 1, partition 78, ANY, 4879 bytes)
18/09/26 10:48:23 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79, 192.168.33.15, executor 0, partition 79, ANY, 4879 bytes)
18/09/26 10:48:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:40617 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:40617 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.13:40271 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.13:40271 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.11:33794 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.11:33794 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:44970 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:44970 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:38641 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.15:44293 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:48:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:38641 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.15:44293 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:48:48 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80, 192.168.33.14, executor 4, partition 80, ANY, 4879 bytes)
18/09/26 10:48:48 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 24816 ms on 192.168.33.14 (executor 4) (1/409)
18/09/26 10:48:49 INFO TaskSetManager: Starting task 81.0 in stage 0.0 (TID 81, 192.168.33.12, executor 3, partition 81, ANY, 4879 bytes)
18/09/26 10:48:49 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 25660 ms on 192.168.33.12 (executor 3) (2/409)
18/09/26 10:48:50 INFO TaskSetManager: Starting task 82.0 in stage 0.0 (TID 82, 192.168.33.14, executor 4, partition 82, ANY, 4879 bytes)
18/09/26 10:48:50 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 26250 ms on 192.168.33.14 (executor 4) (3/409)
18/09/26 10:48:50 INFO TaskSetManager: Starting task 83.0 in stage 0.0 (TID 83, 192.168.33.12, executor 3, partition 83, ANY, 4879 bytes)
18/09/26 10:48:50 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 26349 ms on 192.168.33.12 (executor 3) (4/409)
18/09/26 10:48:50 INFO TaskSetManager: Starting task 84.0 in stage 0.0 (TID 84, 192.168.33.12, executor 3, partition 84, ANY, 4879 bytes)
18/09/26 10:48:50 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 26463 ms on 192.168.33.12 (executor 3) (5/409)
18/09/26 10:48:50 INFO TaskSetManager: Starting task 85.0 in stage 0.0 (TID 85, 192.168.33.12, executor 3, partition 85, ANY, 4879 bytes)
18/09/26 10:48:50 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 26482 ms on 192.168.33.12 (executor 3) (6/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 86.0 in stage 0.0 (TID 86, 192.168.33.12, executor 3, partition 86, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 27285 ms on 192.168.33.12 (executor 3) (7/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 87.0 in stage 0.0 (TID 87, 192.168.33.11, executor 5, partition 87, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 27307 ms on 192.168.33.11 (executor 5) (8/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 88.0 in stage 0.0 (TID 88, 192.168.33.11, executor 5, partition 88, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 27481 ms on 192.168.33.11 (executor 5) (9/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 89.0 in stage 0.0 (TID 89, 192.168.33.14, executor 4, partition 89, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 27498 ms on 192.168.33.14 (executor 4) (10/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 90.0 in stage 0.0 (TID 90, 192.168.33.11, executor 5, partition 90, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 27596 ms on 192.168.33.11 (executor 5) (11/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 91.0 in stage 0.0 (TID 91, 192.168.33.11, executor 5, partition 91, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 27629 ms on 192.168.33.11 (executor 5) (12/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 92.0 in stage 0.0 (TID 92, 192.168.33.14, executor 4, partition 92, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 27635 ms on 192.168.33.14 (executor 4) (13/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 93.0 in stage 0.0 (TID 93, 192.168.33.11, executor 5, partition 93, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 27910 ms on 192.168.33.11 (executor 5) (14/409)
18/09/26 10:48:51 INFO TaskSetManager: Starting task 94.0 in stage 0.0 (TID 94, 192.168.33.14, executor 4, partition 94, ANY, 4879 bytes)
18/09/26 10:48:51 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 28057 ms on 192.168.33.14 (executor 4) (15/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 95.0 in stage 0.0 (TID 95, 192.168.33.12, executor 3, partition 95, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 28170 ms on 192.168.33.12 (executor 3) (16/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 96.0 in stage 0.0 (TID 96, 192.168.33.11, executor 5, partition 96, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 28197 ms on 192.168.33.11 (executor 5) (17/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 97.0 in stage 0.0 (TID 97, 192.168.33.14, executor 4, partition 97, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 28188 ms on 192.168.33.14 (executor 4) (18/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 98.0 in stage 0.0 (TID 98, 192.168.33.14, executor 4, partition 98, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 28216 ms on 192.168.33.14 (executor 4) (19/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 99.0 in stage 0.0 (TID 99, 192.168.33.11, executor 5, partition 99, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 28255 ms on 192.168.33.11 (executor 5) (20/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 100.0 in stage 0.0 (TID 100, 192.168.33.14, executor 4, partition 100, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 28273 ms on 192.168.33.14 (executor 4) (21/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 101.0 in stage 0.0 (TID 101, 192.168.33.12, executor 3, partition 101, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 28550 ms on 192.168.33.12 (executor 3) (22/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 102.0 in stage 0.0 (TID 102, 192.168.33.12, executor 3, partition 102, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 28758 ms on 192.168.33.12 (executor 3) (23/409)
18/09/26 10:48:52 INFO TaskSetManager: Starting task 103.0 in stage 0.0 (TID 103, 192.168.33.13, executor 2, partition 103, ANY, 4879 bytes)
18/09/26 10:48:52 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 29149 ms on 192.168.33.13 (executor 2) (24/409)
18/09/26 10:48:53 INFO TaskSetManager: Starting task 104.0 in stage 0.0 (TID 104, 192.168.33.11, executor 5, partition 104, ANY, 4879 bytes)
18/09/26 10:48:53 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 29163 ms on 192.168.33.11 (executor 5) (25/409)
18/09/26 10:48:53 INFO TaskSetManager: Starting task 105.0 in stage 0.0 (TID 105, 192.168.33.13, executor 2, partition 105, ANY, 4879 bytes)
18/09/26 10:48:53 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 29830 ms on 192.168.33.13 (executor 2) (26/409)
18/09/26 10:48:54 INFO TaskSetManager: Starting task 106.0 in stage 0.0 (TID 106, 192.168.33.13, executor 2, partition 106, ANY, 4879 bytes)
18/09/26 10:48:54 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 30211 ms on 192.168.33.13 (executor 2) (27/409)
18/09/26 10:48:54 INFO TaskSetManager: Starting task 107.0 in stage 0.0 (TID 107, 192.168.33.13, executor 2, partition 107, ANY, 4879 bytes)
18/09/26 10:48:54 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 30352 ms on 192.168.33.13 (executor 2) (28/409)
18/09/26 10:48:54 INFO TaskSetManager: Starting task 108.0 in stage 0.0 (TID 108, 192.168.33.13, executor 2, partition 108, ANY, 4879 bytes)
18/09/26 10:48:54 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 30828 ms on 192.168.33.13 (executor 2) (29/409)
18/09/26 10:48:54 INFO TaskSetManager: Starting task 109.0 in stage 0.0 (TID 109, 192.168.33.13, executor 2, partition 109, ANY, 4879 bytes)
18/09/26 10:48:54 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 31015 ms on 192.168.33.13 (executor 2) (30/409)
18/09/26 10:48:54 INFO TaskSetManager: Starting task 110.0 in stage 0.0 (TID 110, 192.168.33.13, executor 2, partition 110, ANY, 4879 bytes)
18/09/26 10:48:54 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 31024 ms on 192.168.33.13 (executor 2) (31/409)
18/09/26 10:48:55 INFO TaskSetManager: Starting task 111.0 in stage 0.0 (TID 111, 192.168.33.13, executor 2, partition 111, ANY, 4879 bytes)
18/09/26 10:48:55 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 31263 ms on 192.168.33.13 (executor 2) (32/409)
18/09/26 10:48:56 INFO TaskSetManager: Starting task 112.0 in stage 0.0 (TID 112, 192.168.33.14, executor 4, partition 112, ANY, 4879 bytes)
18/09/26 10:48:56 WARN TaskSetManager: Lost task 92.0 in stage 0.0 (TID 92, 192.168.33.14, executor 4): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:49:03 INFO TaskSetManager: Starting task 92.1 in stage 0.0 (TID 113, 192.168.33.14, executor 4, partition 92, ANY, 4879 bytes)
18/09/26 10:49:03 INFO TaskSetManager: Finished task 80.0 in stage 0.0 (TID 80) in 15121 ms on 192.168.33.14 (executor 4) (33/409)
18/09/26 10:49:05 INFO TaskSetManager: Starting task 113.0 in stage 0.0 (TID 114, 192.168.33.14, executor 4, partition 113, ANY, 4879 bytes)
18/09/26 10:49:05 INFO TaskSetManager: Finished task 82.0 in stage 0.0 (TID 82) in 15123 ms on 192.168.33.14 (executor 4) (34/409)
18/09/26 10:49:06 INFO TaskSetManager: Starting task 114.0 in stage 0.0 (TID 115, 192.168.33.12, executor 3, partition 114, ANY, 4879 bytes)
18/09/26 10:49:06 INFO TaskSetManager: Finished task 84.0 in stage 0.0 (TID 84) in 16587 ms on 192.168.33.12 (executor 3) (35/409)
18/09/26 10:49:07 INFO TaskSetManager: Starting task 115.0 in stage 0.0 (TID 116, 192.168.33.12, executor 3, partition 115, ANY, 4879 bytes)
18/09/26 10:49:07 INFO TaskSetManager: Finished task 83.0 in stage 0.0 (TID 83) in 17048 ms on 192.168.33.12 (executor 3) (36/409)
18/09/26 10:49:07 INFO TaskSetManager: Starting task 116.0 in stage 0.0 (TID 117, 192.168.33.12, executor 3, partition 116, ANY, 4879 bytes)
18/09/26 10:49:07 INFO TaskSetManager: Finished task 81.0 in stage 0.0 (TID 81) in 17941 ms on 192.168.33.12 (executor 3) (37/409)
18/09/26 10:49:07 INFO TaskSetManager: Starting task 117.0 in stage 0.0 (TID 118, 192.168.33.14, executor 4, partition 117, ANY, 4879 bytes)
18/09/26 10:49:07 INFO TaskSetManager: Finished task 94.0 in stage 0.0 (TID 94) in 15528 ms on 192.168.33.14 (executor 4) (38/409)
18/09/26 10:49:07 INFO TaskSetManager: Starting task 118.0 in stage 0.0 (TID 119, 192.168.33.14, executor 4, partition 118, ANY, 4879 bytes)
18/09/26 10:49:07 WARN TaskSetManager: Lost task 92.1 in stage 0.0 (TID 113, 192.168.33.14, executor 4): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:49:07 INFO TaskSetManager: Starting task 92.2 in stage 0.0 (TID 120, 192.168.33.12, executor 3, partition 92, ANY, 4879 bytes)
18/09/26 10:49:07 INFO TaskSetManager: Finished task 85.0 in stage 0.0 (TID 85) in 17597 ms on 192.168.33.12 (executor 3) (39/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 119.0 in stage 0.0 (TID 121, 192.168.33.14, executor 4, partition 119, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 100.0 in stage 0.0 (TID 100) in 16225 ms on 192.168.33.14 (executor 4) (40/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 120.0 in stage 0.0 (TID 122, 192.168.33.12, executor 3, partition 120, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 86.0 in stage 0.0 (TID 86) in 17266 ms on 192.168.33.12 (executor 3) (41/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 121.0 in stage 0.0 (TID 123, 192.168.33.11, executor 5, partition 121, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 88.0 in stage 0.0 (TID 88) in 17105 ms on 192.168.33.11 (executor 5) (42/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 122.0 in stage 0.0 (TID 124, 192.168.33.11, executor 5, partition 122, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 99.0 in stage 0.0 (TID 99) in 16527 ms on 192.168.33.11 (executor 5) (43/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 123.0 in stage 0.0 (TID 125, 192.168.33.14, executor 4, partition 123, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 89.0 in stage 0.0 (TID 89) in 17571 ms on 192.168.33.14 (executor 4) (44/409)
18/09/26 10:49:08 INFO TaskSetManager: Starting task 124.0 in stage 0.0 (TID 126, 192.168.33.14, executor 4, partition 124, ANY, 4879 bytes)
18/09/26 10:49:08 INFO TaskSetManager: Finished task 98.0 in stage 0.0 (TID 98) in 16873 ms on 192.168.33.14 (executor 4) (45/409)
18/09/26 10:49:09 INFO TaskSetManager: Starting task 125.0 in stage 0.0 (TID 127, 192.168.33.11, executor 5, partition 125, ANY, 4879 bytes)
18/09/26 10:49:09 INFO TaskSetManager: Finished task 96.0 in stage 0.0 (TID 96) in 17047 ms on 192.168.33.11 (executor 5) (46/409)
18/09/26 10:49:09 INFO TaskSetManager: Starting task 126.0 in stage 0.0 (TID 128, 192.168.33.14, executor 4, partition 126, ANY, 4879 bytes)
18/09/26 10:49:09 INFO TaskSetManager: Finished task 97.0 in stage 0.0 (TID 97) in 17099 ms on 192.168.33.14 (executor 4) (47/409)
18/09/26 10:49:09 INFO TaskSetManager: Starting task 127.0 in stage 0.0 (TID 129, 192.168.33.11, executor 5, partition 127, ANY, 4879 bytes)
18/09/26 10:49:09 INFO TaskSetManager: Finished task 91.0 in stage 0.0 (TID 91) in 17789 ms on 192.168.33.11 (executor 5) (48/409)
18/09/26 10:49:09 INFO TaskSetManager: Starting task 128.0 in stage 0.0 (TID 130, 192.168.33.12, executor 3, partition 128, ANY, 4879 bytes)
18/09/26 10:49:09 INFO TaskSetManager: Finished task 102.0 in stage 0.0 (TID 102) in 16974 ms on 192.168.33.12 (executor 3) (49/409)
18/09/26 10:49:09 INFO TaskSetManager: Starting task 129.0 in stage 0.0 (TID 131, 192.168.33.11, executor 5, partition 129, ANY, 4879 bytes)
18/09/26 10:49:09 INFO TaskSetManager: Finished task 104.0 in stage 0.0 (TID 104) in 16870 ms on 192.168.33.11 (executor 5) (50/409)
18/09/26 10:49:10 INFO TaskSetManager: Starting task 130.0 in stage 0.0 (TID 132, 192.168.33.12, executor 3, partition 130, ANY, 4879 bytes)
18/09/26 10:49:10 INFO TaskSetManager: Finished task 95.0 in stage 0.0 (TID 95) in 18423 ms on 192.168.33.12 (executor 3) (51/409)
18/09/26 10:49:10 INFO TaskSetManager: Starting task 131.0 in stage 0.0 (TID 133, 192.168.33.11, executor 5, partition 131, ANY, 4879 bytes)
18/09/26 10:49:10 INFO TaskSetManager: Finished task 90.0 in stage 0.0 (TID 90) in 19052 ms on 192.168.33.11 (executor 5) (52/409)
18/09/26 10:49:10 INFO TaskSetManager: Starting task 132.0 in stage 0.0 (TID 134, 192.168.33.11, executor 5, partition 132, ANY, 4879 bytes)
18/09/26 10:49:10 INFO TaskSetManager: Finished task 93.0 in stage 0.0 (TID 93) in 18845 ms on 192.168.33.11 (executor 5) (53/409)
18/09/26 10:49:11 INFO TaskSetManager: Starting task 133.0 in stage 0.0 (TID 135, 192.168.33.12, executor 3, partition 133, ANY, 4879 bytes)
18/09/26 10:49:11 INFO TaskSetManager: Finished task 101.0 in stage 0.0 (TID 101) in 18709 ms on 192.168.33.12 (executor 3) (54/409)
18/09/26 10:49:11 INFO TaskSetManager: Starting task 134.0 in stage 0.0 (TID 136, 192.168.33.15, executor 0, partition 134, ANY, 4879 bytes)
18/09/26 10:49:11 INFO TaskSetManager: Finished task 69.0 in stage 0.0 (TID 69) in 47363 ms on 192.168.33.15 (executor 0) (55/409)
18/09/26 10:49:11 INFO TaskSetManager: Starting task 135.0 in stage 0.0 (TID 137, 192.168.33.11, executor 5, partition 135, ANY, 4879 bytes)
18/09/26 10:49:11 INFO TaskSetManager: Finished task 87.0 in stage 0.0 (TID 87) in 20525 ms on 192.168.33.11 (executor 5) (56/409)
18/09/26 10:49:12 INFO TaskSetManager: Starting task 136.0 in stage 0.0 (TID 138, 192.168.33.15, executor 0, partition 136, ANY, 4879 bytes)
18/09/26 10:49:12 INFO TaskSetManager: Finished task 67.0 in stage 0.0 (TID 67) in 48471 ms on 192.168.33.15 (executor 0) (57/409)
18/09/26 10:49:12 INFO TaskSetManager: Starting task 137.0 in stage 0.0 (TID 139, 192.168.33.14, executor 4, partition 137, ANY, 4879 bytes)
18/09/26 10:49:12 INFO TaskSetManager: Finished task 112.0 in stage 0.0 (TID 112) in 15904 ms on 192.168.33.14 (executor 4) (58/409)
18/09/26 10:49:12 INFO TaskSetManager: Starting task 138.0 in stage 0.0 (TID 140, 192.168.33.13, executor 2, partition 138, ANY, 4879 bytes)
18/09/26 10:49:12 INFO TaskSetManager: Finished task 103.0 in stage 0.0 (TID 103) in 19956 ms on 192.168.33.13 (executor 2) (59/409)
18/09/26 10:49:13 INFO TaskSetManager: Starting task 139.0 in stage 0.0 (TID 141, 192.168.33.15, executor 0, partition 139, ANY, 4879 bytes)
18/09/26 10:49:13 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 49780 ms on 192.168.33.15 (executor 0) (60/409)
18/09/26 10:49:13 INFO TaskSetManager: Starting task 140.0 in stage 0.0 (TID 142, 192.168.33.10, executor 1, partition 140, ANY, 4879 bytes)
18/09/26 10:49:13 INFO TaskSetManager: Finished task 64.0 in stage 0.0 (TID 64) in 50103 ms on 192.168.33.10 (executor 1) (61/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 141.0 in stage 0.0 (TID 143, 192.168.33.15, executor 0, partition 141, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 65.0 in stage 0.0 (TID 65) in 50334 ms on 192.168.33.15 (executor 0) (62/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 142.0 in stage 0.0 (TID 144, 192.168.33.10, executor 1, partition 142, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 50482 ms on 192.168.33.10 (executor 1) (63/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 143.0 in stage 0.0 (TID 145, 192.168.33.15, executor 0, partition 143, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 55.0 in stage 0.0 (TID 55) in 50643 ms on 192.168.33.15 (executor 0) (64/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 144.0 in stage 0.0 (TID 146, 192.168.33.13, executor 2, partition 144, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 111.0 in stage 0.0 (TID 111) in 19449 ms on 192.168.33.13 (executor 2) (65/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 145.0 in stage 0.0 (TID 147, 192.168.33.13, executor 2, partition 145, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 105.0 in stage 0.0 (TID 105) in 20917 ms on 192.168.33.13 (executor 2) (66/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 146.0 in stage 0.0 (TID 148, 192.168.33.15, executor 0, partition 146, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 50777 ms on 192.168.33.15 (executor 0) (67/409)
18/09/26 10:49:14 INFO TaskSetManager: Starting task 147.0 in stage 0.0 (TID 149, 192.168.33.13, executor 2, partition 147, ANY, 4879 bytes)
18/09/26 10:49:14 INFO TaskSetManager: Finished task 108.0 in stage 0.0 (TID 108) in 20294 ms on 192.168.33.13 (executor 2) (68/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 148.0 in stage 0.0 (TID 150, 192.168.33.15, executor 0, partition 148, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 57.0 in stage 0.0 (TID 57) in 51320 ms on 192.168.33.15 (executor 0) (69/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 149.0 in stage 0.0 (TID 151, 192.168.33.15, executor 0, partition 149, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 51340 ms on 192.168.33.15 (executor 0) (70/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 150.0 in stage 0.0 (TID 152, 192.168.33.12, executor 3, partition 150, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Lost task 92.2 in stage 0.0 (TID 120) on 192.168.33.12, executor 3: java.lang.NumberFormatException (For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc") [duplicate 1]
18/09/26 10:49:15 INFO TaskSetManager: Starting task 92.3 in stage 0.0 (TID 153, 192.168.33.13, executor 2, partition 92, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 109.0 in stage 0.0 (TID 109) in 20633 ms on 192.168.33.13 (executor 2) (71/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 151.0 in stage 0.0 (TID 154, 192.168.33.13, executor 2, partition 151, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 106.0 in stage 0.0 (TID 106) in 21604 ms on 192.168.33.13 (executor 2) (72/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 152.0 in stage 0.0 (TID 155, 192.168.33.13, executor 2, partition 152, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 110.0 in stage 0.0 (TID 110) in 20832 ms on 192.168.33.13 (executor 2) (73/409)
18/09/26 10:49:15 INFO TaskSetManager: Starting task 153.0 in stage 0.0 (TID 156, 192.168.33.13, executor 2, partition 153, ANY, 4879 bytes)
18/09/26 10:49:15 INFO TaskSetManager: Finished task 107.0 in stage 0.0 (TID 107) in 21599 ms on 192.168.33.13 (executor 2) (74/409)
18/09/26 10:49:16 INFO TaskSetManager: Starting task 154.0 in stage 0.0 (TID 157, 192.168.33.10, executor 1, partition 154, ANY, 4879 bytes)
18/09/26 10:49:16 INFO TaskSetManager: Finished task 60.0 in stage 0.0 (TID 60) in 52384 ms on 192.168.33.10 (executor 1) (75/409)
18/09/26 10:49:16 INFO TaskSetManager: Starting task 155.0 in stage 0.0 (TID 158, 192.168.33.10, executor 1, partition 155, ANY, 4879 bytes)
18/09/26 10:49:16 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 52957 ms on 192.168.33.10 (executor 1) (76/409)
18/09/26 10:49:17 INFO TaskSetManager: Starting task 156.0 in stage 0.0 (TID 159, 192.168.33.10, executor 1, partition 156, ANY, 4879 bytes)
18/09/26 10:49:17 INFO TaskSetManager: Finished task 56.0 in stage 0.0 (TID 56) in 53343 ms on 192.168.33.10 (executor 1) (77/409)
18/09/26 10:49:17 INFO TaskSetManager: Starting task 157.0 in stage 0.0 (TID 160, 192.168.33.10, executor 1, partition 157, ANY, 4879 bytes)
18/09/26 10:49:17 INFO TaskSetManager: Finished task 54.0 in stage 0.0 (TID 54) in 53722 ms on 192.168.33.10 (executor 1) (78/409)
18/09/26 10:49:17 INFO TaskSetManager: Starting task 158.0 in stage 0.0 (TID 161, 192.168.33.15, executor 0, partition 158, ANY, 4879 bytes)
18/09/26 10:49:17 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 53879 ms on 192.168.33.15 (executor 0) (79/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 159.0 in stage 0.0 (TID 162, 192.168.33.15, executor 0, partition 159, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 75.0 in stage 0.0 (TID 75) in 54275 ms on 192.168.33.15 (executor 0) (80/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 160.0 in stage 0.0 (TID 163, 192.168.33.15, executor 0, partition 160, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 54301 ms on 192.168.33.15 (executor 0) (81/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 161.0 in stage 0.0 (TID 164, 192.168.33.15, executor 0, partition 161, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 54336 ms on 192.168.33.15 (executor 0) (82/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 162.0 in stage 0.0 (TID 165, 192.168.33.10, executor 1, partition 162, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 54428 ms on 192.168.33.10 (executor 1) (83/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 163.0 in stage 0.0 (TID 166, 192.168.33.15, executor 0, partition 163, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 77.0 in stage 0.0 (TID 77) in 54569 ms on 192.168.33.15 (executor 0) (84/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 164.0 in stage 0.0 (TID 167, 192.168.33.10, executor 1, partition 164, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 68.0 in stage 0.0 (TID 68) in 54827 ms on 192.168.33.10 (executor 1) (85/409)
18/09/26 10:49:18 INFO TaskSetManager: Starting task 165.0 in stage 0.0 (TID 168, 192.168.33.10, executor 1, partition 165, ANY, 4879 bytes)
18/09/26 10:49:18 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 55008 ms on 192.168.33.10 (executor 1) (86/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 166.0 in stage 0.0 (TID 169, 192.168.33.10, executor 1, partition 166, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 78.0 in stage 0.0 (TID 78) in 55184 ms on 192.168.33.10 (executor 1) (87/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 167.0 in stage 0.0 (TID 170, 192.168.33.15, executor 0, partition 167, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 53.0 in stage 0.0 (TID 53) in 55640 ms on 192.168.33.15 (executor 0) (88/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 168.0 in stage 0.0 (TID 171, 192.168.33.15, executor 0, partition 168, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 59.0 in stage 0.0 (TID 59) in 55661 ms on 192.168.33.15 (executor 0) (89/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 169.0 in stage 0.0 (TID 172, 192.168.33.15, executor 0, partition 169, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 71.0 in stage 0.0 (TID 71) in 55662 ms on 192.168.33.15 (executor 0) (90/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 170.0 in stage 0.0 (TID 173, 192.168.33.10, executor 1, partition 170, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 58.0 in stage 0.0 (TID 58) in 55810 ms on 192.168.33.10 (executor 1) (91/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 171.0 in stage 0.0 (TID 174, 192.168.33.15, executor 0, partition 171, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 61.0 in stage 0.0 (TID 61) in 55974 ms on 192.168.33.15 (executor 0) (92/409)
18/09/26 10:49:19 INFO TaskSetManager: Starting task 172.0 in stage 0.0 (TID 175, 192.168.33.15, executor 0, partition 172, ANY, 4879 bytes)
18/09/26 10:49:19 INFO TaskSetManager: Finished task 63.0 in stage 0.0 (TID 63) in 56023 ms on 192.168.33.15 (executor 0) (93/409)
18/09/26 10:49:20 INFO TaskSetManager: Starting task 173.0 in stage 0.0 (TID 176, 192.168.33.10, executor 1, partition 173, ANY, 4879 bytes)
18/09/26 10:49:20 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 56335 ms on 192.168.33.10 (executor 1) (94/409)
18/09/26 10:49:20 INFO TaskSetManager: Starting task 174.0 in stage 0.0 (TID 177, 192.168.33.15, executor 0, partition 174, ANY, 4879 bytes)
18/09/26 10:49:20 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 56471 ms on 192.168.33.15 (executor 0) (95/409)
18/09/26 10:49:20 INFO TaskSetManager: Starting task 175.0 in stage 0.0 (TID 178, 192.168.33.15, executor 0, partition 175, ANY, 4879 bytes)
18/09/26 10:49:20 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 56866 ms on 192.168.33.15 (executor 0) (96/409)
18/09/26 10:49:20 INFO TaskSetManager: Starting task 176.0 in stage 0.0 (TID 179, 192.168.33.10, executor 1, partition 176, ANY, 4879 bytes)
18/09/26 10:49:20 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 56990 ms on 192.168.33.10 (executor 1) (97/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 177.0 in stage 0.0 (TID 180, 192.168.33.10, executor 1, partition 177, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 57199 ms on 192.168.33.10 (executor 1) (98/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 178.0 in stage 0.0 (TID 181, 192.168.33.14, executor 4, partition 178, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 113.0 in stage 0.0 (TID 114) in 15970 ms on 192.168.33.14 (executor 4) (99/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 179.0 in stage 0.0 (TID 182, 192.168.33.15, executor 0, partition 179, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 73.0 in stage 0.0 (TID 73) in 57409 ms on 192.168.33.15 (executor 0) (100/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 180.0 in stage 0.0 (TID 183, 192.168.33.14, executor 4, partition 180, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 117.0 in stage 0.0 (TID 118) in 14028 ms on 192.168.33.14 (executor 4) (101/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 181.0 in stage 0.0 (TID 184, 192.168.33.10, executor 1, partition 181, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 72.0 in stage 0.0 (TID 72) in 57666 ms on 192.168.33.10 (executor 1) (102/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 182.0 in stage 0.0 (TID 185, 192.168.33.10, executor 1, partition 182, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 70.0 in stage 0.0 (TID 70) in 57835 ms on 192.168.33.10 (executor 1) (103/409)
18/09/26 10:49:21 INFO TaskSetManager: Starting task 183.0 in stage 0.0 (TID 186, 192.168.33.10, executor 1, partition 183, ANY, 4879 bytes)
18/09/26 10:49:21 INFO TaskSetManager: Finished task 62.0 in stage 0.0 (TID 62) in 58074 ms on 192.168.33.10 (executor 1) (104/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 184.0 in stage 0.0 (TID 187, 192.168.33.10, executor 1, partition 184, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 58235 ms on 192.168.33.10 (executor 1) (105/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 185.0 in stage 0.0 (TID 188, 192.168.33.10, executor 1, partition 185, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 74.0 in stage 0.0 (TID 74) in 58277 ms on 192.168.33.10 (executor 1) (106/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 186.0 in stage 0.0 (TID 189, 192.168.33.15, executor 0, partition 186, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 58656 ms on 192.168.33.15 (executor 0) (107/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 187.0 in stage 0.0 (TID 190, 192.168.33.10, executor 1, partition 187, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 58691 ms on 192.168.33.10 (executor 1) (108/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 188.0 in stage 0.0 (TID 191, 192.168.33.15, executor 0, partition 188, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 79.0 in stage 0.0 (TID 79) in 58677 ms on 192.168.33.15 (executor 0) (109/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 189.0 in stage 0.0 (TID 192, 192.168.33.10, executor 1, partition 189, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 58882 ms on 192.168.33.10 (executor 1) (110/409)
18/09/26 10:49:22 INFO TaskSetManager: Starting task 190.0 in stage 0.0 (TID 193, 192.168.33.10, executor 1, partition 190, ANY, 4879 bytes)
18/09/26 10:49:22 INFO TaskSetManager: Finished task 76.0 in stage 0.0 (TID 76) in 59066 ms on 192.168.33.10 (executor 1) (111/409)
18/09/26 10:49:23 INFO TaskSetManager: Starting task 191.0 in stage 0.0 (TID 194, 192.168.33.13, executor 2, partition 191, ANY, 4879 bytes)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 92.3 in stage 0.0 (TID 153, 192.168.33.13, executor 2): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:49:23 ERROR TaskSetManager: Task 92 in stage 0.0 failed 4 times; aborting job
18/09/26 10:49:23 INFO TaskSchedulerImpl: Cancelling stage 0
18/09/26 10:49:23 INFO TaskSchedulerImpl: Stage 0 was cancelled
18/09/26 10:49:23 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) failed in 59,373 s due to Job aborted due to stage failure: Task 92 in stage 0.0 failed 4 times, most recent failure: Lost task 92.3 in stage 0.0 (TID 153, 192.168.33.13, executor 2): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
18/09/26 10:49:23 WARN TaskSetManager: Lost task 180.0 in stage 0.0 (TID 183, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 178.0 in stage 0.0 (TID 181, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 191.0 in stage 0.0 (TID 194, 192.168.33.13, executor 2): TaskKilled (stage cancelled)
18/09/26 10:49:23 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 59,585763 s
18/09/26 10:49:23 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 10:49:23 WARN TaskSetManager: Lost task 159.0 in stage 0.0 (TID 162, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 160.0 in stage 0.0 (TID 163, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 179.0 in stage 0.0 (TID 182, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 158.0 in stage 0.0 (TID 161, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 172.0 in stage 0.0 (TID 175, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 186.0 in stage 0.0 (TID 189, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 175.0 in stage 0.0 (TID 178, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 139.0 in stage 0.0 (TID 141, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 163.0 in stage 0.0 (TID 166, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 10:49:23 WARN TaskSetManager: Lost task 161.0 in stage 0.0 (TID 164, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 167.0 in stage 0.0 (TID 170, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 183.0 in stage 0.0 (TID 186, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 187.0 in stage 0.0 (TID 190, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 182.0 in stage 0.0 (TID 185, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 190.0 in stage 0.0 (TID 193, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 155.0 in stage 0.0 (TID 158, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 189.0 in stage 0.0 (TID 192, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 169.0 in stage 0.0 (TID 172, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 176.0 in stage 0.0 (TID 179, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 184.0 in stage 0.0 (TID 187, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 142.0 in stage 0.0 (TID 144, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 162.0 in stage 0.0 (TID 165, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 166.0 in stage 0.0 (TID 169, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 141.0 in stage 0.0 (TID 143, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 37.0 in stage 0.0 (TID 37, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 181.0 in stage 0.0 (TID 184, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 140.0 in stage 0.0 (TID 142, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 174.0 in stage 0.0 (TID 177, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 148.0 in stage 0.0 (TID 150, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 170.0 in stage 0.0 (TID 173, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 146.0 in stage 0.0 (TID 148, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 165.0 in stage 0.0 (TID 168, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 143.0 in stage 0.0 (TID 145, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 168.0 in stage 0.0 (TID 171, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 154.0 in stage 0.0 (TID 157, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 171.0 in stage 0.0 (TID 174, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 164.0 in stage 0.0 (TID 167, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 156.0 in stage 0.0 (TID 159, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 185.0 in stage 0.0 (TID 188, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 177.0 in stage 0.0 (TID 180, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 157.0 in stage 0.0 (TID 160, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 173.0 in stage 0.0 (TID 176, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:49:23 WARN TaskSetManager: Lost task 188.0 in stage 0.0 (TID 191, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:49:23 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 10:49:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 10:49:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 10:49:23 INFO MemoryStore: MemoryStore cleared
18/09/26 10:49:23 INFO BlockManager: BlockManager stopped
18/09/26 10:49:23 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 10:49:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 10:49:23 INFO SparkContext: Successfully stopped SparkContext
18/09/26 10:49:23 INFO ShutdownHookManager: Shutdown hook called
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-589bbbdb-5c4e-4cb7-94c7-f5d96f0dbb6e
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-d2af6745-091f-415b-99b8-9eef10520d52
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-15257ae5-f187-434a-83c4-bd0406d159e8
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-5bd26154-9455-445a-adde-7c0d7063e65c
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-df025daf-91e4-45b8-b2c8-aa83b06b921b
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-f522f795-e7ef-4aa5-b20a-fbf808785b41
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-9c1c0b8f-9909-4901-bc1e-1a8217b9c988
18/09/26 10:49:23 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-3a2c7def-24f1-4daa-986a-ae149c830143
18/09/26 10:51:16 INFO SparkContext: Running Spark version 2.2.1
18/09/26 10:51:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 10:51:17 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 10:51:17 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 10:51:17 INFO SecurityManager: Changing view acls to: redouane
18/09/26 10:51:17 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 10:51:17 INFO SecurityManager: Changing view acls groups to: 
18/09/26 10:51:17 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 10:51:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 10:51:17 INFO Utils: Successfully started service 'sparkDriver' on port 44916.
18/09/26 10:51:17 INFO SparkEnv: Registering MapOutputTracker
18/09/26 10:51:17 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 10:51:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 10:51:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-71a777a8-554a-4713-96e0-8e9cdc84a888
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-22af0926-f818-4d80-bce7-ebf4b14e84cf
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-eab7ced9-afaf-4823-b0ed-7089891de320
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-cbfbcfff-42ea-44fb-96a8-e2aa761f300d
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-cee9e566-06f6-4e00-94cc-8fe2e7b667cd
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-99710a53-e8b5-489b-bdc8-00cce371c12e
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-97fb3010-7d27-4335-8221-995520652ff1
18/09/26 10:51:17 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-bf824838-ee80-44f7-8eab-53f5b390635e
18/09/26 10:51:17 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 10:51:17 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 10:51:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 10:51:17 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 10:51:18 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:44916/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537951878023
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 10:51:18 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 26 ms (0 ms spent in bootstraps)
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926105118-0004
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43799.
18/09/26 10:51:18 INFO NettyBlockTransferService: Server created on 192.168.33.10:43799
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926105118-0004/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/26 10:51:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926105118-0004/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/26 10:51:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 10:51:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 43799, None)
18/09/26 10:51:18 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:43799 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 43799, None)
18/09/26 10:51:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 43799, None)
18/09/26 10:51:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 43799, None)
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/1 is now RUNNING
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/0 is now RUNNING
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/5 is now RUNNING
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/2 is now RUNNING
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/3 is now RUNNING
18/09/26 10:51:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926105118-0004/4 is now RUNNING
18/09/26 10:51:19 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926105118-0004
18/09/26 10:51:19 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 10:51:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 10:51:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 10:51:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:43799 (size: 27.9 KB, free: 366.3 MB)
18/09/26 10:51:19 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 10:51:20 INFO FileInputFormat: Total input files to process : 409
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:59244) with ID 3
18/09/26 10:51:20 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:52112) with ID 2
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/26 10:51:20 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:58794) with ID 5
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:36150) with ID 0
18/09/26 10:51:20 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:50800) with ID 4
18/09/26 10:51:20 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/26 10:51:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:33114 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.12, 33114, None)
18/09/26 10:51:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:37858 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.13, 37858, None)
18/09/26 10:51:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:36584 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.11, 36584, None)
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:42005 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 42005, None)
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:46645 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.14, 46645, None)
18/09/26 10:51:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/26 10:51:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 10:51:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:43799 (size: 2.5 KB, free: 366.3 MB)
18/09/26 10:51:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/26 10:51:20 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 10:51:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:47910) with ID 1
18/09/26 10:51:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/26 10:51:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.10, executor 1, partition 0, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.15, executor 0, partition 1, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.14, executor 4, partition 2, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.13, executor 2, partition 3, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.12, executor 3, partition 4, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.11, executor 5, partition 5, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.10, executor 1, partition 6, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.15, executor 0, partition 7, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.14, executor 4, partition 8, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.13, executor 2, partition 9, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.12, executor 3, partition 10, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.11, executor 5, partition 11, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.10, executor 1, partition 12, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.15, executor 0, partition 13, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.14, executor 4, partition 14, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.13, executor 2, partition 15, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.12, executor 3, partition 16, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.11, executor 5, partition 17, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.10, executor 1, partition 18, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.15, executor 0, partition 19, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.14, executor 4, partition 20, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.13, executor 2, partition 21, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.12, executor 3, partition 22, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.11, executor 5, partition 23, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.10, executor 1, partition 24, ANY, 4879 bytes)
18/09/26 10:51:20 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:40578 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 40578, None)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.15, executor 0, partition 25, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.14, executor 4, partition 26, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.13, executor 2, partition 27, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.12, executor 3, partition 28, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.11, executor 5, partition 29, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.10, executor 1, partition 30, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.15, executor 0, partition 31, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.14, executor 4, partition 32, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.13, executor 2, partition 33, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.12, executor 3, partition 34, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.11, executor 5, partition 35, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.10, executor 1, partition 36, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.15, executor 0, partition 37, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.14, executor 4, partition 38, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.13, executor 2, partition 39, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.12, executor 3, partition 40, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.11, executor 5, partition 41, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.10, executor 1, partition 42, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.15, executor 0, partition 43, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.14, executor 4, partition 44, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.13, executor 2, partition 45, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.12, executor 3, partition 46, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.11, executor 5, partition 47, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, 192.168.33.10, executor 1, partition 48, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, 192.168.33.15, executor 0, partition 49, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50, 192.168.33.10, executor 1, partition 50, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51, 192.168.33.15, executor 0, partition 51, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52, 192.168.33.10, executor 1, partition 52, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53, 192.168.33.15, executor 0, partition 53, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54, 192.168.33.10, executor 1, partition 54, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55, 192.168.33.15, executor 0, partition 55, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56, 192.168.33.10, executor 1, partition 56, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57, 192.168.33.15, executor 0, partition 57, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58, 192.168.33.10, executor 1, partition 58, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59, 192.168.33.15, executor 0, partition 59, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60, 192.168.33.10, executor 1, partition 60, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61, 192.168.33.15, executor 0, partition 61, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62, 192.168.33.10, executor 1, partition 62, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63, 192.168.33.15, executor 0, partition 63, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64, 192.168.33.10, executor 1, partition 64, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65, 192.168.33.15, executor 0, partition 65, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66, 192.168.33.10, executor 1, partition 66, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67, 192.168.33.15, executor 0, partition 67, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68, 192.168.33.10, executor 1, partition 68, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69, 192.168.33.15, executor 0, partition 69, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70, 192.168.33.10, executor 1, partition 70, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71, 192.168.33.15, executor 0, partition 71, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72, 192.168.33.10, executor 1, partition 72, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73, 192.168.33.15, executor 0, partition 73, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74, 192.168.33.10, executor 1, partition 74, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75, 192.168.33.15, executor 0, partition 75, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76, 192.168.33.10, executor 1, partition 76, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77, 192.168.33.15, executor 0, partition 77, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78, 192.168.33.10, executor 1, partition 78, ANY, 4879 bytes)
18/09/26 10:51:20 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79, 192.168.33.15, executor 0, partition 79, ANY, 4879 bytes)
18/09/26 10:51:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:40578 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:40578 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:46645 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:46645 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.11:36584 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.11:36584 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:33114 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:33114 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.13:37858 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.13:37858 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.15:42005 (size: 2.5 KB, free: 15.8 GB)
18/09/26 10:51:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.15:42005 (size: 27.9 KB, free: 15.8 GB)
18/09/26 10:51:45 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80, 192.168.33.13, executor 2, partition 80, ANY, 4879 bytes)
18/09/26 10:51:45 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 24273 ms on 192.168.33.13 (executor 2) (1/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 81.0 in stage 0.0 (TID 81, 192.168.33.13, executor 2, partition 81, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 25245 ms on 192.168.33.13 (executor 2) (2/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 82.0 in stage 0.0 (TID 82, 192.168.33.13, executor 2, partition 82, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 25350 ms on 192.168.33.13 (executor 2) (3/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 83.0 in stage 0.0 (TID 83, 192.168.33.14, executor 4, partition 83, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 25639 ms on 192.168.33.14 (executor 4) (4/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 84.0 in stage 0.0 (TID 84, 192.168.33.12, executor 3, partition 84, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 25697 ms on 192.168.33.12 (executor 3) (5/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 85.0 in stage 0.0 (TID 85, 192.168.33.12, executor 3, partition 85, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 25725 ms on 192.168.33.12 (executor 3) (6/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 86.0 in stage 0.0 (TID 86, 192.168.33.13, executor 2, partition 86, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 25779 ms on 192.168.33.13 (executor 2) (7/409)
18/09/26 10:51:46 INFO TaskSetManager: Starting task 87.0 in stage 0.0 (TID 87, 192.168.33.13, executor 2, partition 87, ANY, 4879 bytes)
18/09/26 10:51:46 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 25982 ms on 192.168.33.13 (executor 2) (8/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 88.0 in stage 0.0 (TID 88, 192.168.33.14, executor 4, partition 88, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 26339 ms on 192.168.33.14 (executor 4) (9/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 89.0 in stage 0.0 (TID 89, 192.168.33.14, executor 4, partition 89, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 26464 ms on 192.168.33.14 (executor 4) (10/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 90.0 in stage 0.0 (TID 90, 192.168.33.13, executor 2, partition 90, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 26721 ms on 192.168.33.13 (executor 2) (11/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 91.0 in stage 0.0 (TID 91, 192.168.33.13, executor 2, partition 91, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 26760 ms on 192.168.33.13 (executor 2) (12/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 92.0 in stage 0.0 (TID 92, 192.168.33.11, executor 5, partition 92, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 93.0 in stage 0.0 (TID 93, 192.168.33.12, executor 3, partition 93, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 27176 ms on 192.168.33.11 (executor 5) (13/409)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 27179 ms on 192.168.33.12 (executor 3) (14/409)
18/09/26 10:51:47 INFO TaskSetManager: Starting task 94.0 in stage 0.0 (TID 94, 192.168.33.14, executor 4, partition 94, ANY, 4879 bytes)
18/09/26 10:51:47 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 27202 ms on 192.168.33.14 (executor 4) (15/409)
18/09/26 10:51:48 INFO TaskSetManager: Starting task 95.0 in stage 0.0 (TID 95, 192.168.33.14, executor 4, partition 95, ANY, 4879 bytes)
18/09/26 10:51:48 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 27376 ms on 192.168.33.14 (executor 4) (16/409)
18/09/26 10:51:48 INFO TaskSetManager: Starting task 96.0 in stage 0.0 (TID 96, 192.168.33.13, executor 2, partition 96, ANY, 4879 bytes)
18/09/26 10:51:48 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 27516 ms on 192.168.33.13 (executor 2) (17/409)
18/09/26 10:51:48 INFO TaskSetManager: Starting task 97.0 in stage 0.0 (TID 97, 192.168.33.14, executor 4, partition 97, ANY, 4879 bytes)
18/09/26 10:51:48 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 27843 ms on 192.168.33.14 (executor 4) (18/409)
18/09/26 10:51:48 INFO TaskSetManager: Starting task 98.0 in stage 0.0 (TID 98, 192.168.33.12, executor 3, partition 98, ANY, 4879 bytes)
18/09/26 10:51:48 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 27909 ms on 192.168.33.12 (executor 3) (19/409)
18/09/26 10:51:48 INFO TaskSetManager: Starting task 99.0 in stage 0.0 (TID 99, 192.168.33.11, executor 5, partition 99, ANY, 4879 bytes)
18/09/26 10:51:48 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 28131 ms on 192.168.33.11 (executor 5) (20/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 100.0 in stage 0.0 (TID 100, 192.168.33.12, executor 3, partition 100, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 28315 ms on 192.168.33.12 (executor 3) (21/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 101.0 in stage 0.0 (TID 101, 192.168.33.14, executor 4, partition 101, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 28400 ms on 192.168.33.14 (executor 4) (22/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 102.0 in stage 0.0 (TID 102, 192.168.33.11, executor 5, partition 102, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 28548 ms on 192.168.33.11 (executor 5) (23/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 103.0 in stage 0.0 (TID 103, 192.168.33.14, executor 4, partition 103, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 28822 ms on 192.168.33.14 (executor 4) (24/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 104.0 in stage 0.0 (TID 104, 192.168.33.11, executor 5, partition 104, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 28916 ms on 192.168.33.11 (executor 5) (25/409)
18/09/26 10:51:49 INFO TaskSetManager: Starting task 105.0 in stage 0.0 (TID 105, 192.168.33.12, executor 3, partition 105, ANY, 4879 bytes)
18/09/26 10:51:49 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 29150 ms on 192.168.33.12 (executor 3) (26/409)
18/09/26 10:51:50 INFO TaskSetManager: Starting task 106.0 in stage 0.0 (TID 106, 192.168.33.11, executor 5, partition 106, ANY, 4879 bytes)
18/09/26 10:51:50 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 29309 ms on 192.168.33.11 (executor 5) (27/409)
18/09/26 10:51:50 INFO TaskSetManager: Starting task 107.0 in stage 0.0 (TID 107, 192.168.33.12, executor 3, partition 107, ANY, 4879 bytes)
18/09/26 10:51:50 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 29295 ms on 192.168.33.12 (executor 3) (28/409)
18/09/26 10:51:50 INFO TaskSetManager: Starting task 108.0 in stage 0.0 (TID 108, 192.168.33.11, executor 5, partition 108, ANY, 4879 bytes)
18/09/26 10:51:50 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 29435 ms on 192.168.33.11 (executor 5) (29/409)
18/09/26 10:51:50 INFO TaskSetManager: Starting task 109.0 in stage 0.0 (TID 109, 192.168.33.11, executor 5, partition 109, ANY, 4879 bytes)
18/09/26 10:51:50 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 29976 ms on 192.168.33.11 (executor 5) (30/409)
18/09/26 10:51:51 INFO TaskSetManager: Starting task 110.0 in stage 0.0 (TID 110, 192.168.33.12, executor 3, partition 110, ANY, 4879 bytes)
18/09/26 10:51:51 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 30391 ms on 192.168.33.12 (executor 3) (31/409)
18/09/26 10:51:51 INFO TaskSetManager: Starting task 111.0 in stage 0.0 (TID 111, 192.168.33.11, executor 5, partition 111, ANY, 4879 bytes)
18/09/26 10:51:51 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 30769 ms on 192.168.33.11 (executor 5) (32/409)
18/09/26 10:51:54 INFO TaskSetManager: Starting task 112.0 in stage 0.0 (TID 112, 192.168.33.11, executor 5, partition 112, ANY, 4879 bytes)
18/09/26 10:51:54 WARN TaskSetManager: Lost task 92.0 in stage 0.0 (TID 92, 192.168.33.11, executor 5): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:51:54 INFO TaskSetManager: Starting task 92.1 in stage 0.0 (TID 113, 192.168.33.10, executor 1, partition 92, ANY, 4879 bytes)
18/09/26 10:51:54 INFO TaskSetManager: Finished task 60.0 in stage 0.0 (TID 60) in 34024 ms on 192.168.33.10 (executor 1) (33/409)
18/09/26 10:51:56 INFO TaskSetManager: Starting task 113.0 in stage 0.0 (TID 114, 192.168.33.10, executor 1, partition 113, ANY, 4879 bytes)
18/09/26 10:51:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 35386 ms on 192.168.33.10 (executor 1) (34/409)
18/09/26 10:51:56 INFO TaskSetManager: Starting task 114.0 in stage 0.0 (TID 115, 192.168.33.10, executor 1, partition 114, ANY, 4879 bytes)
18/09/26 10:51:56 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 35692 ms on 192.168.33.10 (executor 1) (35/409)
18/09/26 10:51:56 INFO TaskSetManager: Starting task 115.0 in stage 0.0 (TID 116, 192.168.33.10, executor 1, partition 115, ANY, 4879 bytes)
18/09/26 10:51:56 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 35936 ms on 192.168.33.10 (executor 1) (36/409)
18/09/26 10:51:56 INFO TaskSetManager: Starting task 116.0 in stage 0.0 (TID 117, 192.168.33.10, executor 1, partition 116, ANY, 4879 bytes)
18/09/26 10:51:56 INFO TaskSetManager: Finished task 56.0 in stage 0.0 (TID 56) in 36081 ms on 192.168.33.10 (executor 1) (37/409)
18/09/26 10:51:57 INFO TaskSetManager: Starting task 117.0 in stage 0.0 (TID 118, 192.168.33.10, executor 1, partition 117, ANY, 4879 bytes)
18/09/26 10:51:57 INFO TaskSetManager: Finished task 54.0 in stage 0.0 (TID 54) in 36298 ms on 192.168.33.10 (executor 1) (38/409)
18/09/26 10:51:57 INFO TaskSetManager: Starting task 118.0 in stage 0.0 (TID 119, 192.168.33.10, executor 1, partition 118, ANY, 4879 bytes)
18/09/26 10:51:57 INFO TaskSetManager: Finished task 76.0 in stage 0.0 (TID 76) in 36638 ms on 192.168.33.10 (executor 1) (39/409)
18/09/26 10:51:57 INFO TaskSetManager: Starting task 119.0 in stage 0.0 (TID 120, 192.168.33.10, executor 1, partition 119, ANY, 4879 bytes)
18/09/26 10:51:57 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 37123 ms on 192.168.33.10 (executor 1) (40/409)
18/09/26 10:51:58 INFO TaskSetManager: Starting task 120.0 in stage 0.0 (TID 121, 192.168.33.10, executor 1, partition 120, ANY, 4879 bytes)
18/09/26 10:51:58 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 37220 ms on 192.168.33.10 (executor 1) (41/409)
18/09/26 10:51:58 INFO TaskSetManager: Starting task 121.0 in stage 0.0 (TID 122, 192.168.33.10, executor 1, partition 121, ANY, 4879 bytes)
18/09/26 10:51:58 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 37477 ms on 192.168.33.10 (executor 1) (42/409)
18/09/26 10:51:58 INFO TaskSetManager: Starting task 122.0 in stage 0.0 (TID 123, 192.168.33.10, executor 1, partition 122, ANY, 4879 bytes)
18/09/26 10:51:58 INFO TaskSetManager: Finished task 64.0 in stage 0.0 (TID 64) in 37680 ms on 192.168.33.10 (executor 1) (43/409)
18/09/26 10:51:58 INFO TaskSetManager: Starting task 123.0 in stage 0.0 (TID 124, 192.168.33.10, executor 1, partition 123, ANY, 4879 bytes)
18/09/26 10:51:58 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 37754 ms on 192.168.33.10 (executor 1) (44/409)
18/09/26 10:51:59 INFO TaskSetManager: Starting task 124.0 in stage 0.0 (TID 125, 192.168.33.10, executor 1, partition 124, ANY, 4879 bytes)
18/09/26 10:51:59 INFO TaskSetManager: Finished task 74.0 in stage 0.0 (TID 74) in 38193 ms on 192.168.33.10 (executor 1) (45/409)
18/09/26 10:51:59 INFO TaskSetManager: Starting task 125.0 in stage 0.0 (TID 126, 192.168.33.10, executor 1, partition 125, ANY, 4879 bytes)
18/09/26 10:51:59 INFO TaskSetManager: Finished task 62.0 in stage 0.0 (TID 62) in 38756 ms on 192.168.33.10 (executor 1) (46/409)
18/09/26 10:51:59 INFO TaskSetManager: Starting task 126.0 in stage 0.0 (TID 127, 192.168.33.10, executor 1, partition 126, ANY, 4879 bytes)
18/09/26 10:51:59 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 38978 ms on 192.168.33.10 (executor 1) (47/409)
18/09/26 10:51:59 INFO TaskSetManager: Starting task 127.0 in stage 0.0 (TID 128, 192.168.33.10, executor 1, partition 127, ANY, 4879 bytes)
18/09/26 10:51:59 INFO TaskSetManager: Finished task 72.0 in stage 0.0 (TID 72) in 39100 ms on 192.168.33.10 (executor 1) (48/409)
18/09/26 10:52:00 INFO TaskSetManager: Starting task 128.0 in stage 0.0 (TID 129, 192.168.33.10, executor 1, partition 128, ANY, 4879 bytes)
18/09/26 10:52:00 INFO TaskSetManager: Finished task 58.0 in stage 0.0 (TID 58) in 39271 ms on 192.168.33.10 (executor 1) (49/409)
18/09/26 10:52:00 INFO TaskSetManager: Starting task 129.0 in stage 0.0 (TID 130, 192.168.33.10, executor 1, partition 129, ANY, 4879 bytes)
18/09/26 10:52:00 INFO TaskSetManager: Finished task 78.0 in stage 0.0 (TID 78) in 39285 ms on 192.168.33.10 (executor 1) (50/409)
18/09/26 10:52:00 INFO TaskSetManager: Starting task 130.0 in stage 0.0 (TID 131, 192.168.33.13, executor 2, partition 130, ANY, 4879 bytes)
18/09/26 10:52:00 INFO TaskSetManager: Finished task 80.0 in stage 0.0 (TID 80) in 15195 ms on 192.168.33.13 (executor 2) (51/409)
18/09/26 10:52:00 INFO TaskSetManager: Starting task 131.0 in stage 0.0 (TID 132, 192.168.33.10, executor 1, partition 131, ANY, 4879 bytes)
18/09/26 10:52:00 INFO TaskSetManager: Finished task 68.0 in stage 0.0 (TID 68) in 39843 ms on 192.168.33.10 (executor 1) (52/409)
18/09/26 10:52:01 INFO TaskSetManager: Starting task 132.0 in stage 0.0 (TID 133, 192.168.33.13, executor 2, partition 132, ANY, 4879 bytes)
18/09/26 10:52:01 INFO TaskSetManager: Finished task 82.0 in stage 0.0 (TID 82) in 14896 ms on 192.168.33.13 (executor 2) (53/409)
18/09/26 10:52:01 INFO TaskSetManager: Starting task 133.0 in stage 0.0 (TID 134, 192.168.33.12, executor 3, partition 133, ANY, 4879 bytes)
18/09/26 10:52:01 INFO TaskSetManager: Finished task 84.0 in stage 0.0 (TID 84) in 14888 ms on 192.168.33.12 (executor 3) (54/409)
18/09/26 10:52:01 INFO TaskSetManager: Starting task 134.0 in stage 0.0 (TID 135, 192.168.33.10, executor 1, partition 134, ANY, 4879 bytes)
18/09/26 10:52:01 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 40773 ms on 192.168.33.10 (executor 1) (55/409)
18/09/26 10:52:01 INFO TaskSetManager: Starting task 135.0 in stage 0.0 (TID 136, 192.168.33.13, executor 2, partition 135, ANY, 4879 bytes)
18/09/26 10:52:01 INFO TaskSetManager: Finished task 81.0 in stage 0.0 (TID 81) in 15657 ms on 192.168.33.13 (executor 2) (56/409)
18/09/26 10:52:01 INFO TaskSetManager: Starting task 136.0 in stage 0.0 (TID 137, 192.168.33.10, executor 1, partition 136, ANY, 4879 bytes)
18/09/26 10:52:01 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 41055 ms on 192.168.33.10 (executor 1) (57/409)
18/09/26 10:52:02 INFO TaskSetManager: Starting task 137.0 in stage 0.0 (TID 138, 192.168.33.10, executor 1, partition 137, ANY, 4879 bytes)
18/09/26 10:52:02 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 41321 ms on 192.168.33.10 (executor 1) (58/409)
18/09/26 10:52:02 INFO TaskSetManager: Starting task 138.0 in stage 0.0 (TID 139, 192.168.33.10, executor 1, partition 138, ANY, 4879 bytes)
18/09/26 10:52:02 INFO TaskSetManager: Finished task 70.0 in stage 0.0 (TID 70) in 41331 ms on 192.168.33.10 (executor 1) (59/409)
18/09/26 10:52:02 INFO TaskSetManager: Starting task 139.0 in stage 0.0 (TID 140, 192.168.33.10, executor 1, partition 139, ANY, 4879 bytes)
18/09/26 10:52:02 INFO TaskSetManager: Finished task 66.0 in stage 0.0 (TID 66) in 41674 ms on 192.168.33.10 (executor 1) (60/409)
18/09/26 10:52:02 INFO TaskSetManager: Starting task 140.0 in stage 0.0 (TID 141, 192.168.33.12, executor 3, partition 140, ANY, 4879 bytes)
18/09/26 10:52:02 INFO TaskSetManager: Finished task 85.0 in stage 0.0 (TID 85) in 16098 ms on 192.168.33.12 (executor 3) (61/409)
18/09/26 10:52:03 INFO TaskSetManager: Starting task 141.0 in stage 0.0 (TID 142, 192.168.33.13, executor 2, partition 141, ANY, 4879 bytes)
18/09/26 10:52:03 INFO TaskSetManager: Finished task 86.0 in stage 0.0 (TID 86) in 16633 ms on 192.168.33.13 (executor 2) (62/409)
18/09/26 10:52:03 INFO TaskSetManager: Starting task 142.0 in stage 0.0 (TID 143, 192.168.33.13, executor 2, partition 142, ANY, 4879 bytes)
18/09/26 10:52:03 INFO TaskSetManager: Finished task 96.0 in stage 0.0 (TID 96) in 15365 ms on 192.168.33.13 (executor 2) (63/409)
18/09/26 10:52:03 INFO TaskSetManager: Starting task 143.0 in stage 0.0 (TID 144, 192.168.33.13, executor 2, partition 143, ANY, 4879 bytes)
18/09/26 10:52:03 INFO TaskSetManager: Finished task 90.0 in stage 0.0 (TID 90) in 16266 ms on 192.168.33.13 (executor 2) (64/409)
18/09/26 10:52:03 INFO TaskSetManager: Starting task 144.0 in stage 0.0 (TID 145, 192.168.33.13, executor 2, partition 144, ANY, 4879 bytes)
18/09/26 10:52:03 INFO TaskSetManager: Finished task 87.0 in stage 0.0 (TID 87) in 17104 ms on 192.168.33.13 (executor 2) (65/409)
18/09/26 10:52:04 INFO TaskSetManager: Starting task 145.0 in stage 0.0 (TID 146, 192.168.33.12, executor 3, partition 145, ANY, 4879 bytes)
18/09/26 10:52:04 INFO TaskSetManager: Finished task 98.0 in stage 0.0 (TID 98) in 15868 ms on 192.168.33.12 (executor 3) (66/409)
18/09/26 10:52:04 INFO TaskSetManager: Starting task 146.0 in stage 0.0 (TID 147, 192.168.33.12, executor 3, partition 146, ANY, 4879 bytes)
18/09/26 10:52:04 INFO TaskSetManager: Finished task 93.0 in stage 0.0 (TID 93) in 16724 ms on 192.168.33.12 (executor 3) (67/409)
18/09/26 10:52:04 INFO TaskSetManager: Starting task 147.0 in stage 0.0 (TID 148, 192.168.33.14, executor 4, partition 147, ANY, 4879 bytes)
18/09/26 10:52:04 INFO TaskSetManager: Finished task 88.0 in stage 0.0 (TID 88) in 17616 ms on 192.168.33.14 (executor 4) (68/409)
18/09/26 10:52:04 INFO TaskSetManager: Starting task 148.0 in stage 0.0 (TID 149, 192.168.33.12, executor 3, partition 148, ANY, 4879 bytes)
18/09/26 10:52:04 INFO TaskSetManager: Finished task 100.0 in stage 0.0 (TID 100) in 15768 ms on 192.168.33.12 (executor 3) (69/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 149.0 in stage 0.0 (TID 150, 192.168.33.13, executor 2, partition 149, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 91.0 in stage 0.0 (TID 91) in 17550 ms on 192.168.33.13 (executor 2) (70/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 150.0 in stage 0.0 (TID 151, 192.168.33.14, executor 4, partition 150, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 94.0 in stage 0.0 (TID 94) in 17186 ms on 192.168.33.14 (executor 4) (71/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 151.0 in stage 0.0 (TID 152, 192.168.33.12, executor 3, partition 151, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 105.0 in stage 0.0 (TID 105) in 15278 ms on 192.168.33.12 (executor 3) (72/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 152.0 in stage 0.0 (TID 153, 192.168.33.14, executor 4, partition 152, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 83.0 in stage 0.0 (TID 83) in 18966 ms on 192.168.33.14 (executor 4) (73/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 153.0 in stage 0.0 (TID 154, 192.168.33.12, executor 3, partition 153, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 107.0 in stage 0.0 (TID 107) in 15317 ms on 192.168.33.12 (executor 3) (74/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 154.0 in stage 0.0 (TID 155, 192.168.33.12, executor 3, partition 154, ANY, 4879 bytes)
18/09/26 10:52:05 INFO TaskSetManager: Finished task 110.0 in stage 0.0 (TID 110) in 14507 ms on 192.168.33.12 (executor 3) (75/409)
18/09/26 10:52:05 INFO TaskSetManager: Starting task 155.0 in stage 0.0 (TID 156, 192.168.33.10, executor 1, partition 155, ANY, 4879 bytes)
18/09/26 10:52:05 WARN TaskSetManager: Lost task 92.1 in stage 0.0 (TID 113, 192.168.33.10, executor 1): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:52:06 INFO TaskSetManager: Starting task 92.2 in stage 0.0 (TID 157, 192.168.33.11, executor 5, partition 92, ANY, 4879 bytes)
18/09/26 10:52:06 INFO TaskSetManager: Finished task 99.0 in stage 0.0 (TID 99) in 17205 ms on 192.168.33.11 (executor 5) (76/409)
18/09/26 10:52:06 INFO TaskSetManager: Starting task 156.0 in stage 0.0 (TID 158, 192.168.33.14, executor 4, partition 156, ANY, 4879 bytes)
18/09/26 10:52:06 INFO TaskSetManager: Finished task 89.0 in stage 0.0 (TID 89) in 19033 ms on 192.168.33.14 (executor 4) (77/409)
18/09/26 10:52:06 INFO TaskSetManager: Starting task 157.0 in stage 0.0 (TID 159, 192.168.33.14, executor 4, partition 157, ANY, 4879 bytes)
18/09/26 10:52:06 INFO TaskSetManager: Finished task 103.0 in stage 0.0 (TID 103) in 17226 ms on 192.168.33.14 (executor 4) (78/409)
18/09/26 10:52:07 INFO TaskSetManager: Starting task 158.0 in stage 0.0 (TID 160, 192.168.33.14, executor 4, partition 158, ANY, 4879 bytes)
18/09/26 10:52:07 INFO TaskSetManager: Finished task 97.0 in stage 0.0 (TID 97) in 18483 ms on 192.168.33.14 (executor 4) (79/409)
18/09/26 10:52:07 INFO TaskSetManager: Starting task 159.0 in stage 0.0 (TID 161, 192.168.33.11, executor 5, partition 159, ANY, 4879 bytes)
18/09/26 10:52:07 INFO TaskSetManager: Finished task 108.0 in stage 0.0 (TID 108) in 17198 ms on 192.168.33.11 (executor 5) (80/409)
18/09/26 10:52:07 INFO TaskSetManager: Starting task 160.0 in stage 0.0 (TID 162, 192.168.33.14, executor 4, partition 160, ANY, 4879 bytes)
18/09/26 10:52:07 INFO TaskSetManager: Finished task 101.0 in stage 0.0 (TID 101) in 18713 ms on 192.168.33.14 (executor 4) (81/409)
18/09/26 10:52:07 INFO TaskSetManager: Starting task 161.0 in stage 0.0 (TID 163, 192.168.33.14, executor 4, partition 161, ANY, 4879 bytes)
18/09/26 10:52:07 INFO TaskSetManager: Finished task 95.0 in stage 0.0 (TID 95) in 19800 ms on 192.168.33.14 (executor 4) (82/409)
18/09/26 10:52:08 INFO TaskSetManager: Starting task 162.0 in stage 0.0 (TID 164, 192.168.33.11, executor 5, partition 162, ANY, 4879 bytes)
18/09/26 10:52:08 INFO TaskSetManager: Finished task 104.0 in stage 0.0 (TID 104) in 18537 ms on 192.168.33.11 (executor 5) (83/409)
18/09/26 10:52:08 INFO TaskSetManager: Starting task 163.0 in stage 0.0 (TID 165, 192.168.33.11, executor 5, partition 163, ANY, 4879 bytes)
18/09/26 10:52:08 INFO TaskSetManager: Finished task 102.0 in stage 0.0 (TID 102) in 19152 ms on 192.168.33.11 (executor 5) (84/409)
18/09/26 10:52:08 INFO TaskSetManager: Starting task 164.0 in stage 0.0 (TID 166, 192.168.33.15, executor 0, partition 164, ANY, 4879 bytes)
18/09/26 10:52:08 INFO TaskSetManager: Finished task 77.0 in stage 0.0 (TID 77) in 48068 ms on 192.168.33.15 (executor 0) (85/409)
18/09/26 10:52:09 INFO TaskSetManager: Starting task 165.0 in stage 0.0 (TID 167, 192.168.33.11, executor 5, partition 165, ANY, 4879 bytes)
18/09/26 10:52:09 INFO TaskSetManager: Finished task 112.0 in stage 0.0 (TID 112) in 15313 ms on 192.168.33.11 (executor 5) (86/409)
18/09/26 10:52:09 INFO TaskSetManager: Starting task 166.0 in stage 0.0 (TID 168, 192.168.33.11, executor 5, partition 166, ANY, 4879 bytes)
18/09/26 10:52:09 INFO TaskSetManager: Finished task 111.0 in stage 0.0 (TID 111) in 18140 ms on 192.168.33.11 (executor 5) (87/409)
18/09/26 10:52:09 INFO TaskSetManager: Starting task 167.0 in stage 0.0 (TID 169, 192.168.33.11, executor 5, partition 167, ANY, 4879 bytes)
18/09/26 10:52:09 INFO TaskSetManager: Finished task 109.0 in stage 0.0 (TID 109) in 19125 ms on 192.168.33.11 (executor 5) (88/409)
18/09/26 10:52:10 INFO TaskSetManager: Starting task 168.0 in stage 0.0 (TID 170, 192.168.33.11, executor 5, partition 168, ANY, 4879 bytes)
18/09/26 10:52:10 INFO TaskSetManager: Finished task 106.0 in stage 0.0 (TID 106) in 20060 ms on 192.168.33.11 (executor 5) (89/409)
18/09/26 10:52:10 INFO TaskSetManager: Starting task 169.0 in stage 0.0 (TID 171, 192.168.33.15, executor 0, partition 169, ANY, 4879 bytes)
18/09/26 10:52:10 INFO TaskSetManager: Finished task 65.0 in stage 0.0 (TID 65) in 49840 ms on 192.168.33.15 (executor 0) (90/409)
18/09/26 10:52:10 INFO TaskSetManager: Starting task 170.0 in stage 0.0 (TID 172, 192.168.33.15, executor 0, partition 170, ANY, 4879 bytes)
18/09/26 10:52:10 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 49982 ms on 192.168.33.15 (executor 0) (91/409)
18/09/26 10:52:11 INFO TaskSetManager: Starting task 171.0 in stage 0.0 (TID 173, 192.168.33.15, executor 0, partition 171, ANY, 4879 bytes)
18/09/26 10:52:11 INFO TaskSetManager: Finished task 53.0 in stage 0.0 (TID 53) in 50849 ms on 192.168.33.15 (executor 0) (92/409)
18/09/26 10:52:11 INFO TaskSetManager: Starting task 172.0 in stage 0.0 (TID 174, 192.168.33.15, executor 0, partition 172, ANY, 4879 bytes)
18/09/26 10:52:11 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 50899 ms on 192.168.33.15 (executor 0) (93/409)
18/09/26 10:52:12 INFO TaskSetManager: Starting task 173.0 in stage 0.0 (TID 175, 192.168.33.15, executor 0, partition 173, ANY, 4879 bytes)
18/09/26 10:52:12 INFO TaskSetManager: Finished task 69.0 in stage 0.0 (TID 69) in 51241 ms on 192.168.33.15 (executor 0) (94/409)
18/09/26 10:52:12 INFO TaskSetManager: Starting task 174.0 in stage 0.0 (TID 176, 192.168.33.11, executor 5, partition 174, ANY, 4879 bytes)
18/09/26 10:52:12 INFO TaskSetManager: Lost task 92.2 in stage 0.0 (TID 157) on 192.168.33.11, executor 5: java.lang.NumberFormatException (For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc") [duplicate 1]
18/09/26 10:52:12 INFO TaskSetManager: Starting task 92.3 in stage 0.0 (TID 177, 192.168.33.15, executor 0, partition 92, ANY, 4879 bytes)
18/09/26 10:52:12 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 51586 ms on 192.168.33.15 (executor 0) (95/409)
18/09/26 10:52:12 INFO TaskSetManager: Starting task 175.0 in stage 0.0 (TID 178, 192.168.33.15, executor 0, partition 175, ANY, 4879 bytes)
18/09/26 10:52:12 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 51602 ms on 192.168.33.15 (executor 0) (96/409)
18/09/26 10:52:12 INFO TaskSetManager: Starting task 176.0 in stage 0.0 (TID 179, 192.168.33.15, executor 0, partition 176, ANY, 4879 bytes)
18/09/26 10:52:12 INFO TaskSetManager: Finished task 55.0 in stage 0.0 (TID 55) in 51662 ms on 192.168.33.15 (executor 0) (97/409)
18/09/26 10:52:13 INFO TaskSetManager: Starting task 177.0 in stage 0.0 (TID 180, 192.168.33.15, executor 0, partition 177, ANY, 4879 bytes)
18/09/26 10:52:13 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 52753 ms on 192.168.33.15 (executor 0) (98/409)
18/09/26 10:52:13 INFO TaskSetManager: Starting task 178.0 in stage 0.0 (TID 181, 192.168.33.15, executor 0, partition 178, ANY, 4879 bytes)
18/09/26 10:52:13 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 52794 ms on 192.168.33.15 (executor 0) (99/409)
18/09/26 10:52:13 INFO TaskSetManager: Starting task 179.0 in stage 0.0 (TID 182, 192.168.33.13, executor 2, partition 179, ANY, 4879 bytes)
18/09/26 10:52:13 INFO TaskSetManager: Finished task 130.0 in stage 0.0 (TID 131) in 13626 ms on 192.168.33.13 (executor 2) (100/409)
18/09/26 10:52:14 INFO TaskSetManager: Starting task 180.0 in stage 0.0 (TID 183, 192.168.33.15, executor 0, partition 180, ANY, 4879 bytes)
18/09/26 10:52:14 INFO TaskSetManager: Finished task 67.0 in stage 0.0 (TID 67) in 53715 ms on 192.168.33.15 (executor 0) (101/409)
18/09/26 10:52:14 INFO TaskSetManager: Starting task 181.0 in stage 0.0 (TID 184, 192.168.33.15, executor 0, partition 181, ANY, 4879 bytes)
18/09/26 10:52:14 INFO TaskSetManager: Finished task 71.0 in stage 0.0 (TID 71) in 53827 ms on 192.168.33.15 (executor 0) (102/409)
18/09/26 10:52:15 INFO TaskSetManager: Starting task 182.0 in stage 0.0 (TID 185, 192.168.33.15, executor 0, partition 182, ANY, 4879 bytes)
18/09/26 10:52:15 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 54305 ms on 192.168.33.15 (executor 0) (103/409)
18/09/26 10:52:15 INFO TaskSetManager: Starting task 183.0 in stage 0.0 (TID 186, 192.168.33.12, executor 3, partition 183, ANY, 4879 bytes)
18/09/26 10:52:15 INFO TaskSetManager: Finished task 133.0 in stage 0.0 (TID 134) in 13848 ms on 192.168.33.12 (executor 3) (104/409)
18/09/26 10:52:15 INFO TaskSetManager: Starting task 184.0 in stage 0.0 (TID 187, 192.168.33.15, executor 0, partition 184, ANY, 4879 bytes)
18/09/26 10:52:15 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 54812 ms on 192.168.33.15 (executor 0) (105/409)
18/09/26 10:52:15 INFO TaskSetManager: Starting task 185.0 in stage 0.0 (TID 188, 192.168.33.15, executor 0, partition 185, ANY, 4879 bytes)
18/09/26 10:52:15 INFO TaskSetManager: Finished task 73.0 in stage 0.0 (TID 73) in 55000 ms on 192.168.33.15 (executor 0) (106/409)
18/09/26 10:52:15 INFO TaskSetManager: Starting task 186.0 in stage 0.0 (TID 189, 192.168.33.15, executor 0, partition 186, ANY, 4879 bytes)
18/09/26 10:52:15 INFO TaskSetManager: Finished task 61.0 in stage 0.0 (TID 61) in 55044 ms on 192.168.33.15 (executor 0) (107/409)
18/09/26 10:52:16 INFO TaskSetManager: Starting task 187.0 in stage 0.0 (TID 190, 192.168.33.15, executor 0, partition 187, ANY, 4879 bytes)
18/09/26 10:52:16 INFO TaskSetManager: Finished task 75.0 in stage 0.0 (TID 75) in 55301 ms on 192.168.33.15 (executor 0) (108/409)
18/09/26 10:52:16 INFO TaskSetManager: Starting task 188.0 in stage 0.0 (TID 191, 192.168.33.13, executor 2, partition 188, ANY, 4879 bytes)
18/09/26 10:52:16 INFO TaskSetManager: Finished task 132.0 in stage 0.0 (TID 133) in 15094 ms on 192.168.33.13 (executor 2) (109/409)
18/09/26 10:52:16 INFO TaskSetManager: Starting task 189.0 in stage 0.0 (TID 192, 192.168.33.15, executor 0, partition 189, ANY, 4879 bytes)
18/09/26 10:52:16 INFO TaskSetManager: Finished task 57.0 in stage 0.0 (TID 57) in 55629 ms on 192.168.33.15 (executor 0) (110/409)
18/09/26 10:52:16 INFO TaskSetManager: Starting task 190.0 in stage 0.0 (TID 193, 192.168.33.15, executor 0, partition 190, ANY, 4879 bytes)
18/09/26 10:52:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 55861 ms on 192.168.33.15 (executor 0) (111/409)
18/09/26 10:52:16 INFO TaskSetManager: Starting task 191.0 in stage 0.0 (TID 194, 192.168.33.15, executor 0, partition 191, ANY, 4879 bytes)
18/09/26 10:52:16 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 56140 ms on 192.168.33.15 (executor 0) (112/409)
18/09/26 10:52:17 INFO TaskSetManager: Starting task 192.0 in stage 0.0 (TID 195, 192.168.33.15, executor 0, partition 192, ANY, 4879 bytes)
18/09/26 10:52:17 INFO TaskSetManager: Finished task 59.0 in stage 0.0 (TID 59) in 56290 ms on 192.168.33.15 (executor 0) (113/409)
18/09/26 10:52:17 INFO TaskSetManager: Starting task 193.0 in stage 0.0 (TID 196, 192.168.33.15, executor 0, partition 193, ANY, 4879 bytes)
18/09/26 10:52:17 INFO TaskSetManager: Finished task 63.0 in stage 0.0 (TID 63) in 56595 ms on 192.168.33.15 (executor 0) (114/409)
18/09/26 10:52:17 INFO TaskSetManager: Starting task 194.0 in stage 0.0 (TID 197, 192.168.33.13, executor 2, partition 194, ANY, 4879 bytes)
18/09/26 10:52:17 INFO TaskSetManager: Finished task 135.0 in stage 0.0 (TID 136) in 16119 ms on 192.168.33.13 (executor 2) (115/409)
18/09/26 10:52:18 INFO TaskSetManager: Starting task 195.0 in stage 0.0 (TID 198, 192.168.33.13, executor 2, partition 195, ANY, 4879 bytes)
18/09/26 10:52:18 INFO TaskSetManager: Finished task 141.0 in stage 0.0 (TID 142) in 15205 ms on 192.168.33.13 (executor 2) (116/409)
18/09/26 10:52:18 INFO TaskSetManager: Starting task 196.0 in stage 0.0 (TID 199, 192.168.33.13, executor 2, partition 196, ANY, 4879 bytes)
18/09/26 10:52:18 INFO TaskSetManager: Finished task 143.0 in stage 0.0 (TID 144) in 14861 ms on 192.168.33.13 (executor 2) (117/409)
18/09/26 10:52:18 INFO TaskSetManager: Starting task 197.0 in stage 0.0 (TID 200, 192.168.33.12, executor 3, partition 197, ANY, 4879 bytes)
18/09/26 10:52:18 INFO TaskSetManager: Finished task 140.0 in stage 0.0 (TID 141) in 16059 ms on 192.168.33.12 (executor 3) (118/409)
18/09/26 10:52:19 INFO TaskSetManager: Starting task 198.0 in stage 0.0 (TID 201, 192.168.33.13, executor 2, partition 198, ANY, 4879 bytes)
18/09/26 10:52:19 INFO TaskSetManager: Finished task 144.0 in stage 0.0 (TID 145) in 15126 ms on 192.168.33.13 (executor 2) (119/409)
18/09/26 10:52:19 INFO TaskSetManager: Starting task 199.0 in stage 0.0 (TID 202, 192.168.33.13, executor 2, partition 199, ANY, 4879 bytes)
18/09/26 10:52:19 INFO TaskSetManager: Finished task 142.0 in stage 0.0 (TID 143) in 15381 ms on 192.168.33.13 (executor 2) (120/409)
18/09/26 10:52:19 INFO TaskSetManager: Starting task 200.0 in stage 0.0 (TID 203, 192.168.33.15, executor 0, partition 200, ANY, 4879 bytes)
18/09/26 10:52:19 INFO TaskSetManager: Finished task 79.0 in stage 0.0 (TID 79) in 58481 ms on 192.168.33.15 (executor 0) (121/409)
18/09/26 10:52:19 INFO TaskSetManager: Starting task 201.0 in stage 0.0 (TID 204, 192.168.33.14, executor 4, partition 201, ANY, 4879 bytes)
18/09/26 10:52:19 INFO TaskSetManager: Finished task 147.0 in stage 0.0 (TID 148) in 15074 ms on 192.168.33.14 (executor 4) (122/409)
18/09/26 10:52:19 INFO TaskSetManager: Starting task 202.0 in stage 0.0 (TID 205, 192.168.33.12, executor 3, partition 202, ANY, 4879 bytes)
18/09/26 10:52:19 INFO TaskSetManager: Finished task 145.0 in stage 0.0 (TID 146) in 15320 ms on 192.168.33.12 (executor 3) (123/409)
18/09/26 10:52:20 INFO TaskSetManager: Starting task 203.0 in stage 0.0 (TID 206, 192.168.33.13, executor 2, partition 203, ANY, 4879 bytes)
18/09/26 10:52:20 INFO TaskSetManager: Finished task 149.0 in stage 0.0 (TID 150) in 15318 ms on 192.168.33.13 (executor 2) (124/409)
18/09/26 10:52:20 INFO TaskSetManager: Starting task 204.0 in stage 0.0 (TID 207, 192.168.33.14, executor 4, partition 204, ANY, 4879 bytes)
18/09/26 10:52:20 INFO TaskSetManager: Finished task 156.0 in stage 0.0 (TID 158) in 14149 ms on 192.168.33.14 (executor 4) (125/409)
18/09/26 10:52:20 INFO TaskSetManager: Starting task 205.0 in stage 0.0 (TID 208, 192.168.33.12, executor 3, partition 205, ANY, 4879 bytes)
18/09/26 10:52:20 INFO TaskSetManager: Finished task 153.0 in stage 0.0 (TID 154) in 15053 ms on 192.168.33.12 (executor 3) (126/409)
18/09/26 10:52:20 INFO TaskSetManager: Starting task 206.0 in stage 0.0 (TID 209, 192.168.33.12, executor 3, partition 206, ANY, 4879 bytes)
18/09/26 10:52:20 INFO TaskSetManager: Finished task 148.0 in stage 0.0 (TID 149) in 15904 ms on 192.168.33.12 (executor 3) (127/409)
18/09/26 10:52:21 INFO TaskSetManager: Starting task 207.0 in stage 0.0 (TID 210, 192.168.33.14, executor 4, partition 207, ANY, 4879 bytes)
18/09/26 10:52:21 INFO TaskSetManager: Finished task 152.0 in stage 0.0 (TID 153) in 16007 ms on 192.168.33.14 (executor 4) (128/409)
18/09/26 10:52:21 INFO TaskSetManager: Starting task 208.0 in stage 0.0 (TID 211, 192.168.33.12, executor 3, partition 208, ANY, 4879 bytes)
18/09/26 10:52:21 INFO TaskSetManager: Finished task 146.0 in stage 0.0 (TID 147) in 16976 ms on 192.168.33.12 (executor 3) (129/409)
18/09/26 10:52:22 INFO TaskSetManager: Starting task 209.0 in stage 0.0 (TID 212, 192.168.33.12, executor 3, partition 209, ANY, 4879 bytes)
18/09/26 10:52:22 INFO TaskSetManager: Finished task 154.0 in stage 0.0 (TID 155) in 16355 ms on 192.168.33.12 (executor 3) (130/409)
18/09/26 10:52:22 INFO TaskSetManager: Starting task 210.0 in stage 0.0 (TID 213, 192.168.33.14, executor 4, partition 210, ANY, 4879 bytes)
18/09/26 10:52:22 INFO TaskSetManager: Finished task 157.0 in stage 0.0 (TID 159) in 15236 ms on 192.168.33.14 (executor 4) (131/409)
18/09/26 10:52:22 INFO TaskSetManager: Starting task 211.0 in stage 0.0 (TID 214, 192.168.33.12, executor 3, partition 211, ANY, 4879 bytes)
18/09/26 10:52:22 INFO TaskSetManager: Finished task 151.0 in stage 0.0 (TID 152) in 17183 ms on 192.168.33.12 (executor 3) (132/409)
18/09/26 10:52:22 INFO TaskSetManager: Starting task 212.0 in stage 0.0 (TID 215, 192.168.33.14, executor 4, partition 212, ANY, 4879 bytes)
18/09/26 10:52:22 INFO TaskSetManager: Finished task 150.0 in stage 0.0 (TID 151) in 17591 ms on 192.168.33.14 (executor 4) (133/409)
18/09/26 10:52:23 INFO TaskSetManager: Starting task 213.0 in stage 0.0 (TID 216, 192.168.33.14, executor 4, partition 213, ANY, 4879 bytes)
18/09/26 10:52:23 INFO TaskSetManager: Finished task 158.0 in stage 0.0 (TID 160) in 16434 ms on 192.168.33.14 (executor 4) (134/409)
18/09/26 10:52:25 INFO TaskSetManager: Starting task 214.0 in stage 0.0 (TID 217, 192.168.33.11, executor 5, partition 214, ANY, 4879 bytes)
18/09/26 10:52:25 INFO TaskSetManager: Finished task 162.0 in stage 0.0 (TID 164) in 16797 ms on 192.168.33.11 (executor 5) (135/409)
18/09/26 10:52:25 INFO TaskSetManager: Starting task 215.0 in stage 0.0 (TID 218, 192.168.33.11, executor 5, partition 215, ANY, 4879 bytes)
18/09/26 10:52:25 INFO TaskSetManager: Finished task 159.0 in stage 0.0 (TID 161) in 18242 ms on 192.168.33.11 (executor 5) (136/409)
18/09/26 10:52:25 INFO TaskSetManager: Starting task 216.0 in stage 0.0 (TID 219, 192.168.33.14, executor 4, partition 216, ANY, 4879 bytes)
18/09/26 10:52:25 INFO TaskSetManager: Finished task 161.0 in stage 0.0 (TID 163) in 17833 ms on 192.168.33.14 (executor 4) (137/409)
18/09/26 10:52:26 INFO TaskSetManager: Starting task 217.0 in stage 0.0 (TID 220, 192.168.33.10, executor 1, partition 217, ANY, 4879 bytes)
18/09/26 10:52:26 INFO TaskSetManager: Finished task 115.0 in stage 0.0 (TID 116) in 30127 ms on 192.168.33.10 (executor 1) (138/409)
18/09/26 10:52:27 INFO TaskSetManager: Starting task 218.0 in stage 0.0 (TID 221, 192.168.33.14, executor 4, partition 218, ANY, 4879 bytes)
18/09/26 10:52:27 INFO TaskSetManager: Finished task 160.0 in stage 0.0 (TID 162) in 19413 ms on 192.168.33.14 (executor 4) (139/409)
18/09/26 10:52:27 INFO TaskSetManager: Starting task 219.0 in stage 0.0 (TID 222, 192.168.33.10, executor 1, partition 219, ANY, 4879 bytes)
18/09/26 10:52:27 INFO TaskSetManager: Finished task 118.0 in stage 0.0 (TID 119) in 30056 ms on 192.168.33.10 (executor 1) (140/409)
18/09/26 10:52:27 INFO TaskSetManager: Starting task 220.0 in stage 0.0 (TID 223, 192.168.33.11, executor 5, partition 220, ANY, 4879 bytes)
18/09/26 10:52:27 INFO TaskSetManager: Finished task 166.0 in stage 0.0 (TID 168) in 17857 ms on 192.168.33.11 (executor 5) (141/409)
18/09/26 10:52:27 INFO TaskSetManager: Starting task 221.0 in stage 0.0 (TID 224, 192.168.33.10, executor 1, partition 221, ANY, 4879 bytes)
18/09/26 10:52:27 INFO TaskSetManager: Finished task 117.0 in stage 0.0 (TID 118) in 30786 ms on 192.168.33.10 (executor 1) (142/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 222.0 in stage 0.0 (TID 225, 192.168.33.11, executor 5, partition 222, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 163.0 in stage 0.0 (TID 165) in 19734 ms on 192.168.33.11 (executor 5) (143/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 223.0 in stage 0.0 (TID 226, 192.168.33.11, executor 5, partition 223, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 165.0 in stage 0.0 (TID 167) in 18654 ms on 192.168.33.11 (executor 5) (144/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 224.0 in stage 0.0 (TID 227, 192.168.33.13, executor 2, partition 224, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 179.0 in stage 0.0 (TID 182) in 14516 ms on 192.168.33.13 (executor 2) (145/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 225.0 in stage 0.0 (TID 228, 192.168.33.11, executor 5, partition 225, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 168.0 in stage 0.0 (TID 170) in 18661 ms on 192.168.33.11 (executor 5) (146/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 226.0 in stage 0.0 (TID 229, 192.168.33.12, executor 3, partition 226, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 183.0 in stage 0.0 (TID 186) in 13665 ms on 192.168.33.12 (executor 3) (147/409)
18/09/26 10:52:28 INFO TaskSetManager: Starting task 227.0 in stage 0.0 (TID 230, 192.168.33.10, executor 1, partition 227, ANY, 4879 bytes)
18/09/26 10:52:28 INFO TaskSetManager: Finished task 123.0 in stage 0.0 (TID 124) in 30349 ms on 192.168.33.10 (executor 1) (148/409)
18/09/26 10:52:29 INFO TaskSetManager: Starting task 228.0 in stage 0.0 (TID 231, 192.168.33.11, executor 5, partition 228, ANY, 4879 bytes)
18/09/26 10:52:29 INFO TaskSetManager: Finished task 167.0 in stage 0.0 (TID 169) in 19375 ms on 192.168.33.11 (executor 5) (149/409)
18/09/26 10:52:29 INFO TaskSetManager: Starting task 229.0 in stage 0.0 (TID 232, 192.168.33.15, executor 0, partition 229, ANY, 4879 bytes)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 92.3 in stage 0.0 (TID 177, 192.168.33.15, executor 0): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 10:52:29 ERROR TaskSetManager: Task 92 in stage 0.0 failed 4 times; aborting job
18/09/26 10:52:29 INFO TaskSchedulerImpl: Cancelling stage 0
18/09/26 10:52:29 INFO TaskSchedulerImpl: Stage 0 was cancelled
18/09/26 10:52:29 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) failed in 68,865 s due to Job aborted due to stage failure: Task 92 in stage 0.0 failed 4 times, most recent failure: Lost task 92.3 in stage 0.0 (TID 177, 192.168.33.15, executor 0): java.lang.NumberFormatException: For input string: "<http://dbpedia.org/property/_percent_D7_percent_AA_perc"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.parseInt(Integer.java:615)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at david.sc_dbscan.objects.NodeBuilder$$anonfun$createNode$1.apply$mcVI$sp(Noeud.scala:35)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.NodeBuilder$.createNode(Noeud.scala:34)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:54)
	at david.sc_dbscan.process.Partitioning$$anonfun$1.apply(Partitioning.scala:53)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
18/09/26 10:52:29 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 69,106429 s
18/09/26 10:52:29 WARN TaskSetManager: Lost task 226.0 in stage 0.0 (TID 229, 192.168.33.12, executor 3): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 222.0 in stage 0.0 (TID 225, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 220.0 in stage 0.0 (TID 223, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 225.0 in stage 0.0 (TID 228, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 214.0 in stage 0.0 (TID 217, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 223.0 in stage 0.0 (TID 226, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 221.0 in stage 0.0 (TID 224, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:52:29 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 10:52:29 WARN TaskSetManager: Lost task 228.0 in stage 0.0 (TID 231, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 10:52:29 WARN TaskSetManager: Lost task 215.0 in stage 0.0 (TID 218, 192.168.33.11, executor 5): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 177.0 in stage 0.0 (TID 180, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 176.0 in stage 0.0 (TID 179, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 180.0 in stage 0.0 (TID 183, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 213.0 in stage 0.0 (TID 216, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 185.0 in stage 0.0 (TID 188, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 216.0 in stage 0.0 (TID 219, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 218.0 in stage 0.0 (TID 221, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 212.0 in stage 0.0 (TID 215, 192.168.33.14, executor 4): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 113.0 in stage 0.0 (TID 114, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 219.0 in stage 0.0 (TID 222, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 217.0 in stage 0.0 (TID 220, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 229.0 in stage 0.0 (TID 232, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 181.0 in stage 0.0 (TID 184, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 171.0 in stage 0.0 (TID 173, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 173.0 in stage 0.0 (TID 175, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 200.0 in stage 0.0 (TID 203, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 182.0 in stage 0.0 (TID 185, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 178.0 in stage 0.0 (TID 181, 192.168.33.15, executor 0): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 224.0 in stage 0.0 (TID 227, 192.168.33.13, executor 2): TaskKilled (stage cancelled)
18/09/26 10:52:29 WARN TaskSetManager: Lost task 227.0 in stage 0.0 (TID 230, 192.168.33.10, executor 1): TaskKilled (stage cancelled)
18/09/26 10:52:29 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 10:52:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 10:52:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 10:52:29 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:157)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:137)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:647)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:178)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 10:52:29 INFO MemoryStore: MemoryStore cleared
18/09/26 10:52:29 INFO BlockManager: BlockManager stopped
18/09/26 10:52:29 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 10:52:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 10:52:29 INFO SparkContext: Successfully stopped SparkContext
18/09/26 10:52:29 INFO ShutdownHookManager: Shutdown hook called
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-e011a1ae-47a7-436d-ba30-8eab98b41f10
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-6cf458fc-c603-4ce3-80f3-0938de2b4fdd
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-17ec55b9-dca1-4e31-b942-e2734dfcb1a7
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-b2f9501f-abcb-4c57-9b53-ca722d41e9db
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-1de84eee-85d3-453c-9be3-a9c751200d92
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-d76186b2-46cc-41ea-9d25-29602acb6426
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-2288448e-f600-43df-be2e-5515e114c23f
18/09/26 10:52:29 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-1e502e17-2c33-4b53-a199-843b8768fda7
18/09/26 11:11:47 INFO SparkContext: Running Spark version 2.2.1
18/09/26 11:11:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 11:11:48 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 11:11:48 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 11:11:48 INFO SecurityManager: Changing view acls to: redouane
18/09/26 11:11:48 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 11:11:48 INFO SecurityManager: Changing view acls groups to: 
18/09/26 11:11:48 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 11:11:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 11:11:48 INFO Utils: Successfully started service 'sparkDriver' on port 39108.
18/09/26 11:11:48 INFO SparkEnv: Registering MapOutputTracker
18/09/26 11:11:48 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 11:11:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 11:11:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-8a31e74c-2a9b-4ce2-8d26-2b4beda208d5
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-497b1900-8b70-4dd9-900b-c56c78c825a3
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-960a454b-86dc-436e-a3c5-aec06745957a
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-9ca41ff5-1852-49c1-803b-96aa9b62fa00
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-ac88fb0f-c678-4dc4-984c-c0ef443253f1
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-7cd0f5ab-dbca-42e1-a61c-25642eaf4e77
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-9dbe7a41-56f5-43c0-b4e0-87b6c7136f2f
18/09/26 11:11:48 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-148aadd0-2c8b-4d39-8d88-49e2b50b6d3f
18/09/26 11:11:48 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 11:11:48 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 11:11:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 11:11:48 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 11:11:48 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:39108/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537953108952
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 11:11:49 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 28 ms (0 ms spent in bootstraps)
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926111149-0005
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/26 11:11:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36578.
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO NettyBlockTransferService: Server created on 192.168.33.10:36578
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111149-0005/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/26 11:11:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 11:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111149-0005/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/26 11:11:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 36578, None)
18/09/26 11:11:49 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:36578 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 36578, None)
18/09/26 11:11:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 36578, None)
18/09/26 11:11:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 36578, None)
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/1 is now RUNNING
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/0 is now RUNNING
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/2 is now RUNNING
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/5 is now RUNNING
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/3 is now RUNNING
18/09/26 11:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111149-0005/4 is now RUNNING
18/09/26 11:11:50 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926111149-0005
18/09/26 11:11:50 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 11:11:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 11:11:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 11:11:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:36578 (size: 27.9 KB, free: 366.3 MB)
18/09/26 11:11:50 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 11:11:51 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 11:11:51 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 11:11:51 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 11:11:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 11:11:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 11:11:51 INFO MemoryStore: MemoryStore cleared
18/09/26 11:11:51 INFO BlockManager: BlockManager stopped
18/09/26 11:11:51 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 11:11:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 11:11:51 INFO SparkContext: Successfully stopped SparkContext
18/09/26 11:11:51 INFO ShutdownHookManager: Shutdown hook called
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-310042c9-568c-4dab-b135-8d9031b48cac
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-5250f38e-0f82-4516-809b-b3926404111a
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-f557a25a-7c04-4444-8a0b-d959dc486241
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-a5306d90-05db-41a9-92a3-c1f7e5d32718
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-6a2920fb-ec59-4027-b74d-a03375ed45b5
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-f7274cad-d31d-45f2-b99c-4d65f8e5394d
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-6df664c9-2762-485f-8af5-d77dc39e4528
18/09/26 11:11:51 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-b84bb48e-c4d1-45f8-af7c-cb1b1599579d
18/09/26 11:13:28 INFO SparkContext: Running Spark version 2.2.1
18/09/26 11:13:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/26 11:13:29 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/26 11:13:29 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/26 11:13:29 INFO SecurityManager: Changing view acls to: redouane
18/09/26 11:13:29 INFO SecurityManager: Changing modify acls to: redouane
18/09/26 11:13:29 INFO SecurityManager: Changing view acls groups to: 
18/09/26 11:13:29 INFO SecurityManager: Changing modify acls groups to: 
18/09/26 11:13:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/26 11:13:29 INFO Utils: Successfully started service 'sparkDriver' on port 43938.
18/09/26 11:13:29 INFO SparkEnv: Registering MapOutputTracker
18/09/26 11:13:29 INFO SparkEnv: Registering BlockManagerMaster
18/09/26 11:13:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/26 11:13:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-69dc0277-422a-43e0-a98e-06fd063e0776
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-3b817144-19c1-47e9-a7a4-f1e239a73750
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-3e405b07-70c8-42ee-857c-b6d6a0e71b85
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-f229d077-be70-4c10-8c82-3fbf350525cd
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-3d630f53-6cd2-4069-bc9d-3e8ac3bb5d19
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-d9c589cc-2a70-4bfc-b38f-4512975611fb
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-32bcc0cf-0615-4840-89b1-9bd616a49e49
18/09/26 11:13:29 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-9e41168a-8b44-43f7-97e9-c2b06f79d85d
18/09/26 11:13:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/26 11:13:29 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/26 11:13:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/26 11:13:30 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/26 11:13:30 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:43938/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1537953210155
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/26 11:13:30 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 26 ms (0 ms spent in bootstraps)
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180926111330-0006
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/26 11:13:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43403.
18/09/26 11:13:30 INFO NettyBlockTransferService: Server created on 192.168.33.10:43403
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/26 11:13:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 43403, None)
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/26 11:13:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/26 11:13:30 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:43403 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 43403, None)
18/09/26 11:13:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 43403, None)
18/09/26 11:13:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 43403, None)
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/1 is now RUNNING
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/0 is now RUNNING
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/4 is now RUNNING
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/2 is now RUNNING
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/3 is now RUNNING
18/09/26 11:13:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/5 is now RUNNING
18/09/26 11:13:31 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180926111330-0006
18/09/26 11:13:31 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/26 11:13:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/26 11:13:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/26 11:13:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:43403 (size: 27.9 KB, free: 366.3 MB)
18/09/26 11:13:32 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/26 11:13:32 INFO FileInputFormat: Total input files to process : 409
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:43042) with ID 2
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:37794) with ID 3
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:43502) with ID 5
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:37206) with ID 4
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:33570 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.13, 33570, None)
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:35074 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.12, 35074, None)
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:38333 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.11, 38333, None)
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:56464) with ID 0
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:34961 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.14, 34961, None)
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:35408 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 35408, None)
18/09/26 11:13:32 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/26 11:13:32 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/26 11:13:32 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/26 11:13:32 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/26 11:13:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/26 11:13:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/26 11:13:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 11:13:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:37738) with ID 1
18/09/26 11:13:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/26 11:13:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 11:13:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:43403 (size: 2.5 KB, free: 366.3 MB)
18/09/26 11:13:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/26 11:13:32 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 11:13:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 409 tasks
18/09/26 11:13:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:41196 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 41196, None)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.12, executor 3, partition 0, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.13, executor 2, partition 1, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.33.14, executor 4, partition 2, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.33.11, executor 5, partition 3, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 192.168.33.15, executor 0, partition 4, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 192.168.33.10, executor 1, partition 5, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 192.168.33.12, executor 3, partition 6, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 192.168.33.13, executor 2, partition 7, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 192.168.33.14, executor 4, partition 8, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 192.168.33.11, executor 5, partition 9, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 192.168.33.15, executor 0, partition 10, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 192.168.33.10, executor 1, partition 11, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 192.168.33.12, executor 3, partition 12, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 192.168.33.13, executor 2, partition 13, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 192.168.33.14, executor 4, partition 14, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 192.168.33.11, executor 5, partition 15, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16, 192.168.33.15, executor 0, partition 16, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17, 192.168.33.10, executor 1, partition 17, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18, 192.168.33.12, executor 3, partition 18, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19, 192.168.33.13, executor 2, partition 19, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20, 192.168.33.14, executor 4, partition 20, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21, 192.168.33.11, executor 5, partition 21, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22, 192.168.33.15, executor 0, partition 22, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23, 192.168.33.10, executor 1, partition 23, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24, 192.168.33.12, executor 3, partition 24, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25, 192.168.33.13, executor 2, partition 25, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26, 192.168.33.14, executor 4, partition 26, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27, 192.168.33.11, executor 5, partition 27, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28, 192.168.33.15, executor 0, partition 28, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29, 192.168.33.10, executor 1, partition 29, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30, 192.168.33.12, executor 3, partition 30, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31, 192.168.33.13, executor 2, partition 31, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32, 192.168.33.14, executor 4, partition 32, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33, 192.168.33.11, executor 5, partition 33, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34, 192.168.33.15, executor 0, partition 34, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35, 192.168.33.10, executor 1, partition 35, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36, 192.168.33.12, executor 3, partition 36, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37, 192.168.33.13, executor 2, partition 37, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38, 192.168.33.14, executor 4, partition 38, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39, 192.168.33.11, executor 5, partition 39, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, 192.168.33.15, executor 0, partition 40, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41, 192.168.33.10, executor 1, partition 41, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42, 192.168.33.12, executor 3, partition 42, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43, 192.168.33.13, executor 2, partition 43, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44, 192.168.33.14, executor 4, partition 44, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45, 192.168.33.11, executor 5, partition 45, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46, 192.168.33.15, executor 0, partition 46, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47, 192.168.33.10, executor 1, partition 47, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48, 192.168.33.15, executor 0, partition 48, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49, 192.168.33.10, executor 1, partition 49, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50, 192.168.33.15, executor 0, partition 50, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51, 192.168.33.10, executor 1, partition 51, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52, 192.168.33.15, executor 0, partition 52, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53, 192.168.33.10, executor 1, partition 53, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54, 192.168.33.15, executor 0, partition 54, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55, 192.168.33.10, executor 1, partition 55, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56, 192.168.33.15, executor 0, partition 56, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57, 192.168.33.10, executor 1, partition 57, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58, 192.168.33.15, executor 0, partition 58, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59, 192.168.33.10, executor 1, partition 59, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60, 192.168.33.15, executor 0, partition 60, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61, 192.168.33.10, executor 1, partition 61, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62, 192.168.33.15, executor 0, partition 62, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63, 192.168.33.10, executor 1, partition 63, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64, 192.168.33.15, executor 0, partition 64, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65, 192.168.33.10, executor 1, partition 65, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66, 192.168.33.15, executor 0, partition 66, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67, 192.168.33.10, executor 1, partition 67, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68, 192.168.33.15, executor 0, partition 68, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69, 192.168.33.10, executor 1, partition 69, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70, 192.168.33.15, executor 0, partition 70, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71, 192.168.33.10, executor 1, partition 71, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72, 192.168.33.15, executor 0, partition 72, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73, 192.168.33.10, executor 1, partition 73, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74, 192.168.33.15, executor 0, partition 74, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75, 192.168.33.10, executor 1, partition 75, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76, 192.168.33.15, executor 0, partition 76, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77, 192.168.33.10, executor 1, partition 77, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78, 192.168.33.15, executor 0, partition 78, ANY, 4879 bytes)
18/09/26 11:13:32 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79, 192.168.33.10, executor 1, partition 79, ANY, 4879 bytes)
18/09/26 11:13:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:41196 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:41196 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:35074 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:35074 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.13:33570 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.11:38333 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.13:33570 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.11:38333 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:34961 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.15:35408 (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:13:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:34961 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.15:35408 (size: 27.9 KB, free: 15.8 GB)
18/09/26 11:13:58 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80, 192.168.33.14, executor 4, partition 80, ANY, 4879 bytes)
18/09/26 11:13:58 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 25106 ms on 192.168.33.14 (executor 4) (1/409)
18/09/26 11:13:58 INFO TaskSetManager: Starting task 81.0 in stage 0.0 (TID 81, 192.168.33.11, executor 5, partition 81, ANY, 4879 bytes)
18/09/26 11:13:58 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 25302 ms on 192.168.33.11 (executor 5) (2/409)
18/09/26 11:13:58 INFO TaskSetManager: Starting task 82.0 in stage 0.0 (TID 82, 192.168.33.11, executor 5, partition 82, ANY, 4879 bytes)
18/09/26 11:13:58 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 25318 ms on 192.168.33.11 (executor 5) (3/409)
18/09/26 11:13:58 INFO TaskSetManager: Starting task 83.0 in stage 0.0 (TID 83, 192.168.33.14, executor 4, partition 83, ANY, 4879 bytes)
18/09/26 11:13:58 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 25718 ms on 192.168.33.14 (executor 4) (4/409)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 84.0 in stage 0.0 (TID 84, 192.168.33.11, executor 5, partition 84, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 26086 ms on 192.168.33.11 (executor 5) (5/409)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 85.0 in stage 0.0 (TID 85, 192.168.33.14, executor 4, partition 85, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 26297 ms on 192.168.33.14 (executor 4) (6/409)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 26586 ms on 192.168.33.11 (executor 5) (7/409)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 86.0 in stage 0.0 (TID 86, 192.168.33.11, executor 5, partition 86, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 87.0 in stage 0.0 (TID 87, 192.168.33.11, executor 5, partition 87, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 26721 ms on 192.168.33.11 (executor 5) (8/409)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 88.0 in stage 0.0 (TID 88, 192.168.33.14, executor 4, partition 88, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 26988 ms on 192.168.33.14 (executor 4) (9/409)
18/09/26 11:13:59 INFO TaskSetManager: Starting task 89.0 in stage 0.0 (TID 89, 192.168.33.11, executor 5, partition 89, ANY, 4879 bytes)
18/09/26 11:13:59 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 27010 ms on 192.168.33.11 (executor 5) (10/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 90.0 in stage 0.0 (TID 90, 192.168.33.11, executor 5, partition 90, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 27113 ms on 192.168.33.11 (executor 5) (11/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 91.0 in stage 0.0 (TID 91, 192.168.33.14, executor 4, partition 91, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 27317 ms on 192.168.33.14 (executor 4) (12/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 92.0 in stage 0.0 (TID 92, 192.168.33.14, executor 4, partition 92, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 27396 ms on 192.168.33.14 (executor 4) (13/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 93.0 in stage 0.0 (TID 93, 192.168.33.14, executor 4, partition 93, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 27458 ms on 192.168.33.14 (executor 4) (14/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 94.0 in stage 0.0 (TID 94, 192.168.33.11, executor 5, partition 94, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 27585 ms on 192.168.33.11 (executor 5) (15/409)
18/09/26 11:14:00 INFO TaskSetManager: Starting task 95.0 in stage 0.0 (TID 95, 192.168.33.14, executor 4, partition 95, ANY, 4879 bytes)
18/09/26 11:14:00 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 27677 ms on 192.168.33.14 (executor 4) (16/409)
18/09/26 11:14:01 INFO TaskSetManager: Starting task 96.0 in stage 0.0 (TID 96, 192.168.33.13, executor 2, partition 96, ANY, 4879 bytes)
18/09/26 11:14:01 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 28237 ms on 192.168.33.13 (executor 2) (17/409)
18/09/26 11:14:01 INFO TaskSetManager: Starting task 97.0 in stage 0.0 (TID 97, 192.168.33.12, executor 3, partition 97, ANY, 4879 bytes)
18/09/26 11:14:01 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 28674 ms on 192.168.33.12 (executor 3) (18/409)
18/09/26 11:14:01 INFO TaskSetManager: Starting task 98.0 in stage 0.0 (TID 98, 192.168.33.13, executor 2, partition 98, ANY, 4879 bytes)
18/09/26 11:14:01 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 28758 ms on 192.168.33.13 (executor 2) (19/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 99.0 in stage 0.0 (TID 99, 192.168.33.12, executor 3, partition 99, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 29238 ms on 192.168.33.12 (executor 3) (20/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 100.0 in stage 0.0 (TID 100, 192.168.33.13, executor 2, partition 100, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 29257 ms on 192.168.33.13 (executor 2) (21/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 101.0 in stage 0.0 (TID 101, 192.168.33.13, executor 2, partition 101, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 29334 ms on 192.168.33.13 (executor 2) (22/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 102.0 in stage 0.0 (TID 102, 192.168.33.12, executor 3, partition 102, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 29376 ms on 192.168.33.12 (executor 3) (23/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 103.0 in stage 0.0 (TID 103, 192.168.33.12, executor 3, partition 103, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 29495 ms on 192.168.33.12 (executor 3) (24/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 104.0 in stage 0.0 (TID 104, 192.168.33.12, executor 3, partition 104, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 29628 ms on 192.168.33.12 (executor 3) (25/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 105.0 in stage 0.0 (TID 105, 192.168.33.13, executor 2, partition 105, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 29677 ms on 192.168.33.13 (executor 2) (26/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 106.0 in stage 0.0 (TID 106, 192.168.33.12, executor 3, partition 106, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 29882 ms on 192.168.33.12 (executor 3) (27/409)
18/09/26 11:14:02 INFO TaskSetManager: Starting task 107.0 in stage 0.0 (TID 107, 192.168.33.12, executor 3, partition 107, ANY, 4879 bytes)
18/09/26 11:14:02 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 29967 ms on 192.168.33.12 (executor 3) (28/409)
18/09/26 11:14:03 INFO TaskSetManager: Starting task 108.0 in stage 0.0 (TID 108, 192.168.33.13, executor 2, partition 108, ANY, 4879 bytes)
18/09/26 11:14:03 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 30205 ms on 192.168.33.13 (executor 2) (29/409)
18/09/26 11:14:03 INFO TaskSetManager: Starting task 109.0 in stage 0.0 (TID 109, 192.168.33.13, executor 2, partition 109, ANY, 4879 bytes)
18/09/26 11:14:03 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 30510 ms on 192.168.33.13 (executor 2) (30/409)
18/09/26 11:14:04 INFO TaskSetManager: Starting task 110.0 in stage 0.0 (TID 110, 192.168.33.13, executor 2, partition 110, ANY, 4879 bytes)
18/09/26 11:14:04 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 31140 ms on 192.168.33.13 (executor 2) (31/409)
18/09/26 11:14:04 INFO TaskSetManager: Starting task 111.0 in stage 0.0 (TID 111, 192.168.33.12, executor 3, partition 111, ANY, 4879 bytes)
18/09/26 11:14:04 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 31332 ms on 192.168.33.12 (executor 3) (32/409)
18/09/26 11:14:10 INFO TaskSetManager: Starting task 112.0 in stage 0.0 (TID 112, 192.168.33.15, executor 0, partition 112, ANY, 4879 bytes)
18/09/26 11:14:10 INFO TaskSetManager: Finished task 56.0 in stage 0.0 (TID 56) in 37412 ms on 192.168.33.15 (executor 0) (33/409)
18/09/26 11:14:12 INFO TaskSetManager: Starting task 113.0 in stage 0.0 (TID 113, 192.168.33.15, executor 0, partition 113, ANY, 4879 bytes)
18/09/26 11:14:12 INFO TaskSetManager: Finished task 60.0 in stage 0.0 (TID 60) in 39971 ms on 192.168.33.15 (executor 0) (34/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 114.0 in stage 0.0 (TID 114, 192.168.33.15, executor 0, partition 114, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 64.0 in stage 0.0 (TID 64) in 40509 ms on 192.168.33.15 (executor 0) (35/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 115.0 in stage 0.0 (TID 115, 192.168.33.15, executor 0, partition 115, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 40684 ms on 192.168.33.15 (executor 0) (36/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 116.0 in stage 0.0 (TID 116, 192.168.33.14, executor 4, partition 116, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 80.0 in stage 0.0 (TID 80) in 15612 ms on 192.168.33.14 (executor 4) (37/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 117.0 in stage 0.0 (TID 117, 192.168.33.11, executor 5, partition 117, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 84.0 in stage 0.0 (TID 84) in 14644 ms on 192.168.33.11 (executor 5) (38/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 118.0 in stage 0.0 (TID 118, 192.168.33.15, executor 0, partition 118, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 40753 ms on 192.168.33.15 (executor 0) (39/409)
18/09/26 11:14:13 INFO TaskSetManager: Starting task 119.0 in stage 0.0 (TID 119, 192.168.33.11, executor 5, partition 119, ANY, 4879 bytes)
18/09/26 11:14:13 INFO TaskSetManager: Finished task 82.0 in stage 0.0 (TID 82) in 15599 ms on 192.168.33.11 (executor 5) (40/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 120.0 in stage 0.0 (TID 120, 192.168.33.11, executor 5, partition 120, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 121.0 in stage 0.0 (TID 121, 192.168.33.15, executor 0, partition 121, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 87.0 in stage 0.0 (TID 87) in 14547 ms on 192.168.33.11 (executor 5) (41/409)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 54.0 in stage 0.0 (TID 54) in 41248 ms on 192.168.33.15 (executor 0) (42/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 122.0 in stage 0.0 (TID 122, 192.168.33.14, executor 4, partition 122, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 83.0 in stage 0.0 (TID 83) in 15746 ms on 192.168.33.14 (executor 4) (43/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 123.0 in stage 0.0 (TID 123, 192.168.33.15, executor 0, partition 123, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 41598 ms on 192.168.33.15 (executor 0) (44/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 124.0 in stage 0.0 (TID 124, 192.168.33.15, executor 0, partition 124, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 76.0 in stage 0.0 (TID 76) in 41674 ms on 192.168.33.15 (executor 0) (45/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 125.0 in stage 0.0 (TID 125, 192.168.33.15, executor 0, partition 125, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 41840 ms on 192.168.33.15 (executor 0) (46/409)
18/09/26 11:14:14 INFO TaskSetManager: Starting task 126.0 in stage 0.0 (TID 126, 192.168.33.14, executor 4, partition 126, ANY, 4879 bytes)
18/09/26 11:14:14 INFO TaskSetManager: Finished task 88.0 in stage 0.0 (TID 88) in 14897 ms on 192.168.33.14 (executor 4) (47/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 127.0 in stage 0.0 (TID 127, 192.168.33.15, executor 0, partition 127, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 42120 ms on 192.168.33.15 (executor 0) (48/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 128.0 in stage 0.0 (TID 128, 192.168.33.14, executor 4, partition 128, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 85.0 in stage 0.0 (TID 85) in 15887 ms on 192.168.33.14 (executor 4) (49/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 129.0 in stage 0.0 (TID 129, 192.168.33.11, executor 5, partition 129, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 81.0 in stage 0.0 (TID 81) in 17289 ms on 192.168.33.11 (executor 5) (50/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 130.0 in stage 0.0 (TID 130, 192.168.33.14, executor 4, partition 130, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 92.0 in stage 0.0 (TID 92) in 15354 ms on 192.168.33.14 (executor 4) (51/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 131.0 in stage 0.0 (TID 131, 192.168.33.15, executor 0, partition 131, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 58.0 in stage 0.0 (TID 58) in 42863 ms on 192.168.33.15 (executor 0) (52/409)
18/09/26 11:14:15 INFO TaskSetManager: Starting task 132.0 in stage 0.0 (TID 132, 192.168.33.15, executor 0, partition 132, ANY, 4879 bytes)
18/09/26 11:14:15 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 42929 ms on 192.168.33.15 (executor 0) (53/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 133.0 in stage 0.0 (TID 133, 192.168.33.11, executor 5, partition 133, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 94.0 in stage 0.0 (TID 94) in 15770 ms on 192.168.33.11 (executor 5) (54/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 134.0 in stage 0.0 (TID 134, 192.168.33.11, executor 5, partition 134, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 89.0 in stage 0.0 (TID 89) in 16385 ms on 192.168.33.11 (executor 5) (55/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 135.0 in stage 0.0 (TID 135, 192.168.33.15, executor 0, partition 135, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 43401 ms on 192.168.33.15 (executor 0) (56/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 136.0 in stage 0.0 (TID 136, 192.168.33.15, executor 0, partition 136, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 68.0 in stage 0.0 (TID 68) in 43550 ms on 192.168.33.15 (executor 0) (57/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 137.0 in stage 0.0 (TID 137, 192.168.33.15, executor 0, partition 137, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 62.0 in stage 0.0 (TID 62) in 43572 ms on 192.168.33.15 (executor 0) (58/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 138.0 in stage 0.0 (TID 138, 192.168.33.14, executor 4, partition 138, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 91.0 in stage 0.0 (TID 91) in 16308 ms on 192.168.33.14 (executor 4) (59/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 139.0 in stage 0.0 (TID 139, 192.168.33.15, executor 0, partition 139, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 72.0 in stage 0.0 (TID 72) in 43741 ms on 192.168.33.15 (executor 0) (60/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 140.0 in stage 0.0 (TID 140, 192.168.33.15, executor 0, partition 140, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 78.0 in stage 0.0 (TID 78) in 43743 ms on 192.168.33.15 (executor 0) (61/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 141.0 in stage 0.0 (TID 141, 192.168.33.15, executor 0, partition 141, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 74.0 in stage 0.0 (TID 74) in 43923 ms on 192.168.33.15 (executor 0) (62/409)
18/09/26 11:14:16 INFO TaskSetManager: Starting task 142.0 in stage 0.0 (TID 142, 192.168.33.15, executor 0, partition 142, ANY, 4879 bytes)
18/09/26 11:14:16 INFO TaskSetManager: Finished task 66.0 in stage 0.0 (TID 66) in 43953 ms on 192.168.33.15 (executor 0) (63/409)
18/09/26 11:14:17 INFO TaskSetManager: Starting task 143.0 in stage 0.0 (TID 143, 192.168.33.14, executor 4, partition 143, ANY, 4879 bytes)
18/09/26 11:14:17 INFO TaskSetManager: Finished task 93.0 in stage 0.0 (TID 93) in 16914 ms on 192.168.33.14 (executor 4) (64/409)
18/09/26 11:14:17 INFO TaskSetManager: Starting task 144.0 in stage 0.0 (TID 144, 192.168.33.15, executor 0, partition 144, ANY, 4879 bytes)
18/09/26 11:14:17 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 44717 ms on 192.168.33.15 (executor 0) (65/409)
18/09/26 11:14:17 INFO TaskSetManager: Starting task 145.0 in stage 0.0 (TID 145, 192.168.33.15, executor 0, partition 145, ANY, 4879 bytes)
18/09/26 11:14:17 INFO TaskSetManager: Finished task 70.0 in stage 0.0 (TID 70) in 44809 ms on 192.168.33.15 (executor 0) (66/409)
18/09/26 11:14:17 INFO TaskSetManager: Starting task 146.0 in stage 0.0 (TID 146, 192.168.33.11, executor 5, partition 146, ANY, 4879 bytes)
18/09/26 11:14:17 INFO TaskSetManager: Finished task 90.0 in stage 0.0 (TID 90) in 17844 ms on 192.168.33.11 (executor 5) (67/409)
18/09/26 11:14:18 INFO TaskSetManager: Starting task 147.0 in stage 0.0 (TID 147, 192.168.33.11, executor 5, partition 147, ANY, 4879 bytes)
18/09/26 11:14:18 INFO TaskSetManager: Finished task 86.0 in stage 0.0 (TID 86) in 18575 ms on 192.168.33.11 (executor 5) (68/409)
18/09/26 11:14:18 INFO TaskSetManager: Starting task 148.0 in stage 0.0 (TID 148, 192.168.33.14, executor 4, partition 148, ANY, 4879 bytes)
18/09/26 11:14:18 INFO TaskSetManager: Finished task 95.0 in stage 0.0 (TID 95) in 17608 ms on 192.168.33.14 (executor 4) (69/409)
18/09/26 11:14:18 INFO TaskSetManager: Starting task 149.0 in stage 0.0 (TID 149, 192.168.33.15, executor 0, partition 149, ANY, 4879 bytes)
18/09/26 11:14:18 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 45539 ms on 192.168.33.15 (executor 0) (70/409)
18/09/26 11:14:18 INFO TaskSetManager: Starting task 150.0 in stage 0.0 (TID 150, 192.168.33.15, executor 0, partition 150, ANY, 4879 bytes)
18/09/26 11:14:18 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 45603 ms on 192.168.33.15 (executor 0) (71/409)
18/09/26 11:14:18 INFO TaskSetManager: Starting task 151.0 in stage 0.0 (TID 151, 192.168.33.15, executor 0, partition 151, ANY, 4879 bytes)
18/09/26 11:14:18 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 45616 ms on 192.168.33.15 (executor 0) (72/409)
18/09/26 11:14:19 INFO TaskSetManager: Starting task 152.0 in stage 0.0 (TID 152, 192.168.33.13, executor 2, partition 152, ANY, 4879 bytes)
18/09/26 11:14:19 INFO TaskSetManager: Finished task 96.0 in stage 0.0 (TID 96) in 18485 ms on 192.168.33.13 (executor 2) (73/409)
18/09/26 11:14:20 INFO TaskSetManager: Starting task 153.0 in stage 0.0 (TID 153, 192.168.33.13, executor 2, partition 153, ANY, 4879 bytes)
18/09/26 11:14:20 INFO TaskSetManager: Finished task 100.0 in stage 0.0 (TID 100) in 18087 ms on 192.168.33.13 (executor 2) (74/409)
18/09/26 11:14:20 INFO TaskSetManager: Starting task 154.0 in stage 0.0 (TID 154, 192.168.33.13, executor 2, partition 154, ANY, 4879 bytes)
18/09/26 11:14:20 INFO TaskSetManager: Finished task 105.0 in stage 0.0 (TID 105) in 17835 ms on 192.168.33.13 (executor 2) (75/409)
18/09/26 11:14:20 INFO TaskSetManager: Starting task 155.0 in stage 0.0 (TID 155, 192.168.33.13, executor 2, partition 155, ANY, 4879 bytes)
18/09/26 11:14:20 INFO TaskSetManager: Finished task 108.0 in stage 0.0 (TID 108) in 17351 ms on 192.168.33.13 (executor 2) (76/409)
18/09/26 11:14:20 INFO TaskSetManager: Starting task 156.0 in stage 0.0 (TID 156, 192.168.33.13, executor 2, partition 156, ANY, 4879 bytes)
18/09/26 11:14:20 INFO TaskSetManager: Finished task 98.0 in stage 0.0 (TID 98) in 19206 ms on 192.168.33.13 (executor 2) (77/409)
18/09/26 11:14:21 INFO TaskSetManager: Starting task 157.0 in stage 0.0 (TID 157, 192.168.33.10, executor 1, partition 157, ANY, 4879 bytes)
18/09/26 11:14:21 INFO TaskSetManager: Finished task 69.0 in stage 0.0 (TID 69) in 48449 ms on 192.168.33.10 (executor 1) (78/409)
18/09/26 11:14:21 INFO TaskSetManager: Starting task 158.0 in stage 0.0 (TID 158, 192.168.33.12, executor 3, partition 158, ANY, 4879 bytes)
18/09/26 11:14:21 INFO TaskSetManager: Finished task 103.0 in stage 0.0 (TID 103) in 19476 ms on 192.168.33.12 (executor 3) (79/409)
18/09/26 11:14:21 INFO TaskSetManager: Starting task 159.0 in stage 0.0 (TID 159, 192.168.33.12, executor 3, partition 159, ANY, 4879 bytes)
18/09/26 11:14:21 INFO TaskSetManager: Finished task 97.0 in stage 0.0 (TID 97) in 20312 ms on 192.168.33.12 (executor 3) (80/409)
18/09/26 11:14:21 INFO TaskSetManager: Starting task 160.0 in stage 0.0 (TID 160, 192.168.33.12, executor 3, partition 160, ANY, 4879 bytes)
18/09/26 11:14:21 INFO TaskSetManager: Finished task 99.0 in stage 0.0 (TID 99) in 19811 ms on 192.168.33.12 (executor 3) (81/409)
18/09/26 11:14:22 INFO TaskSetManager: Starting task 161.0 in stage 0.0 (TID 161, 192.168.33.13, executor 2, partition 161, ANY, 4879 bytes)
18/09/26 11:14:22 INFO TaskSetManager: Finished task 110.0 in stage 0.0 (TID 110) in 18234 ms on 192.168.33.13 (executor 2) (82/409)
18/09/26 11:14:22 INFO TaskSetManager: Starting task 162.0 in stage 0.0 (TID 162, 192.168.33.12, executor 3, partition 162, ANY, 4879 bytes)
18/09/26 11:14:22 INFO TaskSetManager: Finished task 104.0 in stage 0.0 (TID 104) in 19976 ms on 192.168.33.12 (executor 3) (83/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 163.0 in stage 0.0 (TID 163, 192.168.33.13, executor 2, partition 163, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 101.0 in stage 0.0 (TID 101) in 20697 ms on 192.168.33.13 (executor 2) (84/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 164.0 in stage 0.0 (TID 164, 192.168.33.13, executor 2, partition 164, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 109.0 in stage 0.0 (TID 109) in 19716 ms on 192.168.33.13 (executor 2) (85/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 165.0 in stage 0.0 (TID 165, 192.168.33.12, executor 3, partition 165, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 102.0 in stage 0.0 (TID 102) in 21043 ms on 192.168.33.12 (executor 3) (86/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 166.0 in stage 0.0 (TID 166, 192.168.33.12, executor 3, partition 166, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 106.0 in stage 0.0 (TID 106) in 20579 ms on 192.168.33.12 (executor 3) (87/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 167.0 in stage 0.0 (TID 167, 192.168.33.12, executor 3, partition 167, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 111.0 in stage 0.0 (TID 111) in 19159 ms on 192.168.33.12 (executor 3) (88/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 168.0 in stage 0.0 (TID 168, 192.168.33.10, executor 1, partition 168, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 53.0 in stage 0.0 (TID 53) in 50630 ms on 192.168.33.10 (executor 1) (89/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 169.0 in stage 0.0 (TID 169, 192.168.33.10, executor 1, partition 169, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 77.0 in stage 0.0 (TID 77) in 50641 ms on 192.168.33.10 (executor 1) (90/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 170.0 in stage 0.0 (TID 170, 192.168.33.12, executor 3, partition 170, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 107.0 in stage 0.0 (TID 107) in 20731 ms on 192.168.33.12 (executor 3) (91/409)
18/09/26 11:14:23 INFO TaskSetManager: Starting task 171.0 in stage 0.0 (TID 171, 192.168.33.10, executor 1, partition 171, ANY, 4879 bytes)
18/09/26 11:14:23 INFO TaskSetManager: Finished task 57.0 in stage 0.0 (TID 57) in 50872 ms on 192.168.33.10 (executor 1) (92/409)
18/09/26 11:14:24 INFO TaskSetManager: Starting task 172.0 in stage 0.0 (TID 172, 192.168.33.10, executor 1, partition 172, ANY, 4879 bytes)
18/09/26 11:14:24 INFO TaskSetManager: Finished task 55.0 in stage 0.0 (TID 55) in 51644 ms on 192.168.33.10 (executor 1) (93/409)
18/09/26 11:14:24 INFO TaskSetManager: Starting task 173.0 in stage 0.0 (TID 173, 192.168.33.10, executor 1, partition 173, ANY, 4879 bytes)
18/09/26 11:14:24 INFO TaskSetManager: Finished task 71.0 in stage 0.0 (TID 71) in 51643 ms on 192.168.33.10 (executor 1) (94/409)
18/09/26 11:14:24 INFO TaskSetManager: Starting task 174.0 in stage 0.0 (TID 174, 192.168.33.10, executor 1, partition 174, ANY, 4879 bytes)
18/09/26 11:14:24 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 51879 ms on 192.168.33.10 (executor 1) (95/409)
18/09/26 11:14:24 INFO TaskSetManager: Starting task 175.0 in stage 0.0 (TID 175, 192.168.33.10, executor 1, partition 175, ANY, 4879 bytes)
18/09/26 11:14:24 INFO TaskSetManager: Finished task 73.0 in stage 0.0 (TID 73) in 51938 ms on 192.168.33.10 (executor 1) (96/409)
18/09/26 11:14:24 INFO TaskSetManager: Starting task 176.0 in stage 0.0 (TID 176, 192.168.33.10, executor 1, partition 176, ANY, 4879 bytes)
18/09/26 11:14:24 INFO TaskSetManager: Finished task 65.0 in stage 0.0 (TID 65) in 51961 ms on 192.168.33.10 (executor 1) (97/409)
18/09/26 11:14:25 INFO TaskSetManager: Starting task 177.0 in stage 0.0 (TID 177, 192.168.33.10, executor 1, partition 177, ANY, 4879 bytes)
18/09/26 11:14:25 INFO TaskSetManager: Finished task 63.0 in stage 0.0 (TID 63) in 52654 ms on 192.168.33.10 (executor 1) (98/409)
18/09/26 11:14:25 INFO TaskSetManager: Starting task 178.0 in stage 0.0 (TID 178, 192.168.33.10, executor 1, partition 178, ANY, 4879 bytes)
18/09/26 11:14:25 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 53008 ms on 192.168.33.10 (executor 1) (99/409)
18/09/26 11:14:26 INFO TaskSetManager: Starting task 179.0 in stage 0.0 (TID 179, 192.168.33.10, executor 1, partition 179, ANY, 4879 bytes)
18/09/26 11:14:26 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 53269 ms on 192.168.33.10 (executor 1) (100/409)
18/09/26 11:14:26 INFO TaskSetManager: Starting task 180.0 in stage 0.0 (TID 180, 192.168.33.10, executor 1, partition 180, ANY, 4879 bytes)
18/09/26 11:14:26 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 53372 ms on 192.168.33.10 (executor 1) (101/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 181.0 in stage 0.0 (TID 181, 192.168.33.10, executor 1, partition 181, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 59.0 in stage 0.0 (TID 59) in 54057 ms on 192.168.33.10 (executor 1) (102/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 182.0 in stage 0.0 (TID 182, 192.168.33.10, executor 1, partition 182, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 54421 ms on 192.168.33.10 (executor 1) (103/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 183.0 in stage 0.0 (TID 183, 192.168.33.10, executor 1, partition 183, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 54477 ms on 192.168.33.10 (executor 1) (104/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 184.0 in stage 0.0 (TID 184, 192.168.33.10, executor 1, partition 184, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 67.0 in stage 0.0 (TID 67) in 54547 ms on 192.168.33.10 (executor 1) (105/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 185.0 in stage 0.0 (TID 185, 192.168.33.10, executor 1, partition 185, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 54735 ms on 192.168.33.10 (executor 1) (106/409)
18/09/26 11:14:27 INFO TaskSetManager: Starting task 186.0 in stage 0.0 (TID 186, 192.168.33.10, executor 1, partition 186, ANY, 4879 bytes)
18/09/26 11:14:27 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 54956 ms on 192.168.33.10 (executor 1) (107/409)
18/09/26 11:14:28 INFO TaskSetManager: Starting task 187.0 in stage 0.0 (TID 187, 192.168.33.10, executor 1, partition 187, ANY, 4879 bytes)
18/09/26 11:14:28 INFO TaskSetManager: Finished task 61.0 in stage 0.0 (TID 61) in 55070 ms on 192.168.33.10 (executor 1) (108/409)
18/09/26 11:14:28 INFO TaskSetManager: Starting task 188.0 in stage 0.0 (TID 188, 192.168.33.14, executor 4, partition 188, ANY, 4879 bytes)
18/09/26 11:14:28 INFO TaskSetManager: Finished task 116.0 in stage 0.0 (TID 116) in 14498 ms on 192.168.33.14 (executor 4) (109/409)
18/09/26 11:14:28 INFO TaskSetManager: Starting task 189.0 in stage 0.0 (TID 189, 192.168.33.10, executor 1, partition 189, ANY, 4879 bytes)
18/09/26 11:14:28 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 55375 ms on 192.168.33.10 (executor 1) (110/409)
18/09/26 11:14:29 INFO TaskSetManager: Starting task 190.0 in stage 0.0 (TID 190, 192.168.33.11, executor 5, partition 190, ANY, 4879 bytes)
18/09/26 11:14:29 INFO TaskSetManager: Finished task 120.0 in stage 0.0 (TID 120) in 15382 ms on 192.168.33.11 (executor 5) (111/409)
18/09/26 11:14:29 INFO TaskSetManager: Starting task 191.0 in stage 0.0 (TID 191, 192.168.33.10, executor 1, partition 191, ANY, 4879 bytes)
18/09/26 11:14:29 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 56737 ms on 192.168.33.10 (executor 1) (112/409)
18/09/26 11:14:29 INFO TaskSetManager: Starting task 192.0 in stage 0.0 (TID 192, 192.168.33.14, executor 4, partition 192, ANY, 4879 bytes)
18/09/26 11:14:29 INFO TaskSetManager: Finished task 122.0 in stage 0.0 (TID 122) in 15567 ms on 192.168.33.14 (executor 4) (113/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 193.0 in stage 0.0 (TID 193, 192.168.33.14, executor 4, partition 193, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 126.0 in stage 0.0 (TID 126) in 15263 ms on 192.168.33.14 (executor 4) (114/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 194.0 in stage 0.0 (TID 194, 192.168.33.14, executor 4, partition 194, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 130.0 in stage 0.0 (TID 130) in 14569 ms on 192.168.33.14 (executor 4) (115/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 195.0 in stage 0.0 (TID 195, 192.168.33.11, executor 5, partition 195, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 119.0 in stage 0.0 (TID 119) in 16513 ms on 192.168.33.11 (executor 5) (116/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 196.0 in stage 0.0 (TID 196, 192.168.33.14, executor 4, partition 196, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 128.0 in stage 0.0 (TID 128) in 15482 ms on 192.168.33.14 (executor 4) (117/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 197.0 in stage 0.0 (TID 197, 192.168.33.10, executor 1, partition 197, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 75.0 in stage 0.0 (TID 75) in 57638 ms on 192.168.33.10 (executor 1) (118/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 198.0 in stage 0.0 (TID 198, 192.168.33.10, executor 1, partition 198, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 79.0 in stage 0.0 (TID 79) in 57862 ms on 192.168.33.10 (executor 1) (119/409)
18/09/26 11:14:30 INFO TaskSetManager: Starting task 199.0 in stage 0.0 (TID 199, 192.168.33.14, executor 4, partition 199, ANY, 4879 bytes)
18/09/26 11:14:30 INFO TaskSetManager: Finished task 138.0 in stage 0.0 (TID 138) in 14403 ms on 192.168.33.14 (executor 4) (120/409)
18/09/26 11:14:31 INFO TaskSetManager: Starting task 200.0 in stage 0.0 (TID 200, 192.168.33.11, executor 5, partition 200, ANY, 4879 bytes)
18/09/26 11:14:31 INFO TaskSetManager: Finished task 117.0 in stage 0.0 (TID 117) in 17904 ms on 192.168.33.11 (executor 5) (121/409)
18/09/26 11:14:32 INFO TaskSetManager: Starting task 201.0 in stage 0.0 (TID 201, 192.168.33.15, executor 0, partition 201, ANY, 4879 bytes)
18/09/26 11:14:32 INFO TaskSetManager: Finished task 112.0 in stage 0.0 (TID 112) in 21674 ms on 192.168.33.15 (executor 0) (122/409)
18/09/26 11:14:32 INFO TaskSetManager: Starting task 202.0 in stage 0.0 (TID 202, 192.168.33.14, executor 4, partition 202, ANY, 4879 bytes)
18/09/26 11:14:32 INFO TaskSetManager: Finished task 143.0 in stage 0.0 (TID 143) in 14933 ms on 192.168.33.14 (executor 4) (123/409)
18/09/26 11:14:32 INFO TaskSetManager: Starting task 203.0 in stage 0.0 (TID 203, 192.168.33.11, executor 5, partition 203, ANY, 4879 bytes)
18/09/26 11:14:32 INFO TaskSetManager: Finished task 133.0 in stage 0.0 (TID 133) in 16070 ms on 192.168.33.11 (executor 5) (124/409)
18/09/26 11:14:33 INFO TaskSetManager: Starting task 204.0 in stage 0.0 (TID 204, 192.168.33.14, executor 4, partition 204, ANY, 4879 bytes)
18/09/26 11:14:33 INFO TaskSetManager: Finished task 148.0 in stage 0.0 (TID 148) in 14839 ms on 192.168.33.14 (executor 4) (125/409)
18/09/26 11:14:33 INFO TaskSetManager: Starting task 205.0 in stage 0.0 (TID 205, 192.168.33.11, executor 5, partition 205, ANY, 4879 bytes)
18/09/26 11:14:33 INFO TaskSetManager: Finished task 147.0 in stage 0.0 (TID 147) in 15159 ms on 192.168.33.11 (executor 5) (126/409)
18/09/26 11:14:33 INFO TaskSetManager: Starting task 206.0 in stage 0.0 (TID 206, 192.168.33.11, executor 5, partition 206, ANY, 4879 bytes)
18/09/26 11:14:33 INFO TaskSetManager: Finished task 134.0 in stage 0.0 (TID 134) in 16993 ms on 192.168.33.11 (executor 5) (127/409)
18/09/26 11:14:34 INFO TaskSetManager: Starting task 207.0 in stage 0.0 (TID 207, 192.168.33.11, executor 5, partition 207, ANY, 4879 bytes)
18/09/26 11:14:34 INFO TaskSetManager: Finished task 129.0 in stage 0.0 (TID 129) in 18892 ms on 192.168.33.11 (executor 5) (128/409)
18/09/26 11:14:34 INFO TaskSetManager: Starting task 208.0 in stage 0.0 (TID 208, 192.168.33.13, executor 2, partition 208, ANY, 4879 bytes)
18/09/26 11:14:34 INFO TaskSetManager: Finished task 153.0 in stage 0.0 (TID 153) in 14298 ms on 192.168.33.13 (executor 2) (129/409)
18/09/26 11:14:34 INFO TaskSetManager: Starting task 209.0 in stage 0.0 (TID 209, 192.168.33.13, executor 2, partition 209, ANY, 4879 bytes)
18/09/26 11:14:34 INFO TaskSetManager: Finished task 152.0 in stage 0.0 (TID 152) in 15057 ms on 192.168.33.13 (executor 2) (130/409)
18/09/26 11:14:35 INFO TaskSetManager: Starting task 210.0 in stage 0.0 (TID 210, 192.168.33.13, executor 2, partition 210, ANY, 4879 bytes)
18/09/26 11:14:35 INFO TaskSetManager: Finished task 154.0 in stage 0.0 (TID 154) in 14929 ms on 192.168.33.13 (executor 2) (131/409)
18/09/26 11:14:36 INFO TaskSetManager: Starting task 211.0 in stage 0.0 (TID 211, 192.168.33.13, executor 2, partition 211, ANY, 4879 bytes)
18/09/26 11:14:36 INFO TaskSetManager: Finished task 156.0 in stage 0.0 (TID 156) in 15290 ms on 192.168.33.13 (executor 2) (132/409)
18/09/26 11:14:36 INFO TaskSetManager: Starting task 212.0 in stage 0.0 (TID 212, 192.168.33.11, executor 5, partition 212, ANY, 4879 bytes)
18/09/26 11:14:36 INFO TaskSetManager: Finished task 146.0 in stage 0.0 (TID 146) in 18384 ms on 192.168.33.11 (executor 5) (133/409)
18/09/26 11:14:37 INFO TaskSetManager: Starting task 213.0 in stage 0.0 (TID 213, 192.168.33.13, executor 2, partition 213, ANY, 4879 bytes)
18/09/26 11:14:37 INFO TaskSetManager: Finished task 155.0 in stage 0.0 (TID 155) in 16661 ms on 192.168.33.13 (executor 2) (134/409)
18/09/26 11:14:39 INFO TaskSetManager: Starting task 214.0 in stage 0.0 (TID 214, 192.168.33.13, executor 2, partition 214, ANY, 4879 bytes)
18/09/26 11:14:39 INFO TaskSetManager: Finished task 163.0 in stage 0.0 (TID 163) in 16953 ms on 192.168.33.13 (executor 2) (135/409)
18/09/26 11:14:41 INFO TaskSetManager: Starting task 215.0 in stage 0.0 (TID 215, 192.168.33.13, executor 2, partition 215, ANY, 4879 bytes)
18/09/26 11:14:41 INFO TaskSetManager: Finished task 161.0 in stage 0.0 (TID 161) in 19053 ms on 192.168.33.13 (executor 2) (136/409)
18/09/26 11:14:41 INFO TaskSetManager: Starting task 216.0 in stage 0.0 (TID 216, 192.168.33.15, executor 0, partition 216, ANY, 4879 bytes)
18/09/26 11:14:41 INFO TaskSetManager: Finished task 115.0 in stage 0.0 (TID 115) in 28273 ms on 192.168.33.15 (executor 0) (137/409)
18/09/26 11:14:42 INFO TaskSetManager: Starting task 217.0 in stage 0.0 (TID 217, 192.168.33.12, executor 3, partition 217, ANY, 4879 bytes)
18/09/26 11:14:42 INFO TaskSetManager: Finished task 159.0 in stage 0.0 (TID 159) in 20159 ms on 192.168.33.12 (executor 3) (138/409)
18/09/26 11:14:42 INFO TaskSetManager: Starting task 218.0 in stage 0.0 (TID 218, 192.168.33.12, executor 3, partition 218, ANY, 4879 bytes)
18/09/26 11:14:42 INFO TaskSetManager: Finished task 166.0 in stage 0.0 (TID 166) in 18968 ms on 192.168.33.12 (executor 3) (139/409)
18/09/26 11:14:42 INFO TaskSetManager: Starting task 219.0 in stage 0.0 (TID 219, 192.168.33.12, executor 3, partition 219, ANY, 4879 bytes)
18/09/26 11:14:42 INFO TaskSetManager: Finished task 162.0 in stage 0.0 (TID 162) in 20020 ms on 192.168.33.12 (executor 3) (140/409)
18/09/26 11:14:42 INFO TaskSetManager: Starting task 220.0 in stage 0.0 (TID 220, 192.168.33.15, executor 0, partition 220, ANY, 4879 bytes)
18/09/26 11:14:42 INFO TaskSetManager: Finished task 123.0 in stage 0.0 (TID 123) in 28216 ms on 192.168.33.15 (executor 0) (141/409)
18/09/26 11:14:42 INFO TaskSetManager: Starting task 221.0 in stage 0.0 (TID 221, 192.168.33.15, executor 0, partition 221, ANY, 4879 bytes)
18/09/26 11:14:42 INFO TaskSetManager: Finished task 113.0 in stage 0.0 (TID 113) in 29848 ms on 192.168.33.15 (executor 0) (142/409)
18/09/26 11:14:43 INFO TaskSetManager: Starting task 222.0 in stage 0.0 (TID 222, 192.168.33.14, executor 4, partition 222, ANY, 4879 bytes)
18/09/26 11:14:43 INFO TaskSetManager: Finished task 188.0 in stage 0.0 (TID 188) in 15097 ms on 192.168.33.14 (executor 4) (143/409)
18/09/26 11:14:43 INFO TaskSetManager: Starting task 223.0 in stage 0.0 (TID 223, 192.168.33.15, executor 0, partition 223, ANY, 4879 bytes)
18/09/26 11:14:43 INFO TaskSetManager: Finished task 121.0 in stage 0.0 (TID 121) in 29217 ms on 192.168.33.15 (executor 0) (144/409)
18/09/26 11:14:43 INFO TaskSetManager: Starting task 224.0 in stage 0.0 (TID 224, 192.168.33.12, executor 3, partition 224, ANY, 4879 bytes)
18/09/26 11:14:43 INFO TaskSetManager: Finished task 158.0 in stage 0.0 (TID 158) in 21747 ms on 192.168.33.12 (executor 3) (145/409)
18/09/26 11:14:43 INFO TaskSetManager: Starting task 225.0 in stage 0.0 (TID 225, 192.168.33.12, executor 3, partition 225, ANY, 4879 bytes)
18/09/26 11:14:43 INFO TaskSetManager: Finished task 160.0 in stage 0.0 (TID 160) in 21946 ms on 192.168.33.12 (executor 3) (146/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 226.0 in stage 0.0 (TID 226, 192.168.33.15, executor 0, partition 226, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 124.0 in stage 0.0 (TID 124) in 29346 ms on 192.168.33.15 (executor 0) (147/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 227.0 in stage 0.0 (TID 227, 192.168.33.13, executor 2, partition 227, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 164.0 in stage 0.0 (TID 164) in 20849 ms on 192.168.33.13 (executor 2) (148/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 228.0 in stage 0.0 (TID 228, 192.168.33.12, executor 3, partition 228, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 167.0 in stage 0.0 (TID 167) in 20714 ms on 192.168.33.12 (executor 3) (149/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 229.0 in stage 0.0 (TID 229, 192.168.33.15, executor 0, partition 229, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 127.0 in stage 0.0 (TID 127) in 29463 ms on 192.168.33.15 (executor 0) (150/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 230.0 in stage 0.0 (TID 230, 192.168.33.15, executor 0, partition 230, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 125.0 in stage 0.0 (TID 125) in 29842 ms on 192.168.33.15 (executor 0) (151/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 231.0 in stage 0.0 (TID 231, 192.168.33.11, executor 5, partition 231, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 190.0 in stage 0.0 (TID 190) in 15062 ms on 192.168.33.11 (executor 5) (152/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 232.0 in stage 0.0 (TID 232, 192.168.33.12, executor 3, partition 232, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 165.0 in stage 0.0 (TID 165) in 21325 ms on 192.168.33.12 (executor 3) (153/409)
18/09/26 11:14:44 INFO TaskSetManager: Starting task 233.0 in stage 0.0 (TID 233, 192.168.33.12, executor 3, partition 233, ANY, 4879 bytes)
18/09/26 11:14:44 INFO TaskSetManager: Finished task 170.0 in stage 0.0 (TID 170) in 21048 ms on 192.168.33.12 (executor 3) (154/409)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 234.0 in stage 0.0 (TID 234, 192.168.33.14, executor 4, partition 234, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 199.0 in stage 0.0 (TID 199) in 14078 ms on 192.168.33.14 (executor 4) (155/409)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 235.0 in stage 0.0 (TID 235, 192.168.33.14, executor 4, partition 235, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 192.0 in stage 0.0 (TID 192) in 15209 ms on 192.168.33.14 (executor 4) (156/409)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 236.0 in stage 0.0 (TID 236, 192.168.33.14, executor 4, partition 236, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 193.0 in stage 0.0 (TID 193) in 15311 ms on 192.168.33.14 (executor 4) (157/409)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 237.0 in stage 0.0 (TID 237, 192.168.33.15, executor 0, partition 237, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 114.0 in stage 0.0 (TID 114) in 31936 ms on 192.168.33.15 (executor 0) (158/409)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 238.0 in stage 0.0 (TID 238, 192.168.33.14, executor 4, partition 238, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Starting task 239.0 in stage 0.0 (TID 239, 192.168.33.14, executor 4, partition 239, ANY, 4879 bytes)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 194.0 in stage 0.0 (TID 194) in 15565 ms on 192.168.33.14 (executor 4) (159/409)
18/09/26 11:14:45 INFO TaskSetManager: Finished task 196.0 in stage 0.0 (TID 196) in 15231 ms on 192.168.33.14 (executor 4) (160/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 240.0 in stage 0.0 (TID 240, 192.168.33.15, executor 0, partition 240, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 139.0 in stage 0.0 (TID 139) in 29312 ms on 192.168.33.15 (executor 0) (161/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 241.0 in stage 0.0 (TID 241, 192.168.33.15, executor 0, partition 241, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 137.0 in stage 0.0 (TID 137) in 29544 ms on 192.168.33.15 (executor 0) (162/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 242.0 in stage 0.0 (TID 242, 192.168.33.15, executor 0, partition 242, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 142.0 in stage 0.0 (TID 142) in 29308 ms on 192.168.33.15 (executor 0) (163/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 243.0 in stage 0.0 (TID 243, 192.168.33.15, executor 0, partition 243, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 141.0 in stage 0.0 (TID 141) in 29351 ms on 192.168.33.15 (executor 0) (164/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 244.0 in stage 0.0 (TID 244, 192.168.33.15, executor 0, partition 244, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 118.0 in stage 0.0 (TID 118) in 32679 ms on 192.168.33.15 (executor 0) (165/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 245.0 in stage 0.0 (TID 245, 192.168.33.15, executor 0, partition 245, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 140.0 in stage 0.0 (TID 140) in 29686 ms on 192.168.33.15 (executor 0) (166/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 246.0 in stage 0.0 (TID 246, 192.168.33.15, executor 0, partition 246, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 132.0 in stage 0.0 (TID 132) in 30627 ms on 192.168.33.15 (executor 0) (167/409)
18/09/26 11:14:46 INFO TaskSetManager: Starting task 247.0 in stage 0.0 (TID 247, 192.168.33.15, executor 0, partition 247, ANY, 4879 bytes)
18/09/26 11:14:46 INFO TaskSetManager: Finished task 145.0 in stage 0.0 (TID 145) in 28896 ms on 192.168.33.15 (executor 0) (168/409)
18/09/26 11:14:47 INFO TaskSetManager: Starting task 248.0 in stage 0.0 (TID 248, 192.168.33.11, executor 5, partition 248, ANY, 4879 bytes)
18/09/26 11:14:47 INFO TaskSetManager: Finished task 195.0 in stage 0.0 (TID 195) in 16799 ms on 192.168.33.11 (executor 5) (169/409)
18/09/26 11:14:48 INFO TaskSetManager: Starting task 249.0 in stage 0.0 (TID 249, 192.168.33.14, executor 4, partition 249, ANY, 4879 bytes)
18/09/26 11:14:48 INFO TaskSetManager: Finished task 202.0 in stage 0.0 (TID 202) in 15823 ms on 192.168.33.14 (executor 4) (170/409)
18/09/26 11:14:48 INFO TaskSetManager: Starting task 250.0 in stage 0.0 (TID 250, 192.168.33.13, executor 2, partition 250, ANY, 4879 bytes)
18/09/26 11:14:48 INFO TaskSetManager: Finished task 208.0 in stage 0.0 (TID 208) in 13826 ms on 192.168.33.13 (executor 2) (171/409)
18/09/26 11:14:48 INFO TaskSetManager: Starting task 251.0 in stage 0.0 (TID 251, 192.168.33.11, executor 5, partition 251, ANY, 4879 bytes)
18/09/26 11:14:48 INFO TaskSetManager: Finished task 206.0 in stage 0.0 (TID 206) in 15097 ms on 192.168.33.11 (executor 5) (172/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 252.0 in stage 0.0 (TID 252, 192.168.33.13, executor 2, partition 252, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 209.0 in stage 0.0 (TID 209) in 14439 ms on 192.168.33.13 (executor 2) (173/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 253.0 in stage 0.0 (TID 253, 192.168.33.15, executor 0, partition 253, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 144.0 in stage 0.0 (TID 144) in 31685 ms on 192.168.33.15 (executor 0) (174/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 254.0 in stage 0.0 (TID 254, 192.168.33.15, executor 0, partition 254, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 255.0 in stage 0.0 (TID 255, 192.168.33.15, executor 0, partition 255, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 149.0 in stage 0.0 (TID 149) in 30848 ms on 192.168.33.15 (executor 0) (175/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 256.0 in stage 0.0 (TID 256, 192.168.33.15, executor 0, partition 256, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 257.0 in stage 0.0 (TID 257, 192.168.33.15, executor 0, partition 257, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 150.0 in stage 0.0 (TID 150) in 30804 ms on 192.168.33.15 (executor 0) (176/409)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 131.0 in stage 0.0 (TID 131) in 33519 ms on 192.168.33.15 (executor 0) (177/409)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 136.0 in stage 0.0 (TID 136) in 32828 ms on 192.168.33.15 (executor 0) (178/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 258.0 in stage 0.0 (TID 258, 192.168.33.14, executor 4, partition 258, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 204.0 in stage 0.0 (TID 204) in 16347 ms on 192.168.33.14 (executor 4) (179/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 259.0 in stage 0.0 (TID 259, 192.168.33.15, executor 0, partition 259, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 135.0 in stage 0.0 (TID 135) in 33385 ms on 192.168.33.15 (executor 0) (180/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 260.0 in stage 0.0 (TID 260, 192.168.33.15, executor 0, partition 260, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 151.0 in stage 0.0 (TID 151) in 31312 ms on 192.168.33.15 (executor 0) (181/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 261.0 in stage 0.0 (TID 261, 192.168.33.11, executor 5, partition 261, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 203.0 in stage 0.0 (TID 203) in 17554 ms on 192.168.33.11 (executor 5) (182/409)
18/09/26 11:14:49 INFO TaskSetManager: Starting task 262.0 in stage 0.0 (TID 262, 192.168.33.13, executor 2, partition 262, ANY, 4879 bytes)
18/09/26 11:14:49 INFO TaskSetManager: Finished task 210.0 in stage 0.0 (TID 210) in 14555 ms on 192.168.33.13 (executor 2) (183/409)
18/09/26 11:14:51 INFO TaskSetManager: Starting task 263.0 in stage 0.0 (TID 263, 192.168.33.11, executor 5, partition 263, ANY, 4879 bytes)
18/09/26 11:14:51 INFO TaskSetManager: Finished task 200.0 in stage 0.0 (TID 200) in 19537 ms on 192.168.33.11 (executor 5) (184/409)
18/09/26 11:14:51 INFO TaskSetManager: Starting task 264.0 in stage 0.0 (TID 264, 192.168.33.11, executor 5, partition 264, ANY, 4879 bytes)
18/09/26 11:14:51 INFO TaskSetManager: Finished task 205.0 in stage 0.0 (TID 205) in 18000 ms on 192.168.33.11 (executor 5) (185/409)
18/09/26 11:14:51 INFO TaskSetManager: Starting task 265.0 in stage 0.0 (TID 265, 192.168.33.10, executor 1, partition 265, ANY, 4879 bytes)
18/09/26 11:14:51 INFO TaskSetManager: Finished task 157.0 in stage 0.0 (TID 157) in 29909 ms on 192.168.33.10 (executor 1) (186/409)
18/09/26 11:14:51 INFO TaskSetManager: Starting task 266.0 in stage 0.0 (TID 266, 192.168.33.13, executor 2, partition 266, ANY, 4879 bytes)
18/09/26 11:14:51 INFO TaskSetManager: Finished task 211.0 in stage 0.0 (TID 211) in 15258 ms on 192.168.33.13 (executor 2) (187/409)
18/09/26 11:14:51 INFO TaskSetManager: Starting task 267.0 in stage 0.0 (TID 267, 192.168.33.15, executor 0, partition 267, ANY, 4879 bytes)
18/09/26 11:14:51 INFO TaskSetManager: Finished task 201.0 in stage 0.0 (TID 201) in 19522 ms on 192.168.33.15 (executor 0) (188/409)
18/09/26 11:14:52 INFO TaskSetManager: Starting task 268.0 in stage 0.0 (TID 268, 192.168.33.11, executor 5, partition 268, ANY, 4879 bytes)
18/09/26 11:14:52 INFO TaskSetManager: Finished task 212.0 in stage 0.0 (TID 212) in 15887 ms on 192.168.33.11 (executor 5) (189/409)
18/09/26 11:14:52 INFO TaskSetManager: Starting task 269.0 in stage 0.0 (TID 269, 192.168.33.11, executor 5, partition 269, ANY, 4879 bytes)
18/09/26 11:14:52 INFO TaskSetManager: Finished task 207.0 in stage 0.0 (TID 207) in 18308 ms on 192.168.33.11 (executor 5) (190/409)
18/09/26 11:14:53 INFO TaskSetManager: Starting task 270.0 in stage 0.0 (TID 270, 192.168.33.13, executor 2, partition 270, ANY, 4879 bytes)
18/09/26 11:14:53 INFO TaskSetManager: Finished task 213.0 in stage 0.0 (TID 213) in 16135 ms on 192.168.33.13 (executor 2) (191/409)
18/09/26 11:14:55 INFO TaskSetManager: Starting task 271.0 in stage 0.0 (TID 271, 192.168.33.13, executor 2, partition 271, ANY, 4879 bytes)
18/09/26 11:14:55 INFO TaskSetManager: Finished task 215.0 in stage 0.0 (TID 215) in 14404 ms on 192.168.33.13 (executor 2) (192/409)
18/09/26 11:14:56 INFO TaskSetManager: Starting task 272.0 in stage 0.0 (TID 272, 192.168.33.13, executor 2, partition 272, ANY, 4879 bytes)
18/09/26 11:14:56 INFO TaskSetManager: Finished task 214.0 in stage 0.0 (TID 214) in 16346 ms on 192.168.33.13 (executor 2) (193/409)
18/09/26 11:14:58 INFO TaskSetManager: Starting task 273.0 in stage 0.0 (TID 273, 192.168.33.12, executor 3, partition 273, ANY, 4879 bytes)
18/09/26 11:14:58 INFO TaskSetManager: Finished task 217.0 in stage 0.0 (TID 217) in 16407 ms on 192.168.33.12 (executor 3) (194/409)
18/09/26 11:14:58 INFO TaskSetManager: Starting task 274.0 in stage 0.0 (TID 274, 192.168.33.13, executor 2, partition 274, ANY, 4879 bytes)
18/09/26 11:14:58 INFO TaskSetManager: Finished task 227.0 in stage 0.0 (TID 227) in 14598 ms on 192.168.33.13 (executor 2) (195/409)
18/09/26 11:14:58 INFO TaskSetManager: Starting task 275.0 in stage 0.0 (TID 275, 192.168.33.14, executor 4, partition 275, ANY, 4879 bytes)
18/09/26 11:14:58 INFO TaskSetManager: Finished task 234.0 in stage 0.0 (TID 234) in 13888 ms on 192.168.33.14 (executor 4) (196/409)
18/09/26 11:14:59 INFO TaskSetManager: Starting task 276.0 in stage 0.0 (TID 276, 192.168.33.12, executor 3, partition 276, ANY, 4879 bytes)
18/09/26 11:14:59 INFO TaskSetManager: Finished task 219.0 in stage 0.0 (TID 219) in 17333 ms on 192.168.33.12 (executor 3) (197/409)
18/09/26 11:14:59 INFO TaskSetManager: Starting task 277.0 in stage 0.0 (TID 277, 192.168.33.12, executor 3, partition 277, ANY, 4879 bytes)
18/09/26 11:14:59 INFO TaskSetManager: Finished task 218.0 in stage 0.0 (TID 218) in 17582 ms on 192.168.33.12 (executor 3) (198/409)
18/09/26 11:15:00 INFO TaskSetManager: Starting task 278.0 in stage 0.0 (TID 278, 192.168.33.14, executor 4, partition 278, ANY, 4879 bytes)
18/09/26 11:15:00 INFO TaskSetManager: Finished task 235.0 in stage 0.0 (TID 235) in 15606 ms on 192.168.33.14 (executor 4) (199/409)
18/09/26 11:15:01 INFO TaskSetManager: Starting task 279.0 in stage 0.0 (TID 279, 192.168.33.11, executor 5, partition 279, ANY, 4879 bytes)
18/09/26 11:15:01 INFO TaskSetManager: Finished task 231.0 in stage 0.0 (TID 231) in 16935 ms on 192.168.33.11 (executor 5) (200/409)
18/09/26 11:15:01 INFO TaskSetManager: Starting task 280.0 in stage 0.0 (TID 280, 192.168.33.14, executor 4, partition 280, ANY, 4879 bytes)
18/09/26 11:15:01 INFO TaskSetManager: Finished task 236.0 in stage 0.0 (TID 236) in 16548 ms on 192.168.33.14 (executor 4) (201/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 281.0 in stage 0.0 (TID 281, 192.168.33.13, executor 2, partition 281, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 250.0 in stage 0.0 (TID 250) in 13584 ms on 192.168.33.13 (executor 2) (202/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 282.0 in stage 0.0 (TID 282, 192.168.33.14, executor 4, partition 282, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 222.0 in stage 0.0 (TID 222) in 18921 ms on 192.168.33.14 (executor 4) (203/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 283.0 in stage 0.0 (TID 283, 192.168.33.12, executor 3, partition 283, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 224.0 in stage 0.0 (TID 224) in 18580 ms on 192.168.33.12 (executor 3) (204/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 284.0 in stage 0.0 (TID 284, 192.168.33.11, executor 5, partition 284, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 251.0 in stage 0.0 (TID 251) in 13828 ms on 192.168.33.11 (executor 5) (205/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 285.0 in stage 0.0 (TID 285, 192.168.33.14, executor 4, partition 285, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 249.0 in stage 0.0 (TID 249) in 14278 ms on 192.168.33.14 (executor 4) (206/409)
18/09/26 11:15:02 INFO TaskSetManager: Starting task 286.0 in stage 0.0 (TID 286, 192.168.33.12, executor 3, partition 286, ANY, 4879 bytes)
18/09/26 11:15:02 INFO TaskSetManager: Finished task 225.0 in stage 0.0 (TID 225) in 18446 ms on 192.168.33.12 (executor 3) (207/409)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 287.0 in stage 0.0 (TID 287, 192.168.33.12, executor 3, partition 287, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 233.0 in stage 0.0 (TID 233) in 18393 ms on 192.168.33.12 (executor 3) (208/409)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 288.0 in stage 0.0 (TID 288, 192.168.33.12, executor 3, partition 288, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 232.0 in stage 0.0 (TID 232) in 18847 ms on 192.168.33.12 (executor 3) (209/409)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 289.0 in stage 0.0 (TID 289, 192.168.33.15, executor 0, partition 289, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 221.0 in stage 0.0 (TID 221) in 20788 ms on 192.168.33.15 (executor 0) (210/409)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 290.0 in stage 0.0 (TID 290, 192.168.33.12, executor 3, partition 290, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 228.0 in stage 0.0 (TID 228) in 19470 ms on 192.168.33.12 (executor 3) (211/409)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 291.0 in stage 0.0 (TID 291, 192.168.33.14, executor 4, partition 291, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Starting task 292.0 in stage 0.0 (TID 292, 192.168.33.14, executor 4, partition 292, ANY, 4879 bytes)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 239.0 in stage 0.0 (TID 239) in 17802 ms on 192.168.33.14 (executor 4) (212/409)
18/09/26 11:15:03 INFO TaskSetManager: Finished task 238.0 in stage 0.0 (TID 238) in 17805 ms on 192.168.33.14 (executor 4) (213/409)
18/09/26 11:15:04 INFO TaskSetManager: Starting task 293.0 in stage 0.0 (TID 293, 192.168.33.11, executor 5, partition 293, ANY, 4879 bytes)
18/09/26 11:15:04 INFO TaskSetManager: Finished task 248.0 in stage 0.0 (TID 248) in 16827 ms on 192.168.33.11 (executor 5) (214/409)
18/09/26 11:15:04 INFO TaskSetManager: Starting task 294.0 in stage 0.0 (TID 294, 192.168.33.14, executor 4, partition 294, ANY, 4879 bytes)
18/09/26 11:15:04 INFO TaskSetManager: Finished task 258.0 in stage 0.0 (TID 258) in 14895 ms on 192.168.33.14 (executor 4) (215/409)
18/09/26 11:15:04 INFO TaskSetManager: Starting task 295.0 in stage 0.0 (TID 295, 192.168.33.10, executor 1, partition 295, ANY, 4879 bytes)
18/09/26 11:15:04 INFO TaskSetManager: Finished task 171.0 in stage 0.0 (TID 171) in 40563 ms on 192.168.33.10 (executor 1) (216/409)
18/09/26 11:15:04 INFO TaskSetManager: Starting task 296.0 in stage 0.0 (TID 296, 192.168.33.15, executor 0, partition 296, ANY, 4879 bytes)
18/09/26 11:15:04 INFO TaskSetManager: Finished task 220.0 in stage 0.0 (TID 220) in 21760 ms on 192.168.33.15 (executor 0) (217/409)
18/09/26 11:15:04 INFO TaskSetManager: Starting task 297.0 in stage 0.0 (TID 297, 192.168.33.15, executor 0, partition 297, ANY, 4879 bytes)
18/09/26 11:15:04 INFO TaskSetManager: Finished task 216.0 in stage 0.0 (TID 216) in 22729 ms on 192.168.33.15 (executor 0) (218/409)
18/09/26 11:15:05 INFO TaskSetManager: Starting task 298.0 in stage 0.0 (TID 298, 192.168.33.13, executor 2, partition 298, ANY, 4879 bytes)
18/09/26 11:15:05 INFO TaskSetManager: Finished task 252.0 in stage 0.0 (TID 252) in 15994 ms on 192.168.33.13 (executor 2) (219/409)
18/09/26 11:15:05 INFO TaskSetManager: Starting task 299.0 in stage 0.0 (TID 299, 192.168.33.10, executor 1, partition 299, ANY, 4879 bytes)
18/09/26 11:15:05 INFO TaskSetManager: Finished task 168.0 in stage 0.0 (TID 168) in 41908 ms on 192.168.33.10 (executor 1) (220/409)
18/09/26 11:15:05 INFO TaskSetManager: Starting task 300.0 in stage 0.0 (TID 300, 192.168.33.13, executor 2, partition 300, ANY, 4879 bytes)
18/09/26 11:15:05 INFO TaskSetManager: Finished task 262.0 in stage 0.0 (TID 262) in 15643 ms on 192.168.33.13 (executor 2) (221/409)
18/09/26 11:15:06 INFO TaskSetManager: Starting task 301.0 in stage 0.0 (TID 301, 192.168.33.15, executor 0, partition 301, ANY, 4879 bytes)
18/09/26 11:15:06 INFO TaskSetManager: Finished task 223.0 in stage 0.0 (TID 223) in 23086 ms on 192.168.33.15 (executor 0) (222/409)
18/09/26 11:15:07 INFO TaskSetManager: Starting task 302.0 in stage 0.0 (TID 302, 192.168.33.15, executor 0, partition 302, ANY, 4879 bytes)
18/09/26 11:15:07 INFO TaskSetManager: Finished task 226.0 in stage 0.0 (TID 226) in 23002 ms on 192.168.33.15 (executor 0) (223/409)
18/09/26 11:15:07 INFO TaskSetManager: Starting task 303.0 in stage 0.0 (TID 303, 192.168.33.11, executor 5, partition 303, ANY, 4879 bytes)
18/09/26 11:15:07 INFO TaskSetManager: Finished task 261.0 in stage 0.0 (TID 261) in 17707 ms on 192.168.33.11 (executor 5) (224/409)
18/09/26 11:15:08 INFO TaskSetManager: Starting task 304.0 in stage 0.0 (TID 304, 192.168.33.13, executor 2, partition 304, ANY, 4879 bytes)
18/09/26 11:15:08 INFO TaskSetManager: Finished task 266.0 in stage 0.0 (TID 266) in 16632 ms on 192.168.33.13 (executor 2) (225/409)
18/09/26 11:15:08 INFO TaskSetManager: Starting task 305.0 in stage 0.0 (TID 305, 192.168.33.11, executor 5, partition 305, ANY, 4879 bytes)
18/09/26 11:15:08 INFO TaskSetManager: Finished task 264.0 in stage 0.0 (TID 264) in 16904 ms on 192.168.33.11 (executor 5) (226/409)
18/09/26 11:15:08 INFO TaskSetManager: Starting task 306.0 in stage 0.0 (TID 306, 192.168.33.11, executor 5, partition 306, ANY, 4879 bytes)
18/09/26 11:15:08 INFO TaskSetManager: Finished task 263.0 in stage 0.0 (TID 263) in 17304 ms on 192.168.33.11 (executor 5) (227/409)
18/09/26 11:15:08 INFO TaskSetManager: Starting task 307.0 in stage 0.0 (TID 307, 192.168.33.10, executor 1, partition 307, ANY, 4879 bytes)
18/09/26 11:15:08 INFO TaskSetManager: Finished task 178.0 in stage 0.0 (TID 178) in 42566 ms on 192.168.33.10 (executor 1) (228/409)
18/09/26 11:15:08 INFO TaskSetManager: Starting task 308.0 in stage 0.0 (TID 308, 192.168.33.11, executor 5, partition 308, ANY, 4879 bytes)
18/09/26 11:15:08 INFO TaskSetManager: Finished task 268.0 in stage 0.0 (TID 268) in 16393 ms on 192.168.33.11 (executor 5) (229/409)
18/09/26 11:15:09 INFO TaskSetManager: Starting task 309.0 in stage 0.0 (TID 309, 192.168.33.15, executor 0, partition 309, ANY, 4879 bytes)
18/09/26 11:15:09 INFO TaskSetManager: Finished task 237.0 in stage 0.0 (TID 237) in 23683 ms on 192.168.33.15 (executor 0) (230/409)
18/09/26 11:15:09 INFO TaskSetManager: Starting task 310.0 in stage 0.0 (TID 310, 192.168.33.13, executor 2, partition 310, ANY, 4879 bytes)
18/09/26 11:15:09 INFO TaskSetManager: Finished task 270.0 in stage 0.0 (TID 270) in 15829 ms on 192.168.33.13 (executor 2) (231/409)
18/09/26 11:15:09 INFO TaskSetManager: Starting task 311.0 in stage 0.0 (TID 311, 192.168.33.11, executor 5, partition 311, ANY, 4879 bytes)
18/09/26 11:15:09 INFO TaskSetManager: Finished task 269.0 in stage 0.0 (TID 269) in 16917 ms on 192.168.33.11 (executor 5) (232/409)
18/09/26 11:15:09 INFO TaskSetManager: Starting task 312.0 in stage 0.0 (TID 312, 192.168.33.13, executor 2, partition 312, ANY, 4879 bytes)
18/09/26 11:15:09 INFO TaskSetManager: Finished task 271.0 in stage 0.0 (TID 271) in 14093 ms on 192.168.33.13 (executor 2) (233/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 313.0 in stage 0.0 (TID 313, 192.168.33.15, executor 0, partition 313, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 230.0 in stage 0.0 (TID 230) in 25705 ms on 192.168.33.15 (executor 0) (234/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 314.0 in stage 0.0 (TID 314, 192.168.33.10, executor 1, partition 314, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 173.0 in stage 0.0 (TID 173) in 45833 ms on 192.168.33.10 (executor 1) (235/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 315.0 in stage 0.0 (TID 315, 192.168.33.10, executor 1, partition 315, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 179.0 in stage 0.0 (TID 179) in 44253 ms on 192.168.33.10 (executor 1) (236/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 316.0 in stage 0.0 (TID 316, 192.168.33.15, executor 0, partition 316, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 244.0 in stage 0.0 (TID 244) in 24139 ms on 192.168.33.15 (executor 0) (237/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 317.0 in stage 0.0 (TID 317, 192.168.33.10, executor 1, partition 317, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 169.0 in stage 0.0 (TID 169) in 46987 ms on 192.168.33.10 (executor 1) (238/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 318.0 in stage 0.0 (TID 318, 192.168.33.10, executor 1, partition 318, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 172.0 in stage 0.0 (TID 172) in 46049 ms on 192.168.33.10 (executor 1) (239/409)
18/09/26 11:15:10 INFO TaskSetManager: Starting task 319.0 in stage 0.0 (TID 319, 192.168.33.15, executor 0, partition 319, ANY, 4879 bytes)
18/09/26 11:15:10 INFO TaskSetManager: Finished task 229.0 in stage 0.0 (TID 229) in 26198 ms on 192.168.33.15 (executor 0) (240/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 320.0 in stage 0.0 (TID 320, 192.168.33.10, executor 1, partition 320, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 176.0 in stage 0.0 (TID 176) in 46218 ms on 192.168.33.10 (executor 1) (241/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 321.0 in stage 0.0 (TID 321, 192.168.33.10, executor 1, partition 321, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 186.0 in stage 0.0 (TID 186) in 43304 ms on 192.168.33.10 (executor 1) (242/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 322.0 in stage 0.0 (TID 322, 192.168.33.15, executor 0, partition 322, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 240.0 in stage 0.0 (TID 240) in 25263 ms on 192.168.33.15 (executor 0) (243/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 323.0 in stage 0.0 (TID 323, 192.168.33.14, executor 4, partition 323, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 275.0 in stage 0.0 (TID 275) in 12496 ms on 192.168.33.14 (executor 4) (244/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 324.0 in stage 0.0 (TID 324, 192.168.33.13, executor 2, partition 324, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 272.0 in stage 0.0 (TID 272) in 15561 ms on 192.168.33.13 (executor 2) (245/409)
18/09/26 11:15:11 INFO TaskSetManager: Starting task 325.0 in stage 0.0 (TID 325, 192.168.33.10, executor 1, partition 325, ANY, 4879 bytes)
18/09/26 11:15:11 INFO TaskSetManager: Finished task 180.0 in stage 0.0 (TID 180) in 45516 ms on 192.168.33.10 (executor 1) (246/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 326.0 in stage 0.0 (TID 326, 192.168.33.15, executor 0, partition 326, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 245.0 in stage 0.0 (TID 245) in 25882 ms on 192.168.33.15 (executor 0) (247/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 327.0 in stage 0.0 (TID 327, 192.168.33.10, executor 1, partition 327, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 183.0 in stage 0.0 (TID 183) in 44946 ms on 192.168.33.10 (executor 1) (248/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 328.0 in stage 0.0 (TID 328, 192.168.33.10, executor 1, partition 328, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 181.0 in stage 0.0 (TID 181) in 45544 ms on 192.168.33.10 (executor 1) (249/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 329.0 in stage 0.0 (TID 329, 192.168.33.15, executor 0, partition 329, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 247.0 in stage 0.0 (TID 247) in 25932 ms on 192.168.33.15 (executor 0) (250/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 330.0 in stage 0.0 (TID 330, 192.168.33.10, executor 1, partition 330, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 174.0 in stage 0.0 (TID 174) in 47842 ms on 192.168.33.10 (executor 1) (251/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 331.0 in stage 0.0 (TID 331, 192.168.33.15, executor 0, partition 331, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 242.0 in stage 0.0 (TID 242) in 26452 ms on 192.168.33.15 (executor 0) (252/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 332.0 in stage 0.0 (TID 332, 192.168.33.10, executor 1, partition 332, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 184.0 in stage 0.0 (TID 184) in 45180 ms on 192.168.33.10 (executor 1) (253/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 333.0 in stage 0.0 (TID 333, 192.168.33.15, executor 0, partition 333, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 253.0 in stage 0.0 (TID 253) in 23430 ms on 192.168.33.15 (executor 0) (254/409)
18/09/26 11:15:12 INFO TaskSetManager: Starting task 334.0 in stage 0.0 (TID 334, 192.168.33.10, executor 1, partition 334, ANY, 4879 bytes)
18/09/26 11:15:12 INFO TaskSetManager: Finished task 182.0 in stage 0.0 (TID 182) in 45496 ms on 192.168.33.10 (executor 1) (255/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 335.0 in stage 0.0 (TID 335, 192.168.33.15, executor 0, partition 335, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 243.0 in stage 0.0 (TID 243) in 26790 ms on 192.168.33.15 (executor 0) (256/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 336.0 in stage 0.0 (TID 336, 192.168.33.15, executor 0, partition 336, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 246.0 in stage 0.0 (TID 246) in 26598 ms on 192.168.33.15 (executor 0) (257/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 337.0 in stage 0.0 (TID 337, 192.168.33.15, executor 0, partition 337, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 255.0 in stage 0.0 (TID 255) in 23892 ms on 192.168.33.15 (executor 0) (258/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 338.0 in stage 0.0 (TID 338, 192.168.33.13, executor 2, partition 338, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 274.0 in stage 0.0 (TID 274) in 14620 ms on 192.168.33.13 (executor 2) (259/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 339.0 in stage 0.0 (TID 339, 192.168.33.15, executor 0, partition 339, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 254.0 in stage 0.0 (TID 254) in 24011 ms on 192.168.33.15 (executor 0) (260/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 340.0 in stage 0.0 (TID 340, 192.168.33.10, executor 1, partition 340, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 185.0 in stage 0.0 (TID 185) in 45692 ms on 192.168.33.10 (executor 1) (261/409)
18/09/26 11:15:13 INFO TaskSetManager: Starting task 341.0 in stage 0.0 (TID 341, 192.168.33.15, executor 0, partition 341, ANY, 4879 bytes)
18/09/26 11:15:13 INFO TaskSetManager: Finished task 256.0 in stage 0.0 (TID 256) in 24344 ms on 192.168.33.15 (executor 0) (262/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 342.0 in stage 0.0 (TID 342, 192.168.33.12, executor 3, partition 342, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 273.0 in stage 0.0 (TID 273) in 15655 ms on 192.168.33.12 (executor 3) (263/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 343.0 in stage 0.0 (TID 343, 192.168.33.10, executor 1, partition 343, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 197.0 in stage 0.0 (TID 197) in 43809 ms on 192.168.33.10 (executor 1) (264/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 344.0 in stage 0.0 (TID 344, 192.168.33.10, executor 1, partition 344, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 187.0 in stage 0.0 (TID 187) in 46482 ms on 192.168.33.10 (executor 1) (265/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 345.0 in stage 0.0 (TID 345, 192.168.33.10, executor 1, partition 345, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 189.0 in stage 0.0 (TID 189) in 46207 ms on 192.168.33.10 (executor 1) (266/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 346.0 in stage 0.0 (TID 346, 192.168.33.15, executor 0, partition 346, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 257.0 in stage 0.0 (TID 257) in 25241 ms on 192.168.33.15 (executor 0) (267/409)
18/09/26 11:15:14 INFO TaskSetManager: Starting task 347.0 in stage 0.0 (TID 347, 192.168.33.10, executor 1, partition 347, ANY, 4879 bytes)
18/09/26 11:15:14 INFO TaskSetManager: Finished task 191.0 in stage 0.0 (TID 191) in 44955 ms on 192.168.33.10 (executor 1) (268/409)
18/09/26 11:15:15 INFO TaskSetManager: Starting task 348.0 in stage 0.0 (TID 348, 192.168.33.12, executor 3, partition 348, ANY, 4879 bytes)
18/09/26 11:15:15 INFO TaskSetManager: Finished task 277.0 in stage 0.0 (TID 277) in 15588 ms on 192.168.33.12 (executor 3) (269/409)
18/09/26 11:15:15 INFO TaskSetManager: Starting task 349.0 in stage 0.0 (TID 349, 192.168.33.10, executor 1, partition 349, ANY, 4879 bytes)
18/09/26 11:15:15 INFO TaskSetManager: Finished task 175.0 in stage 0.0 (TID 175) in 51007 ms on 192.168.33.10 (executor 1) (270/409)
18/09/26 11:15:15 INFO TaskSetManager: Starting task 350.0 in stage 0.0 (TID 350, 192.168.33.15, executor 0, partition 350, ANY, 4879 bytes)
18/09/26 11:15:15 INFO TaskSetManager: Finished task 260.0 in stage 0.0 (TID 260) in 26053 ms on 192.168.33.15 (executor 0) (271/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 351.0 in stage 0.0 (TID 351, 192.168.33.10, executor 1, partition 351, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 177.0 in stage 0.0 (TID 177) in 50380 ms on 192.168.33.10 (executor 1) (272/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 352.0 in stage 0.0 (TID 352, 192.168.33.15, executor 0, partition 352, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 267.0 in stage 0.0 (TID 267) in 24534 ms on 192.168.33.15 (executor 0) (273/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 353.0 in stage 0.0 (TID 353, 192.168.33.13, executor 2, partition 353, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 281.0 in stage 0.0 (TID 281) in 14476 ms on 192.168.33.13 (executor 2) (274/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 354.0 in stage 0.0 (TID 354, 192.168.33.11, executor 5, partition 354, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 284.0 in stage 0.0 (TID 284) in 14280 ms on 192.168.33.11 (executor 5) (275/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 355.0 in stage 0.0 (TID 355, 192.168.33.14, executor 4, partition 355, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 278.0 in stage 0.0 (TID 278) in 15838 ms on 192.168.33.14 (executor 4) (276/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 356.0 in stage 0.0 (TID 356, 192.168.33.10, executor 1, partition 356, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 198.0 in stage 0.0 (TID 198) in 45856 ms on 192.168.33.10 (executor 1) (277/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 357.0 in stage 0.0 (TID 357, 192.168.33.15, executor 0, partition 357, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 259.0 in stage 0.0 (TID 259) in 27111 ms on 192.168.33.15 (executor 0) (278/409)
18/09/26 11:15:16 INFO TaskSetManager: Starting task 358.0 in stage 0.0 (TID 358, 192.168.33.14, executor 4, partition 358, ANY, 4879 bytes)
18/09/26 11:15:16 INFO TaskSetManager: Finished task 285.0 in stage 0.0 (TID 285) in 14528 ms on 192.168.33.14 (executor 4) (279/409)
18/09/26 11:15:17 INFO TaskSetManager: Starting task 359.0 in stage 0.0 (TID 359, 192.168.33.14, executor 4, partition 359, ANY, 4879 bytes)
18/09/26 11:15:17 INFO TaskSetManager: Finished task 280.0 in stage 0.0 (TID 280) in 15172 ms on 192.168.33.14 (executor 4) (280/409)
18/09/26 11:15:17 INFO TaskSetManager: Starting task 360.0 in stage 0.0 (TID 360, 192.168.33.12, executor 3, partition 360, ANY, 4879 bytes)
18/09/26 11:15:17 INFO TaskSetManager: Finished task 276.0 in stage 0.0 (TID 276) in 17735 ms on 192.168.33.12 (executor 3) (281/409)
18/09/26 11:15:17 INFO TaskSetManager: Starting task 361.0 in stage 0.0 (TID 361, 192.168.33.11, executor 5, partition 361, ANY, 4879 bytes)
18/09/26 11:15:17 INFO TaskSetManager: Finished task 279.0 in stage 0.0 (TID 279) in 16091 ms on 192.168.33.11 (executor 5) (282/409)
18/09/26 11:15:17 INFO TaskSetManager: Starting task 362.0 in stage 0.0 (TID 362, 192.168.33.14, executor 4, partition 362, ANY, 4879 bytes)
18/09/26 11:15:17 INFO TaskSetManager: Finished task 282.0 in stage 0.0 (TID 282) in 15523 ms on 192.168.33.14 (executor 4) (283/409)
18/09/26 11:15:18 INFO TaskSetManager: Starting task 363.0 in stage 0.0 (TID 363, 192.168.33.11, executor 5, partition 363, ANY, 4879 bytes)
18/09/26 11:15:18 INFO TaskSetManager: Finished task 293.0 in stage 0.0 (TID 293) in 14292 ms on 192.168.33.11 (executor 5) (284/409)
18/09/26 11:15:18 INFO TaskSetManager: Starting task 364.0 in stage 0.0 (TID 364, 192.168.33.13, executor 2, partition 364, ANY, 4879 bytes)
18/09/26 11:15:18 INFO TaskSetManager: Finished task 300.0 in stage 0.0 (TID 300) in 13216 ms on 192.168.33.13 (executor 2) (285/409)
18/09/26 11:15:19 INFO TaskSetManager: Starting task 365.0 in stage 0.0 (TID 365, 192.168.33.12, executor 3, partition 365, ANY, 4879 bytes)
18/09/26 11:15:19 INFO TaskSetManager: Finished task 286.0 in stage 0.0 (TID 286) in 16680 ms on 192.168.33.12 (executor 3) (286/409)
18/09/26 11:15:19 INFO TaskSetManager: Starting task 366.0 in stage 0.0 (TID 366, 192.168.33.12, executor 3, partition 366, ANY, 4879 bytes)
18/09/26 11:15:19 INFO TaskSetManager: Finished task 283.0 in stage 0.0 (TID 283) in 16976 ms on 192.168.33.12 (executor 3) (287/409)
18/09/26 11:15:19 INFO TaskSetManager: Starting task 367.0 in stage 0.0 (TID 367, 192.168.33.10, executor 1, partition 367, ANY, 4879 bytes)
18/09/26 11:15:19 INFO TaskSetManager: Finished task 265.0 in stage 0.0 (TID 265) in 28208 ms on 192.168.33.10 (executor 1) (288/409)
18/09/26 11:15:19 INFO TaskSetManager: Starting task 368.0 in stage 0.0 (TID 368, 192.168.33.12, executor 3, partition 368, ANY, 4879 bytes)
18/09/26 11:15:19 INFO TaskSetManager: Finished task 290.0 in stage 0.0 (TID 290) in 16011 ms on 192.168.33.12 (executor 3) (289/409)
18/09/26 11:15:20 INFO TaskSetManager: Starting task 369.0 in stage 0.0 (TID 369, 192.168.33.13, executor 2, partition 369, ANY, 4879 bytes)
18/09/26 11:15:20 INFO TaskSetManager: Finished task 298.0 in stage 0.0 (TID 298) in 14886 ms on 192.168.33.13 (executor 2) (290/409)
18/09/26 11:15:20 INFO TaskSetManager: Starting task 370.0 in stage 0.0 (TID 370, 192.168.33.12, executor 3, partition 370, ANY, 4879 bytes)
18/09/26 11:15:20 INFO TaskSetManager: Finished task 288.0 in stage 0.0 (TID 288) in 17155 ms on 192.168.33.12 (executor 3) (291/409)
18/09/26 11:15:20 INFO TaskSetManager: Starting task 371.0 in stage 0.0 (TID 371, 192.168.33.12, executor 3, partition 371, ANY, 4879 bytes)
18/09/26 11:15:20 INFO TaskSetManager: Finished task 287.0 in stage 0.0 (TID 287) in 17825 ms on 192.168.33.12 (executor 3) (292/409)
18/09/26 11:15:21 INFO TaskSetManager: Starting task 372.0 in stage 0.0 (TID 372, 192.168.33.14, executor 4, partition 372, ANY, 4879 bytes)
18/09/26 11:15:21 INFO TaskSetManager: Finished task 292.0 in stage 0.0 (TID 292) in 17726 ms on 192.168.33.14 (executor 4) (293/409)
18/09/26 11:15:21 INFO TaskSetManager: Starting task 373.0 in stage 0.0 (TID 373, 192.168.33.14, executor 4, partition 373, ANY, 4879 bytes)
18/09/26 11:15:21 INFO TaskSetManager: Finished task 294.0 in stage 0.0 (TID 294) in 17434 ms on 192.168.33.14 (executor 4) (294/409)
18/09/26 11:15:22 INFO TaskSetManager: Starting task 374.0 in stage 0.0 (TID 374, 192.168.33.14, executor 4, partition 374, ANY, 4879 bytes)
18/09/26 11:15:22 INFO TaskSetManager: Finished task 291.0 in stage 0.0 (TID 291) in 18675 ms on 192.168.33.14 (executor 4) (295/409)
18/09/26 11:15:22 INFO TaskSetManager: Starting task 375.0 in stage 0.0 (TID 375, 192.168.33.11, executor 5, partition 375, ANY, 4879 bytes)
18/09/26 11:15:22 INFO TaskSetManager: Finished task 303.0 in stage 0.0 (TID 303) in 15308 ms on 192.168.33.11 (executor 5) (296/409)
18/09/26 11:15:24 INFO TaskSetManager: Starting task 376.0 in stage 0.0 (TID 376, 192.168.33.11, executor 5, partition 376, ANY, 4879 bytes)
18/09/26 11:15:24 INFO TaskSetManager: Finished task 308.0 in stage 0.0 (TID 308) in 16075 ms on 192.168.33.11 (executor 5) (297/409)
18/09/26 11:15:24 INFO TaskSetManager: Starting task 377.0 in stage 0.0 (TID 377, 192.168.33.13, executor 2, partition 377, ANY, 4879 bytes)
18/09/26 11:15:24 INFO TaskSetManager: Starting task 378.0 in stage 0.0 (TID 378, 192.168.33.11, executor 5, partition 378, ANY, 4879 bytes)
18/09/26 11:15:24 INFO TaskSetManager: Finished task 306.0 in stage 0.0 (TID 306) in 16202 ms on 192.168.33.11 (executor 5) (298/409)
18/09/26 11:15:24 INFO TaskSetManager: Starting task 379.0 in stage 0.0 (TID 379, 192.168.33.11, executor 5, partition 379, ANY, 4879 bytes)
18/09/26 11:15:24 INFO TaskSetManager: Finished task 304.0 in stage 0.0 (TID 304) in 16547 ms on 192.168.33.13 (executor 2) (299/409)
18/09/26 11:15:24 INFO TaskSetManager: Finished task 305.0 in stage 0.0 (TID 305) in 16467 ms on 192.168.33.11 (executor 5) (300/409)
18/09/26 11:15:24 INFO TaskSetManager: Starting task 380.0 in stage 0.0 (TID 380, 192.168.33.15, executor 0, partition 380, ANY, 4879 bytes)
18/09/26 11:15:24 INFO TaskSetManager: Finished task 289.0 in stage 0.0 (TID 289) in 21292 ms on 192.168.33.15 (executor 0) (301/409)
18/09/26 11:15:25 INFO TaskSetManager: Starting task 381.0 in stage 0.0 (TID 381, 192.168.33.13, executor 2, partition 381, ANY, 4879 bytes)
18/09/26 11:15:25 INFO TaskSetManager: Finished task 310.0 in stage 0.0 (TID 310) in 16828 ms on 192.168.33.13 (executor 2) (302/409)
18/09/26 11:15:26 INFO TaskSetManager: Starting task 382.0 in stage 0.0 (TID 382, 192.168.33.14, executor 4, partition 382, ANY, 4879 bytes)
18/09/26 11:15:26 INFO TaskSetManager: Finished task 323.0 in stage 0.0 (TID 323) in 14636 ms on 192.168.33.14 (executor 4) (303/409)
18/09/26 11:15:26 INFO TaskSetManager: Starting task 383.0 in stage 0.0 (TID 383, 192.168.33.13, executor 2, partition 383, ANY, 4879 bytes)
18/09/26 11:15:26 INFO TaskSetManager: Finished task 312.0 in stage 0.0 (TID 312) in 16522 ms on 192.168.33.13 (executor 2) (304/409)
18/09/26 11:15:26 INFO TaskSetManager: Starting task 384.0 in stage 0.0 (TID 384, 192.168.33.13, executor 2, partition 384, ANY, 4879 bytes)
18/09/26 11:15:26 INFO TaskSetManager: Finished task 338.0 in stage 0.0 (TID 338) in 13535 ms on 192.168.33.13 (executor 2) (305/409)
18/09/26 11:15:26 INFO TaskSetManager: Starting task 385.0 in stage 0.0 (TID 385, 192.168.33.11, executor 5, partition 385, ANY, 4879 bytes)
18/09/26 11:15:26 INFO TaskSetManager: Finished task 311.0 in stage 0.0 (TID 311) in 17155 ms on 192.168.33.11 (executor 5) (306/409)
18/09/26 11:15:28 INFO TaskSetManager: Starting task 386.0 in stage 0.0 (TID 386, 192.168.33.15, executor 0, partition 386, ANY, 4879 bytes)
18/09/26 11:15:28 INFO TaskSetManager: Finished task 296.0 in stage 0.0 (TID 296) in 24167 ms on 192.168.33.15 (executor 0) (307/409)
18/09/26 11:15:28 INFO TaskSetManager: Starting task 387.0 in stage 0.0 (TID 387, 192.168.33.15, executor 0, partition 387, ANY, 4879 bytes)
18/09/26 11:15:28 INFO TaskSetManager: Finished task 301.0 in stage 0.0 (TID 301) in 22446 ms on 192.168.33.15 (executor 0) (308/409)
18/09/26 11:15:29 INFO TaskSetManager: Starting task 388.0 in stage 0.0 (TID 388, 192.168.33.13, executor 2, partition 388, ANY, 4879 bytes)
18/09/26 11:15:29 INFO TaskSetManager: Finished task 324.0 in stage 0.0 (TID 324) in 17895 ms on 192.168.33.13 (executor 2) (309/409)
18/09/26 11:15:29 INFO TaskSetManager: Starting task 389.0 in stage 0.0 (TID 389, 192.168.33.12, executor 3, partition 389, ANY, 4879 bytes)
18/09/26 11:15:29 INFO TaskSetManager: Finished task 342.0 in stage 0.0 (TID 342) in 15662 ms on 192.168.33.12 (executor 3) (310/409)
18/09/26 11:15:30 INFO TaskSetManager: Starting task 390.0 in stage 0.0 (TID 390, 192.168.33.15, executor 0, partition 390, ANY, 4879 bytes)
18/09/26 11:15:30 INFO TaskSetManager: Finished task 302.0 in stage 0.0 (TID 302) in 23598 ms on 192.168.33.15 (executor 0) (311/409)
18/09/26 11:15:30 INFO TaskSetManager: Starting task 391.0 in stage 0.0 (TID 391, 192.168.33.15, executor 0, partition 391, ANY, 4879 bytes)
18/09/26 11:15:30 INFO TaskSetManager: Finished task 297.0 in stage 0.0 (TID 297) in 26058 ms on 192.168.33.15 (executor 0) (312/409)
18/09/26 11:15:30 INFO TaskSetManager: Starting task 392.0 in stage 0.0 (TID 392, 192.168.33.14, executor 4, partition 392, ANY, 4879 bytes)
18/09/26 11:15:30 INFO TaskSetManager: Finished task 359.0 in stage 0.0 (TID 359) in 13634 ms on 192.168.33.14 (executor 4) (313/409)
18/09/26 11:15:31 INFO TaskSetManager: Starting task 393.0 in stage 0.0 (TID 393, 192.168.33.12, executor 3, partition 393, ANY, 4879 bytes)
18/09/26 11:15:31 INFO TaskSetManager: Finished task 348.0 in stage 0.0 (TID 348) in 15617 ms on 192.168.33.12 (executor 3) (314/409)
18/09/26 11:15:31 INFO TaskSetManager: Starting task 394.0 in stage 0.0 (TID 394, 192.168.33.15, executor 0, partition 394, ANY, 4879 bytes)
18/09/26 11:15:31 INFO TaskSetManager: Finished task 309.0 in stage 0.0 (TID 309) in 22313 ms on 192.168.33.15 (executor 0) (315/409)
18/09/26 11:15:31 INFO TaskSetManager: Starting task 395.0 in stage 0.0 (TID 395, 192.168.33.14, executor 4, partition 395, ANY, 4879 bytes)
18/09/26 11:15:31 INFO TaskSetManager: Finished task 358.0 in stage 0.0 (TID 358) in 14988 ms on 192.168.33.14 (executor 4) (316/409)
18/09/26 11:15:32 INFO TaskSetManager: Starting task 396.0 in stage 0.0 (TID 396, 192.168.33.14, executor 4, partition 396, ANY, 4879 bytes)
18/09/26 11:15:32 INFO TaskSetManager: Finished task 355.0 in stage 0.0 (TID 355) in 15440 ms on 192.168.33.14 (executor 4) (317/409)
18/09/26 11:15:32 INFO TaskSetManager: Starting task 397.0 in stage 0.0 (TID 397, 192.168.33.11, executor 5, partition 397, ANY, 4879 bytes)
18/09/26 11:15:32 INFO TaskSetManager: Finished task 354.0 in stage 0.0 (TID 354) in 16035 ms on 192.168.33.11 (executor 5) (318/409)
18/09/26 11:15:32 INFO TaskSetManager: Starting task 398.0 in stage 0.0 (TID 398, 192.168.33.13, executor 2, partition 398, ANY, 4879 bytes)
18/09/26 11:15:32 INFO TaskSetManager: Finished task 353.0 in stage 0.0 (TID 353) in 16148 ms on 192.168.33.13 (executor 2) (319/409)
18/09/26 11:15:33 INFO TaskSetManager: Starting task 399.0 in stage 0.0 (TID 399, 192.168.33.13, executor 2, partition 399, ANY, 4879 bytes)
18/09/26 11:15:33 INFO TaskSetManager: Finished task 364.0 in stage 0.0 (TID 364) in 14369 ms on 192.168.33.13 (executor 2) (320/409)
18/09/26 11:15:33 INFO TaskSetManager: Starting task 400.0 in stage 0.0 (TID 400, 192.168.33.15, executor 0, partition 400, ANY, 4879 bytes)
18/09/26 11:15:33 INFO TaskSetManager: Finished task 313.0 in stage 0.0 (TID 313) in 23108 ms on 192.168.33.15 (executor 0) (321/409)
18/09/26 11:15:33 INFO TaskSetManager: Starting task 401.0 in stage 0.0 (TID 401, 192.168.33.14, executor 4, partition 401, ANY, 4879 bytes)
18/09/26 11:15:33 INFO TaskSetManager: Finished task 362.0 in stage 0.0 (TID 362) in 15759 ms on 192.168.33.14 (executor 4) (322/409)
18/09/26 11:15:33 INFO TaskSetManager: Starting task 402.0 in stage 0.0 (TID 402, 192.168.33.11, executor 5, partition 402, ANY, 4879 bytes)
18/09/26 11:15:33 INFO TaskSetManager: Finished task 363.0 in stage 0.0 (TID 363) in 15410 ms on 192.168.33.11 (executor 5) (323/409)
18/09/26 11:15:34 INFO TaskSetManager: Starting task 403.0 in stage 0.0 (TID 403, 192.168.33.14, executor 4, partition 403, ANY, 4879 bytes)
18/09/26 11:15:34 INFO TaskSetManager: Finished task 372.0 in stage 0.0 (TID 372) in 13187 ms on 192.168.33.14 (executor 4) (324/409)
18/09/26 11:15:35 INFO TaskSetManager: Starting task 404.0 in stage 0.0 (TID 404, 192.168.33.13, executor 2, partition 404, ANY, 4879 bytes)
18/09/26 11:15:35 INFO TaskSetManager: Finished task 369.0 in stage 0.0 (TID 369) in 14991 ms on 192.168.33.13 (executor 2) (325/409)
18/09/26 11:15:35 INFO TaskSetManager: Starting task 405.0 in stage 0.0 (TID 405, 192.168.33.12, executor 3, partition 405, ANY, 4879 bytes)
18/09/26 11:15:35 INFO TaskSetManager: Finished task 360.0 in stage 0.0 (TID 360) in 17599 ms on 192.168.33.12 (executor 3) (326/409)
18/09/26 11:15:35 INFO TaskSetManager: Starting task 406.0 in stage 0.0 (TID 406, 192.168.33.11, executor 5, partition 406, ANY, 4879 bytes)
18/09/26 11:15:35 INFO TaskSetManager: Finished task 361.0 in stage 0.0 (TID 361) in 17697 ms on 192.168.33.11 (executor 5) (327/409)
18/09/26 11:15:35 INFO TaskSetManager: Starting task 407.0 in stage 0.0 (TID 407, 192.168.33.12, executor 3, partition 407, ANY, 4879 bytes)
18/09/26 11:15:35 INFO TaskSetManager: Finished task 368.0 in stage 0.0 (TID 368) in 15920 ms on 192.168.33.12 (executor 3) (328/409)
18/09/26 11:15:36 INFO TaskSetManager: Starting task 408.0 in stage 0.0 (TID 408, 192.168.33.15, executor 0, partition 408, ANY, 4879 bytes)
18/09/26 11:15:36 INFO TaskSetManager: Finished task 319.0 in stage 0.0 (TID 319) in 25330 ms on 192.168.33.15 (executor 0) (329/409)
18/09/26 11:15:36 INFO TaskSetManager: Finished task 316.0 in stage 0.0 (TID 316) in 25563 ms on 192.168.33.15 (executor 0) (330/409)
18/09/26 11:15:36 INFO TaskSetManager: Finished task 370.0 in stage 0.0 (TID 370) in 15925 ms on 192.168.33.12 (executor 3) (331/409)
18/09/26 11:15:36 INFO TaskSetManager: Finished task 365.0 in stage 0.0 (TID 365) in 17642 ms on 192.168.33.12 (executor 3) (332/409)
18/09/26 11:15:37 INFO TaskSetManager: Finished task 336.0 in stage 0.0 (TID 336) in 23922 ms on 192.168.33.15 (executor 0) (333/409)
18/09/26 11:15:37 INFO TaskSetManager: Finished task 366.0 in stage 0.0 (TID 366) in 17860 ms on 192.168.33.12 (executor 3) (334/409)
18/09/26 11:15:37 INFO TaskSetManager: Finished task 371.0 in stage 0.0 (TID 371) in 16285 ms on 192.168.33.12 (executor 3) (335/409)
18/09/26 11:15:37 INFO TaskSetManager: Finished task 333.0 in stage 0.0 (TID 333) in 24714 ms on 192.168.33.15 (executor 0) (336/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 374.0 in stage 0.0 (TID 374) in 15853 ms on 192.168.33.14 (executor 4) (337/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 375.0 in stage 0.0 (TID 375) in 15258 ms on 192.168.33.11 (executor 5) (338/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 352.0 in stage 0.0 (TID 352) in 22333 ms on 192.168.33.15 (executor 0) (339/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 326.0 in stage 0.0 (TID 326) in 26156 ms on 192.168.33.15 (executor 0) (340/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 373.0 in stage 0.0 (TID 373) in 16791 ms on 192.168.33.14 (executor 4) (341/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 339.0 in stage 0.0 (TID 339) in 25280 ms on 192.168.33.15 (executor 0) (342/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 341.0 in stage 0.0 (TID 341) in 25096 ms on 192.168.33.15 (executor 0) (343/409)
18/09/26 11:15:38 INFO TaskSetManager: Finished task 322.0 in stage 0.0 (TID 322) in 27614 ms on 192.168.33.15 (executor 0) (344/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 335.0 in stage 0.0 (TID 335) in 26048 ms on 192.168.33.15 (executor 0) (345/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 346.0 in stage 0.0 (TID 346) in 24799 ms on 192.168.33.15 (executor 0) (346/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 299.0 in stage 0.0 (TID 299) in 34018 ms on 192.168.33.10 (executor 1) (347/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 331.0 in stage 0.0 (TID 331) in 26985 ms on 192.168.33.15 (executor 0) (348/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 350.0 in stage 0.0 (TID 350) in 23728 ms on 192.168.33.15 (executor 0) (349/409)
18/09/26 11:15:39 INFO TaskSetManager: Finished task 337.0 in stage 0.0 (TID 337) in 26493 ms on 192.168.33.15 (executor 0) (350/409)
18/09/26 11:15:40 INFO TaskSetManager: Finished task 295.0 in stage 0.0 (TID 295) in 35731 ms on 192.168.33.10 (executor 1) (351/409)
18/09/26 11:15:40 INFO TaskSetManager: Finished task 329.0 in stage 0.0 (TID 329) in 27659 ms on 192.168.33.15 (executor 0) (352/409)
18/09/26 11:15:40 INFO TaskSetManager: Finished task 376.0 in stage 0.0 (TID 376) in 16295 ms on 192.168.33.11 (executor 5) (353/409)
18/09/26 11:15:40 INFO TaskSetManager: Finished task 382.0 in stage 0.0 (TID 382) in 14784 ms on 192.168.33.14 (executor 4) (354/409)
18/09/26 11:15:41 INFO TaskSetManager: Finished task 385.0 in stage 0.0 (TID 385) in 14343 ms on 192.168.33.11 (executor 5) (355/409)
18/09/26 11:15:41 INFO TaskSetManager: Finished task 377.0 in stage 0.0 (TID 377) in 16523 ms on 192.168.33.13 (executor 2) (356/409)
18/09/26 11:15:41 INFO TaskSetManager: Finished task 378.0 in stage 0.0 (TID 378) in 16551 ms on 192.168.33.11 (executor 5) (357/409)
18/09/26 11:15:42 INFO TaskSetManager: Finished task 383.0 in stage 0.0 (TID 383) in 15763 ms on 192.168.33.13 (executor 2) (358/409)
18/09/26 11:15:42 INFO TaskSetManager: Finished task 379.0 in stage 0.0 (TID 379) in 17938 ms on 192.168.33.11 (executor 5) (359/409)
18/09/26 11:15:42 INFO TaskSetManager: Finished task 384.0 in stage 0.0 (TID 384) in 16044 ms on 192.168.33.13 (executor 2) (360/409)
18/09/26 11:15:42 INFO TaskSetManager: Finished task 357.0 in stage 0.0 (TID 357) in 26076 ms on 192.168.33.15 (executor 0) (361/409)
18/09/26 11:15:43 INFO TaskSetManager: Finished task 241.0 in stage 0.0 (TID 241) in 57472 ms on 192.168.33.15 (executor 0) (362/409)
18/09/26 11:15:43 INFO TaskSetManager: Finished task 392.0 in stage 0.0 (TID 392) in 12816 ms on 192.168.33.14 (executor 4) (363/409)
18/09/26 11:15:43 INFO TaskSetManager: Finished task 381.0 in stage 0.0 (TID 381) in 17809 ms on 192.168.33.13 (executor 2) (364/409)
18/09/26 11:15:44 INFO TaskSetManager: Finished task 395.0 in stage 0.0 (TID 395) in 12518 ms on 192.168.33.14 (executor 4) (365/409)
18/09/26 11:15:44 INFO TaskSetManager: Finished task 380.0 in stage 0.0 (TID 380) in 20064 ms on 192.168.33.15 (executor 0) (366/409)
18/09/26 11:15:45 INFO TaskSetManager: Finished task 387.0 in stage 0.0 (TID 387) in 16145 ms on 192.168.33.15 (executor 0) (367/409)
18/09/26 11:15:45 INFO TaskSetManager: Finished task 396.0 in stage 0.0 (TID 396) in 13291 ms on 192.168.33.14 (executor 4) (368/409)
18/09/26 11:15:45 INFO TaskSetManager: Finished task 393.0 in stage 0.0 (TID 393) in 14688 ms on 192.168.33.12 (executor 3) (369/409)
18/09/26 11:15:45 INFO TaskSetManager: Finished task 402.0 in stage 0.0 (TID 402) in 12251 ms on 192.168.33.11 (executor 5) (370/409)
18/09/26 11:15:46 INFO TaskSetManager: Finished task 389.0 in stage 0.0 (TID 389) in 16215 ms on 192.168.33.12 (executor 3) (371/409)
18/09/26 11:15:46 INFO TaskSetManager: Finished task 388.0 in stage 0.0 (TID 388) in 16377 ms on 192.168.33.13 (executor 2) (372/409)
18/09/26 11:15:46 INFO TaskSetManager: Finished task 397.0 in stage 0.0 (TID 397) in 13811 ms on 192.168.33.11 (executor 5) (373/409)
18/09/26 11:15:46 INFO TaskSetManager: Finished task 401.0 in stage 0.0 (TID 401) in 13443 ms on 192.168.33.14 (executor 4) (374/409)
18/09/26 11:15:46 INFO TaskSetManager: Finished task 398.0 in stage 0.0 (TID 398) in 14290 ms on 192.168.33.13 (executor 2) (375/409)
18/09/26 11:15:47 INFO TaskSetManager: Finished task 391.0 in stage 0.0 (TID 391) in 16557 ms on 192.168.33.15 (executor 0) (376/409)
18/09/26 11:15:47 INFO TaskSetManager: Finished task 386.0 in stage 0.0 (TID 386) in 18780 ms on 192.168.33.15 (executor 0) (377/409)
18/09/26 11:15:47 INFO TaskSetManager: Finished task 390.0 in stage 0.0 (TID 390) in 16996 ms on 192.168.33.15 (executor 0) (378/409)
18/09/26 11:15:47 INFO TaskSetManager: Finished task 314.0 in stage 0.0 (TID 314) in 37161 ms on 192.168.33.10 (executor 1) (379/409)
18/09/26 11:15:47 INFO TaskSetManager: Finished task 318.0 in stage 0.0 (TID 318) in 37236 ms on 192.168.33.10 (executor 1) (380/409)
18/09/26 11:15:48 INFO TaskSetManager: Finished task 403.0 in stage 0.0 (TID 403) in 13477 ms on 192.168.33.14 (executor 4) (381/409)
18/09/26 11:15:48 INFO TaskSetManager: Finished task 399.0 in stage 0.0 (TID 399) in 14929 ms on 192.168.33.13 (executor 2) (382/409)
18/09/26 11:15:49 INFO TaskSetManager: Finished task 404.0 in stage 0.0 (TID 404) in 14059 ms on 192.168.33.13 (executor 2) (383/409)
18/09/26 11:15:49 INFO TaskSetManager: Finished task 317.0 in stage 0.0 (TID 317) in 39129 ms on 192.168.33.10 (executor 1) (384/409)
18/09/26 11:15:49 INFO TaskSetManager: Finished task 408.0 in stage 0.0 (TID 408) in 13884 ms on 192.168.33.15 (executor 0) (385/409)
18/09/26 11:15:49 INFO TaskSetManager: Finished task 394.0 in stage 0.0 (TID 394) in 18549 ms on 192.168.33.15 (executor 0) (386/409)
18/09/26 11:15:49 INFO TaskSetManager: Finished task 400.0 in stage 0.0 (TID 400) in 16512 ms on 192.168.33.15 (executor 0) (387/409)
18/09/26 11:15:50 INFO TaskSetManager: Finished task 315.0 in stage 0.0 (TID 315) in 40004 ms on 192.168.33.10 (executor 1) (388/409)
18/09/26 11:15:50 INFO TaskSetManager: Finished task 406.0 in stage 0.0 (TID 406) in 15318 ms on 192.168.33.11 (executor 5) (389/409)
18/09/26 11:15:51 INFO TaskSetManager: Finished task 307.0 in stage 0.0 (TID 307) in 42574 ms on 192.168.33.10 (executor 1) (390/409)
18/09/26 11:15:51 INFO TaskSetManager: Finished task 405.0 in stage 0.0 (TID 405) in 15926 ms on 192.168.33.12 (executor 3) (391/409)
18/09/26 11:15:51 INFO TaskSetManager: Finished task 332.0 in stage 0.0 (TID 332) in 38814 ms on 192.168.33.10 (executor 1) (392/409)
18/09/26 11:15:51 INFO TaskSetManager: Finished task 330.0 in stage 0.0 (TID 330) in 39217 ms on 192.168.33.10 (executor 1) (393/409)
18/09/26 11:15:52 INFO TaskSetManager: Finished task 328.0 in stage 0.0 (TID 328) in 39525 ms on 192.168.33.10 (executor 1) (394/409)
18/09/26 11:15:52 INFO TaskSetManager: Finished task 407.0 in stage 0.0 (TID 407) in 16599 ms on 192.168.33.12 (executor 3) (395/409)
18/09/26 11:15:52 INFO TaskSetManager: Finished task 325.0 in stage 0.0 (TID 325) in 40915 ms on 192.168.33.10 (executor 1) (396/409)
18/09/26 11:15:53 INFO TaskSetManager: Finished task 349.0 in stage 0.0 (TID 349) in 37552 ms on 192.168.33.10 (executor 1) (397/409)
18/09/26 11:15:53 INFO TaskSetManager: Finished task 345.0 in stage 0.0 (TID 345) in 38995 ms on 192.168.33.10 (executor 1) (398/409)
18/09/26 11:15:53 INFO TaskSetManager: Finished task 320.0 in stage 0.0 (TID 320) in 42510 ms on 192.168.33.10 (executor 1) (399/409)
18/09/26 11:15:54 INFO TaskSetManager: Finished task 347.0 in stage 0.0 (TID 347) in 39959 ms on 192.168.33.10 (executor 1) (400/409)
18/09/26 11:15:54 INFO TaskSetManager: Finished task 340.0 in stage 0.0 (TID 340) in 41518 ms on 192.168.33.10 (executor 1) (401/409)
18/09/26 11:15:55 INFO TaskSetManager: Finished task 344.0 in stage 0.0 (TID 344) in 40544 ms on 192.168.33.10 (executor 1) (402/409)
18/09/26 11:15:55 INFO TaskSetManager: Finished task 321.0 in stage 0.0 (TID 321) in 43906 ms on 192.168.33.10 (executor 1) (403/409)
18/09/26 11:15:55 INFO TaskSetManager: Finished task 334.0 in stage 0.0 (TID 334) in 42311 ms on 192.168.33.10 (executor 1) (404/409)
18/09/26 11:15:55 INFO TaskSetManager: Finished task 367.0 in stage 0.0 (TID 367) in 36243 ms on 192.168.33.10 (executor 1) (405/409)
18/09/26 11:15:55 INFO TaskSetManager: Finished task 327.0 in stage 0.0 (TID 327) in 43483 ms on 192.168.33.10 (executor 1) (406/409)
18/09/26 11:15:56 INFO TaskSetManager: Finished task 351.0 in stage 0.0 (TID 351) in 40283 ms on 192.168.33.10 (executor 1) (407/409)
18/09/26 11:15:56 INFO TaskSetManager: Finished task 343.0 in stage 0.0 (TID 343) in 42411 ms on 192.168.33.10 (executor 1) (408/409)
18/09/26 11:15:57 INFO TaskSetManager: Finished task 356.0 in stage 0.0 (TID 356) in 41260 ms on 192.168.33.10 (executor 1) (409/409)
18/09/26 11:15:57 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 145,036 s
18/09/26 11:15:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/09/26 11:15:57 INFO DAGScheduler: looking for newly runnable stages
18/09/26 11:15:57 INFO DAGScheduler: running: Set()
18/09/26 11:15:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 11:15:57 INFO DAGScheduler: failed: Set()
18/09/26 11:15:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/26 11:15:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/26 11:15:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1836.0 B, free 365.9 MB)
18/09/26 11:15:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.10:43403 (size: 1836.0 B, free: 366.3 MB)
18/09/26 11:15:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/09/26 11:15:58 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 11:15:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 409 tasks
18/09/26 11:15:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 409, 192.168.33.15, executor 0, partition 0, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 410, 192.168.33.15, executor 0, partition 1, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 411, 192.168.33.15, executor 0, partition 2, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 412, 192.168.33.15, executor 0, partition 3, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 413, 192.168.33.15, executor 0, partition 4, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 414, 192.168.33.15, executor 0, partition 5, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 415, 192.168.33.15, executor 0, partition 6, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 416, 192.168.33.15, executor 0, partition 7, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 417, 192.168.33.15, executor 0, partition 8, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 418, 192.168.33.15, executor 0, partition 9, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 419, 192.168.33.15, executor 0, partition 10, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 420, 192.168.33.15, executor 0, partition 11, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 421, 192.168.33.15, executor 0, partition 12, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 422, 192.168.33.15, executor 0, partition 13, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 423, 192.168.33.15, executor 0, partition 14, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 424, 192.168.33.15, executor 0, partition 15, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 425, 192.168.33.15, executor 0, partition 16, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 426, 192.168.33.15, executor 0, partition 17, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 427, 192.168.33.15, executor 0, partition 18, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 428, 192.168.33.15, executor 0, partition 19, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 429, 192.168.33.15, executor 0, partition 20, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 430, 192.168.33.15, executor 0, partition 21, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 431, 192.168.33.15, executor 0, partition 22, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 432, 192.168.33.15, executor 0, partition 23, NODE_LOCAL, 4614 bytes)
18/09/26 11:15:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.15:35408 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.15:56464
18/09/26 11:15:58 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 92522 bytes
18/09/26 11:16:01 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 433, 192.168.33.10, executor 1, partition 24, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 434, 192.168.33.12, executor 3, partition 25, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 435, 192.168.33.14, executor 4, partition 26, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 436, 192.168.33.11, executor 5, partition 27, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 437, 192.168.33.13, executor 2, partition 28, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 438, 192.168.33.10, executor 1, partition 29, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 439, 192.168.33.12, executor 3, partition 30, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 440, 192.168.33.14, executor 4, partition 31, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 441, 192.168.33.11, executor 5, partition 32, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 442, 192.168.33.13, executor 2, partition 33, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 443, 192.168.33.10, executor 1, partition 34, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 444, 192.168.33.12, executor 3, partition 35, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 445, 192.168.33.14, executor 4, partition 36, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 446, 192.168.33.11, executor 5, partition 37, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 447, 192.168.33.13, executor 2, partition 38, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 448, 192.168.33.10, executor 1, partition 39, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 449, 192.168.33.12, executor 3, partition 40, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 450, 192.168.33.14, executor 4, partition 41, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 451, 192.168.33.11, executor 5, partition 42, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 452, 192.168.33.13, executor 2, partition 43, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 453, 192.168.33.10, executor 1, partition 44, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 454, 192.168.33.12, executor 3, partition 45, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 455, 192.168.33.14, executor 4, partition 46, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 456, 192.168.33.11, executor 5, partition 47, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 457, 192.168.33.13, executor 2, partition 48, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 458, 192.168.33.10, executor 1, partition 49, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 459, 192.168.33.12, executor 3, partition 50, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 460, 192.168.33.14, executor 4, partition 51, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 461, 192.168.33.11, executor 5, partition 52, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 462, 192.168.33.13, executor 2, partition 53, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 463, 192.168.33.10, executor 1, partition 54, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 464, 192.168.33.12, executor 3, partition 55, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 465, 192.168.33.14, executor 4, partition 56, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 466, 192.168.33.11, executor 5, partition 57, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 467, 192.168.33.13, executor 2, partition 58, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 468, 192.168.33.10, executor 1, partition 59, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 469, 192.168.33.12, executor 3, partition 60, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 470, 192.168.33.14, executor 4, partition 61, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 471, 192.168.33.11, executor 5, partition 62, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 472, 192.168.33.13, executor 2, partition 63, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 473, 192.168.33.10, executor 1, partition 64, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 474, 192.168.33.10, executor 1, partition 65, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 475, 192.168.33.10, executor 1, partition 66, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 476, 192.168.33.10, executor 1, partition 67, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 477, 192.168.33.10, executor 1, partition 68, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 478, 192.168.33.10, executor 1, partition 69, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 479, 192.168.33.10, executor 1, partition 70, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 480, 192.168.33.10, executor 1, partition 71, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 481, 192.168.33.10, executor 1, partition 72, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 482, 192.168.33.10, executor 1, partition 73, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 483, 192.168.33.10, executor 1, partition 74, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 484, 192.168.33.10, executor 1, partition 75, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 485, 192.168.33.10, executor 1, partition 76, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 486, 192.168.33.10, executor 1, partition 77, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 487, 192.168.33.10, executor 1, partition 78, ANY, 4614 bytes)
18/09/26 11:16:01 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 488, 192.168.33.10, executor 1, partition 79, ANY, 4614 bytes)
18/09/26 11:16:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.10:41196 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:16:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.13:33570 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.10:37738
18/09/26 11:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.13:43042
18/09/26 11:16:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.14:34961 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:16:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.12:35074 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.12:37794
18/09/26 11:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:37206
18/09/26 11:16:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.11:38333 (size: 1836.0 B, free: 15.8 GB)
18/09/26 11:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.11:43502
18/09/26 11:19:30 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 489, 192.168.33.13, executor 2, partition 80, ANY, 4614 bytes)
18/09/26 11:19:30 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 467) in 209694 ms on 192.168.33.13 (executor 2) (1/409)
18/09/26 11:19:37 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 490, 192.168.33.13, executor 2, partition 81, ANY, 4614 bytes)
18/09/26 11:19:37 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 452) in 216578 ms on 192.168.33.13 (executor 2) (2/409)
18/09/26 11:19:46 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 491, 192.168.33.13, executor 2, partition 82, ANY, 4614 bytes)
18/09/26 11:19:46 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 472) in 224834 ms on 192.168.33.13 (executor 2) (3/409)
18/09/26 11:19:55 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 492, 192.168.33.14, executor 4, partition 83, ANY, 4614 bytes)
18/09/26 11:19:55 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 445) in 234731 ms on 192.168.33.14 (executor 4) (4/409)
18/09/26 11:20:02 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 493, 192.168.33.14, executor 4, partition 84, ANY, 4614 bytes)
18/09/26 11:20:02 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 470) in 241272 ms on 192.168.33.14 (executor 4) (5/409)
18/09/26 11:20:09 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 494, 192.168.33.13, executor 2, partition 85, ANY, 4614 bytes)
18/09/26 11:20:09 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 462) in 248523 ms on 192.168.33.13 (executor 2) (6/409)
18/09/26 11:20:15 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 495, 192.168.33.13, executor 2, partition 86, ANY, 4614 bytes)
18/09/26 11:20:15 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 437) in 254404 ms on 192.168.33.13 (executor 2) (7/409)
18/09/26 11:20:16 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 496, 192.168.33.14, executor 4, partition 87, ANY, 4614 bytes)
18/09/26 11:20:16 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 450) in 255162 ms on 192.168.33.14 (executor 4) (8/409)
18/09/26 11:20:17 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 497, 192.168.33.14, executor 4, partition 88, ANY, 4614 bytes)
18/09/26 11:20:17 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 465) in 256048 ms on 192.168.33.14 (executor 4) (9/409)
18/09/26 11:20:17 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 498, 192.168.33.12, executor 3, partition 89, ANY, 4614 bytes)
18/09/26 11:20:17 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 439) in 256306 ms on 192.168.33.12 (executor 3) (10/409)
18/09/26 11:20:24 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 499, 192.168.33.13, executor 2, partition 90, ANY, 4614 bytes)
18/09/26 11:20:24 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 442) in 263436 ms on 192.168.33.13 (executor 2) (11/409)
18/09/26 11:20:29 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 500, 192.168.33.12, executor 3, partition 91, ANY, 4614 bytes)
18/09/26 11:20:29 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 449) in 268001 ms on 192.168.33.12 (executor 3) (12/409)
18/09/26 11:20:36 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 501, 192.168.33.12, executor 3, partition 92, ANY, 4614 bytes)
18/09/26 11:20:36 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 434) in 274981 ms on 192.168.33.12 (executor 3) (13/409)
18/09/26 11:20:43 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 502, 192.168.33.12, executor 3, partition 93, ANY, 4614 bytes)
18/09/26 11:20:43 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 459) in 281946 ms on 192.168.33.12 (executor 3) (14/409)
18/09/26 11:20:45 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 503, 192.168.33.12, executor 3, partition 94, ANY, 4614 bytes)
18/09/26 11:20:45 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 454) in 284570 ms on 192.168.33.12 (executor 3) (15/409)
18/09/26 11:20:46 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 504, 192.168.33.11, executor 5, partition 95, ANY, 4614 bytes)
18/09/26 11:20:46 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 466) in 285683 ms on 192.168.33.11 (executor 5) (16/409)
18/09/26 11:20:48 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 505, 192.168.33.12, executor 3, partition 96, ANY, 4614 bytes)
18/09/26 11:20:48 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 444) in 286890 ms on 192.168.33.12 (executor 3) (17/409)
18/09/26 11:21:10 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 506, 192.168.33.14, executor 4, partition 97, ANY, 4614 bytes)
18/09/26 11:21:10 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 460) in 309062 ms on 192.168.33.14 (executor 4) (18/409)
18/09/26 11:21:13 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 507, 192.168.33.13, executor 2, partition 98, ANY, 4614 bytes)
18/09/26 11:21:13 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 447) in 312001 ms on 192.168.33.13 (executor 2) (19/409)
18/09/26 11:21:25 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 508, 192.168.33.14, executor 4, partition 99, ANY, 4614 bytes)
18/09/26 11:21:25 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 440) in 324603 ms on 192.168.33.14 (executor 4) (20/409)
18/09/26 11:21:35 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 509, 192.168.33.11, executor 5, partition 100, ANY, 4614 bytes)
18/09/26 11:21:35 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 441) in 334073 ms on 192.168.33.11 (executor 5) (21/409)
18/09/26 11:22:00 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 510, 192.168.33.14, executor 4, partition 101, ANY, 4614 bytes)
18/09/26 11:22:00 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 435) in 359280 ms on 192.168.33.14 (executor 4) (22/409)
18/09/26 11:22:01 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 511, 192.168.33.11, executor 5, partition 102, ANY, 4614 bytes)
18/09/26 11:22:01 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 451) in 360074 ms on 192.168.33.11 (executor 5) (23/409)
18/09/26 11:22:07 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 512, 192.168.33.11, executor 5, partition 103, ANY, 4614 bytes)
18/09/26 11:22:07 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 436) in 366152 ms on 192.168.33.11 (executor 5) (24/409)
18/09/26 11:22:22 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 513, 192.168.33.12, executor 3, partition 104, ANY, 4614 bytes)
18/09/26 11:22:22 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 464) in 380973 ms on 192.168.33.12 (executor 3) (25/409)
18/09/26 11:22:25 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 514, 192.168.33.11, executor 5, partition 105, ANY, 4614 bytes)
18/09/26 11:22:25 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 471) in 384576 ms on 192.168.33.11 (executor 5) (26/409)
18/09/26 11:23:05 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 515, 192.168.33.12, executor 3, partition 106, ANY, 4614 bytes)
18/09/26 11:23:05 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 469) in 423760 ms on 192.168.33.12 (executor 3) (27/409)
18/09/26 11:23:30 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 516, 192.168.33.11, executor 5, partition 107, ANY, 4614 bytes)
18/09/26 11:23:30 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 446) in 449276 ms on 192.168.33.11 (executor 5) (28/409)
18/09/26 11:23:31 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 517, 192.168.33.13, executor 2, partition 108, ANY, 4614 bytes)
18/09/26 11:23:31 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 489) in 241007 ms on 192.168.33.13 (executor 2) (29/409)
18/09/26 11:23:36 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 518, 192.168.33.12, executor 3, partition 109, ANY, 4614 bytes)
18/09/26 11:23:36 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 498) in 198646 ms on 192.168.33.12 (executor 3) (30/409)
18/09/26 11:23:36 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 519, 192.168.33.13, executor 2, partition 110, ANY, 4614 bytes)
18/09/26 11:23:36 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 491) in 230766 ms on 192.168.33.13 (executor 2) (31/409)
18/09/26 11:23:48 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 520, 192.168.33.11, executor 5, partition 111, ANY, 4614 bytes)
18/09/26 11:23:48 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 461) in 467244 ms on 192.168.33.11 (executor 5) (32/409)
18/09/26 11:23:49 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 521, 192.168.33.12, executor 3, partition 112, ANY, 4614 bytes)
18/09/26 11:23:49 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 505) in 181202 ms on 192.168.33.12 (executor 3) (33/409)
18/09/26 11:23:49 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 522, 192.168.33.15, executor 0, partition 113, NODE_LOCAL, 4614 bytes)
18/09/26 11:23:49 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 424) in 471187 ms on 192.168.33.15 (executor 0) (34/409)
18/09/26 11:23:49 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 492) in 233962 ms on 192.168.33.14 (executor 4) (35/409)
18/09/26 11:23:50 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 523, 192.168.33.15, executor 0, partition 114, NODE_LOCAL, 4614 bytes)
18/09/26 11:23:50 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 430) in 472406 ms on 192.168.33.15 (executor 0) (36/409)
18/09/26 11:23:54 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 524, 192.168.33.14, executor 4, partition 115, ANY, 4614 bytes)
18/09/26 11:23:55 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 525, 192.168.33.13, executor 2, partition 116, ANY, 4614 bytes)
18/09/26 11:23:55 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 490) in 257924 ms on 192.168.33.13 (executor 2) (37/409)
18/09/26 11:23:59 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 526, 192.168.33.15, executor 0, partition 117, NODE_LOCAL, 4614 bytes)
18/09/26 11:23:59 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 426) in 481585 ms on 192.168.33.15 (executor 0) (38/409)
18/09/26 11:24:01 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 527, 192.168.33.15, executor 0, partition 118, NODE_LOCAL, 4614 bytes)
18/09/26 11:24:01 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 422) in 483735 ms on 192.168.33.15 (executor 0) (39/409)
18/09/26 11:24:03 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 500) in 214604 ms on 192.168.33.12 (executor 3) (40/409)
18/09/26 11:24:05 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 528, 192.168.33.12, executor 3, partition 119, ANY, 4614 bytes)
18/09/26 11:24:08 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 529, 192.168.33.13, executor 2, partition 120, ANY, 4614 bytes)
18/09/26 11:24:08 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 495) in 232939 ms on 192.168.33.13 (executor 2) (41/409)
18/09/26 11:24:08 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 530, 192.168.33.12, executor 3, partition 121, ANY, 4614 bytes)
18/09/26 11:24:08 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 502) in 205765 ms on 192.168.33.12 (executor 3) (42/409)
18/09/26 11:24:26 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 531, 192.168.33.12, executor 3, partition 122, ANY, 4614 bytes)
18/09/26 11:24:26 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 501) in 230116 ms on 192.168.33.12 (executor 3) (43/409)
18/09/26 11:24:28 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 532, 192.168.33.13, executor 2, partition 123, ANY, 4614 bytes)
18/09/26 11:24:28 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 457) in 507443 ms on 192.168.33.13 (executor 2) (44/409)
18/09/26 11:24:58 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 533, 192.168.33.12, executor 3, partition 124, ANY, 4614 bytes)
18/09/26 11:24:58 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 503) in 252339 ms on 192.168.33.12 (executor 3) (45/409)
18/09/26 11:25:01 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 534, 192.168.33.15, executor 0, partition 125, NODE_LOCAL, 4614 bytes)
18/09/26 11:25:01 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 415) in 542925 ms on 192.168.33.15 (executor 0) (46/409)
18/09/26 11:25:08 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 535, 192.168.33.14, executor 4, partition 126, ANY, 4614 bytes)
18/09/26 11:25:08 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 493) in 305518 ms on 192.168.33.14 (executor 4) (47/409)
18/09/26 11:25:12 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 536, 192.168.33.15, executor 0, partition 127, NODE_LOCAL, 4614 bytes)
18/09/26 11:25:12 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 414) in 554108 ms on 192.168.33.15 (executor 0) (48/409)
18/09/26 11:25:15 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 537, 192.168.33.15, executor 0, partition 128, NODE_LOCAL, 4614 bytes)
18/09/26 11:25:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 409) in 557529 ms on 192.168.33.15 (executor 0) (49/409)
18/09/26 11:25:24 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 538, 192.168.33.13, executor 2, partition 129, ANY, 4614 bytes)
18/09/26 11:25:24 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 507) in 251275 ms on 192.168.33.13 (executor 2) (50/409)
18/09/26 11:25:36 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 539, 192.168.33.14, executor 4, partition 130, ANY, 4614 bytes)
18/09/26 11:25:36 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 506) in 266457 ms on 192.168.33.14 (executor 4) (51/409)
18/09/26 11:25:48 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 540, 192.168.33.11, executor 5, partition 131, ANY, 4614 bytes)
18/09/26 11:25:48 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 504) in 301477 ms on 192.168.33.11 (executor 5) (52/409)
18/09/26 11:25:53 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 541, 192.168.33.13, executor 2, partition 132, ANY, 4614 bytes)
18/09/26 11:25:53 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 494) in 343974 ms on 192.168.33.13 (executor 2) (53/409)
18/09/26 11:25:59 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 542, 192.168.33.10, executor 1, partition 133, ANY, 4614 bytes)
18/09/26 11:25:59 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 481) in 598608 ms on 192.168.33.10 (executor 1) (54/409)
18/09/26 11:26:06 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 543, 192.168.33.12, executor 3, partition 134, ANY, 4614 bytes)
18/09/26 11:26:06 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 513) in 224355 ms on 192.168.33.12 (executor 3) (55/409)
18/09/26 11:26:08 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 544, 192.168.33.11, executor 5, partition 135, ANY, 4614 bytes)
18/09/26 11:26:08 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 456) in 607182 ms on 192.168.33.11 (executor 5) (56/409)
18/09/26 11:26:12 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 545, 192.168.33.13, executor 2, partition 136, ANY, 4614 bytes)
18/09/26 11:26:12 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 499) in 347864 ms on 192.168.33.13 (executor 2) (57/409)
18/09/26 11:26:22 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 546, 192.168.33.12, executor 3, partition 137, ANY, 4614 bytes)
18/09/26 11:26:22 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 515) in 197985 ms on 192.168.33.12 (executor 3) (58/409)
18/09/26 11:26:23 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 547, 192.168.33.15, executor 0, partition 138, NODE_LOCAL, 4614 bytes)
18/09/26 11:26:23 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 412) in 625540 ms on 192.168.33.15 (executor 0) (59/409)
18/09/26 11:26:35 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 548, 192.168.33.11, executor 5, partition 139, ANY, 4614 bytes)
18/09/26 11:26:35 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 514) in 250082 ms on 192.168.33.11 (executor 5) (60/409)
18/09/26 11:26:37 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 549, 192.168.33.11, executor 5, partition 140, ANY, 4614 bytes)
18/09/26 11:26:37 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 509) in 301777 ms on 192.168.33.11 (executor 5) (61/409)
18/09/26 11:26:41 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 550, 192.168.33.11, executor 5, partition 141, ANY, 4614 bytes)
18/09/26 11:26:41 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 512) in 273857 ms on 192.168.33.11 (executor 5) (62/409)
18/09/26 11:26:53 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 551, 192.168.33.11, executor 5, partition 142, ANY, 4614 bytes)
18/09/26 11:26:53 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 511) in 292514 ms on 192.168.33.11 (executor 5) (63/409)
18/09/26 11:27:14 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 552, 192.168.33.12, executor 3, partition 143, ANY, 4614 bytes)
18/09/26 11:27:14 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 528) in 189574 ms on 192.168.33.12 (executor 3) (64/409)
18/09/26 11:27:14 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 553, 192.168.33.12, executor 3, partition 144, ANY, 4614 bytes)
18/09/26 11:27:14 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 518) in 218805 ms on 192.168.33.12 (executor 3) (65/409)
18/09/26 11:28:05 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 554, 192.168.33.13, executor 2, partition 145, ANY, 4614 bytes)
18/09/26 11:28:05 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 517) in 274021 ms on 192.168.33.13 (executor 2) (66/409)
18/09/26 11:28:21 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 555, 192.168.33.13, executor 2, partition 146, ANY, 4614 bytes)
18/09/26 11:28:21 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 538) in 176751 ms on 192.168.33.13 (executor 2) (67/409)
18/09/26 11:28:32 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 556, 192.168.33.13, executor 2, partition 147, ANY, 4614 bytes)
18/09/26 11:28:32 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 532) in 243439 ms on 192.168.33.13 (executor 2) (68/409)
18/09/26 11:28:33 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 557, 192.168.33.13, executor 2, partition 148, ANY, 4614 bytes)
18/09/26 11:28:33 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 529) in 264481 ms on 192.168.33.13 (executor 2) (69/409)
18/09/26 11:28:33 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 558, 192.168.33.13, executor 2, partition 149, ANY, 4614 bytes)
18/09/26 11:28:33 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 519) in 296299 ms on 192.168.33.13 (executor 2) (70/409)
18/09/26 11:28:34 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 559, 192.168.33.15, executor 0, partition 150, NODE_LOCAL, 4614 bytes)
18/09/26 11:28:34 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 425) in 756074 ms on 192.168.33.15 (executor 0) (71/409)
18/09/26 11:28:37 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 516) in 306661 ms on 192.168.33.11 (executor 5) (72/409)
18/09/26 11:28:38 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 560, 192.168.33.11, executor 5, partition 151, ANY, 4614 bytes)
18/09/26 11:28:38 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 561, 192.168.33.12, executor 3, partition 152, ANY, 4614 bytes)
18/09/26 11:28:38 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 531) in 252550 ms on 192.168.33.12 (executor 3) (73/409)
18/09/26 11:28:43 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 562, 192.168.33.10, executor 1, partition 153, ANY, 4614 bytes)
18/09/26 11:28:43 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 433) in 761983 ms on 192.168.33.10 (executor 1) (74/409)
18/09/26 11:28:46 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 563, 192.168.33.10, executor 1, partition 154, ANY, 4614 bytes)
18/09/26 11:28:46 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 468) in 765433 ms on 192.168.33.10 (executor 1) (75/409)
18/09/26 11:28:51 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 564, 192.168.33.10, executor 1, partition 155, ANY, 4614 bytes)
18/09/26 11:28:51 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 458) in 770392 ms on 192.168.33.10 (executor 1) (76/409)
18/09/26 11:28:54 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 565, 192.168.33.14, executor 4, partition 156, ANY, 4614 bytes)
18/09/26 11:28:54 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 510) in 413819 ms on 192.168.33.14 (executor 4) (77/409)
18/09/26 11:29:02 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 566, 192.168.33.12, executor 3, partition 157, ANY, 4614 bytes)
18/09/26 11:29:02 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 533) in 244831 ms on 192.168.33.12 (executor 3) (78/409)
18/09/26 11:29:11 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 567, 192.168.33.12, executor 3, partition 158, ANY, 4614 bytes)
18/09/26 11:29:11 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 521) in 322439 ms on 192.168.33.12 (executor 3) (79/409)
18/09/26 11:29:24 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 568, 192.168.33.10, executor 1, partition 159, ANY, 4614 bytes)
18/09/26 11:29:24 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 479) in 802807 ms on 192.168.33.10 (executor 1) (80/409)
18/09/26 11:29:28 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 569, 192.168.33.11, executor 5, partition 160, ANY, 4614 bytes)
18/09/26 11:29:28 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 520) in 339655 ms on 192.168.33.11 (executor 5) (81/409)
18/09/26 11:29:50 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 570, 192.168.33.14, executor 4, partition 161, ANY, 4614 bytes)
18/09/26 11:29:50 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 524) in 356466 ms on 192.168.33.14 (executor 4) (82/409)
18/09/26 11:29:51 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 571, 192.168.33.13, executor 2, partition 162, ANY, 4614 bytes)
18/09/26 11:29:51 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 525) in 356260 ms on 192.168.33.13 (executor 2) (83/409)
18/09/26 11:29:57 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 572, 192.168.33.12, executor 3, partition 163, ANY, 4614 bytes)
18/09/26 11:29:57 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 546) in 214082 ms on 192.168.33.12 (executor 3) (84/409)
18/09/26 11:29:57 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 573, 192.168.33.14, executor 4, partition 164, ANY, 4614 bytes)
18/09/26 11:29:57 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 496) in 581130 ms on 192.168.33.14 (executor 4) (85/409)
18/09/26 11:30:03 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 574, 192.168.33.14, executor 4, partition 165, ANY, 4614 bytes)
18/09/26 11:30:03 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 497) in 586188 ms on 192.168.33.14 (executor 4) (86/409)
18/09/26 11:30:05 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 575, 192.168.33.14, executor 4, partition 166, ANY, 4614 bytes)
18/09/26 11:30:05 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 455) in 844030 ms on 192.168.33.14 (executor 4) (87/409)
18/09/26 11:30:13 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 576, 192.168.33.12, executor 3, partition 167, ANY, 4614 bytes)
18/09/26 11:30:13 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 530) in 364743 ms on 192.168.33.12 (executor 3) (88/409)
18/09/26 11:30:29 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 577, 192.168.33.10, executor 1, partition 168, ANY, 4614 bytes)
18/09/26 11:30:29 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 475) in 868274 ms on 192.168.33.10 (executor 1) (89/409)
18/09/26 11:30:35 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 578, 192.168.33.10, executor 1, partition 169, ANY, 4614 bytes)
18/09/26 11:30:35 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 443) in 874348 ms on 192.168.33.10 (executor 1) (90/409)
18/09/26 11:30:55 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 579, 192.168.33.10, executor 1, partition 170, ANY, 4614 bytes)
18/09/26 11:30:55 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 477) in 894285 ms on 192.168.33.10 (executor 1) (91/409)
18/09/26 11:30:57 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 580, 192.168.33.10, executor 1, partition 171, ANY, 4614 bytes)
18/09/26 11:30:57 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 476) in 896632 ms on 192.168.33.10 (executor 1) (92/409)
18/09/26 11:31:11 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 581, 192.168.33.10, executor 1, partition 172, ANY, 4614 bytes)
18/09/26 11:31:11 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 463) in 909811 ms on 192.168.33.10 (executor 1) (93/409)
18/09/26 11:31:11 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 582, 192.168.33.13, executor 2, partition 173, ANY, 4614 bytes)
18/09/26 11:31:11 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 545) in 298590 ms on 192.168.33.13 (executor 2) (94/409)
18/09/26 11:31:15 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 583, 192.168.33.12, executor 3, partition 174, ANY, 4614 bytes)
18/09/26 11:31:15 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 553) in 240070 ms on 192.168.33.12 (executor 3) (95/409)
18/09/26 11:31:18 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 584, 192.168.33.11, executor 5, partition 175, ANY, 4614 bytes)
18/09/26 11:31:18 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 548) in 282583 ms on 192.168.33.11 (executor 5) (96/409)
18/09/26 11:31:25 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 585, 192.168.33.11, executor 5, partition 176, ANY, 4614 bytes)
18/09/26 11:31:25 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 551) in 271742 ms on 192.168.33.11 (executor 5) (97/409)
18/09/26 11:31:27 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 586, 192.168.33.11, executor 5, partition 177, ANY, 4614 bytes)
18/09/26 11:31:27 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 544) in 319072 ms on 192.168.33.11 (executor 5) (98/409)
18/09/26 11:31:42 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 587, 192.168.33.13, executor 2, partition 178, ANY, 4614 bytes)
18/09/26 11:31:42 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 554) in 216299 ms on 192.168.33.13 (executor 2) (99/409)
18/09/26 11:31:56 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 588, 192.168.33.12, executor 3, partition 179, ANY, 4614 bytes)
18/09/26 11:31:56 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 552) in 281710 ms on 192.168.33.12 (executor 3) (100/409)
18/09/26 11:32:02 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 589, 192.168.33.12, executor 3, partition 180, ANY, 4614 bytes)
18/09/26 11:32:02 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 543) in 356262 ms on 192.168.33.12 (executor 3) (101/409)
18/09/26 11:32:15 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 590, 192.168.33.11, executor 5, partition 181, ANY, 4614 bytes)
18/09/26 11:32:15 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 550) in 334141 ms on 192.168.33.11 (executor 5) (102/409)
18/09/26 11:32:21 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 591, 192.168.33.10, executor 1, partition 182, ANY, 4614 bytes)
18/09/26 11:32:21 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 486) in 980214 ms on 192.168.33.10 (executor 1) (103/409)
18/09/26 11:32:23 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 592, 192.168.33.13, executor 2, partition 183, ANY, 4614 bytes)
18/09/26 11:32:23 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 541) in 389989 ms on 192.168.33.13 (executor 2) (104/409)
18/09/26 11:32:36 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 593, 192.168.33.12, executor 3, partition 184, ANY, 4614 bytes)
18/09/26 11:32:36 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 561) in 237253 ms on 192.168.33.12 (executor 3) (105/409)
18/09/26 11:32:40 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 594, 192.168.33.15, executor 0, partition 185, NODE_LOCAL, 4614 bytes)
18/09/26 11:32:40 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 431) in 1001831 ms on 192.168.33.15 (executor 0) (106/409)
18/09/26 11:32:48 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 595, 192.168.33.13, executor 2, partition 186, ANY, 4614 bytes)
18/09/26 11:32:48 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 555) in 267207 ms on 192.168.33.13 (executor 2) (107/409)
18/09/26 11:32:49 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 596, 192.168.33.13, executor 2, partition 187, ANY, 4614 bytes)
18/09/26 11:32:49 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 557) in 256159 ms on 192.168.33.13 (executor 2) (108/409)
18/09/26 11:32:54 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 597, 192.168.33.11, executor 5, partition 188, ANY, 4614 bytes)
18/09/26 11:32:54 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 540) in 425849 ms on 192.168.33.11 (executor 5) (109/409)
18/09/26 11:33:00 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 598, 192.168.33.12, executor 3, partition 189, ANY, 4614 bytes)
18/09/26 11:33:00 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 566) in 237373 ms on 192.168.33.12 (executor 3) (110/409)
18/09/26 11:33:02 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 599, 192.168.33.10, executor 1, partition 190, ANY, 4614 bytes)
18/09/26 11:33:02 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 480) in 1021456 ms on 192.168.33.10 (executor 1) (111/409)
18/09/26 11:33:02 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 600, 192.168.33.13, executor 2, partition 191, ANY, 4614 bytes)
18/09/26 11:33:02 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 556) in 270701 ms on 192.168.33.13 (executor 2) (112/409)
18/09/26 11:33:06 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 601, 192.168.33.12, executor 3, partition 192, ANY, 4614 bytes)
18/09/26 11:33:06 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 567) in 235224 ms on 192.168.33.12 (executor 3) (113/409)
18/09/26 11:33:21 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 602, 192.168.33.12, executor 3, partition 193, ANY, 4614 bytes)
18/09/26 11:33:21 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 572) in 204841 ms on 192.168.33.12 (executor 3) (114/409)
18/09/26 11:33:34 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 603, 192.168.33.12, executor 3, partition 194, ANY, 4614 bytes)
18/09/26 11:33:34 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 576) in 200373 ms on 192.168.33.12 (executor 3) (115/409)
18/09/26 11:33:49 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 604, 192.168.33.11, executor 5, partition 195, ANY, 4614 bytes)
18/09/26 11:33:49 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 569) in 261493 ms on 192.168.33.11 (executor 5) (116/409)
18/09/26 11:34:11 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 605, 192.168.33.14, executor 4, partition 196, ANY, 4614 bytes)
18/09/26 11:34:11 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 535) in 543188 ms on 192.168.33.14 (executor 4) (117/409)
18/09/26 11:34:16 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 606, 192.168.33.15, executor 0, partition 197, NODE_LOCAL, 4614 bytes)
18/09/26 11:34:16 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 418) in 1098305 ms on 192.168.33.15 (executor 0) (118/409)
18/09/26 11:34:28 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 607, 192.168.33.11, executor 5, partition 198, ANY, 4614 bytes)
18/09/26 11:34:28 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 560) in 350442 ms on 192.168.33.11 (executor 5) (119/409)
18/09/26 11:34:31 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 608, 192.168.33.14, executor 4, partition 199, ANY, 4614 bytes)
18/09/26 11:34:31 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 539) in 534667 ms on 192.168.33.14 (executor 4) (120/409)
18/09/26 11:34:47 INFO TaskSetManager: Starting task 200.0 in stage 1.0 (TID 609, 192.168.33.13, executor 2, partition 200, ANY, 4614 bytes)
18/09/26 11:34:47 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 571) in 295073 ms on 192.168.33.13 (executor 2) (121/409)
18/09/26 11:35:00 INFO TaskSetManager: Starting task 201.0 in stage 1.0 (TID 610, 192.168.33.13, executor 2, partition 201, ANY, 4614 bytes)
18/09/26 11:35:00 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 558) in 387305 ms on 192.168.33.13 (executor 2) (122/409)
18/09/26 11:35:20 INFO TaskSetManager: Starting task 202.0 in stage 1.0 (TID 611, 192.168.33.11, executor 5, partition 202, ANY, 4614 bytes)
18/09/26 11:35:20 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 586) in 233201 ms on 192.168.33.11 (executor 5) (123/409)
18/09/26 11:35:33 INFO TaskSetManager: Starting task 203.0 in stage 1.0 (TID 612, 192.168.33.15, executor 0, partition 203, NODE_LOCAL, 4614 bytes)
18/09/26 11:35:33 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 419) in 1175072 ms on 192.168.33.15 (executor 0) (124/409)
18/09/26 11:35:35 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 488) in 1174178 ms on 192.168.33.10 (executor 1) (125/409)
18/09/26 11:35:37 INFO TaskSetManager: Starting task 204.0 in stage 1.0 (TID 613, 192.168.33.10, executor 1, partition 204, ANY, 4614 bytes)
18/09/26 11:35:41 INFO TaskSetManager: Starting task 205.0 in stage 1.0 (TID 614, 192.168.33.12, executor 3, partition 205, ANY, 4614 bytes)
18/09/26 11:35:41 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 583) in 266005 ms on 192.168.33.12 (executor 3) (126/409)
18/09/26 11:35:46 INFO TaskSetManager: Starting task 206.0 in stage 1.0 (TID 615, 192.168.33.10, executor 1, partition 206, ANY, 4614 bytes)
18/09/26 11:35:46 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 484) in 1185073 ms on 192.168.33.10 (executor 1) (127/409)
18/09/26 11:35:47 INFO TaskSetManager: Starting task 207.0 in stage 1.0 (TID 616, 192.168.33.14, executor 4, partition 207, ANY, 4614 bytes)
18/09/26 11:35:47 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 570) in 357117 ms on 192.168.33.14 (executor 4) (128/409)
18/09/26 11:35:51 INFO TaskSetManager: Starting task 208.0 in stage 1.0 (TID 617, 192.168.33.15, executor 0, partition 208, NODE_LOCAL, 4614 bytes)
18/09/26 11:35:51 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 420) in 1193125 ms on 192.168.33.15 (executor 0) (129/409)
18/09/26 11:35:57 INFO TaskSetManager: Starting task 209.0 in stage 1.0 (TID 618, 192.168.33.12, executor 3, partition 209, ANY, 4614 bytes)
18/09/26 11:35:57 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 593) in 201314 ms on 192.168.33.12 (executor 3) (130/409)
18/09/26 11:35:58 INFO TaskSetManager: Starting task 210.0 in stage 1.0 (TID 619, 192.168.33.14, executor 4, partition 210, ANY, 4614 bytes)
18/09/26 11:35:58 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 575) in 353455 ms on 192.168.33.14 (executor 4) (131/409)
18/09/26 11:36:03 INFO TaskSetManager: Starting task 211.0 in stage 1.0 (TID 620, 192.168.33.14, executor 4, partition 211, ANY, 4614 bytes)
18/09/26 11:36:03 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 565) in 429294 ms on 192.168.33.14 (executor 4) (132/409)
18/09/26 11:36:10 INFO TaskSetManager: Starting task 212.0 in stage 1.0 (TID 621, 192.168.33.15, executor 0, partition 212, NODE_LOCAL, 4614 bytes)
18/09/26 11:36:10 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 428) in 1212636 ms on 192.168.33.15 (executor 0) (133/409)
18/09/26 11:36:11 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 585) in 286076 ms on 192.168.33.11 (executor 5) (134/409)
18/09/26 11:36:13 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 587) in 271119 ms on 192.168.33.13 (executor 2) (135/409)
18/09/26 11:36:14 INFO TaskSetManager: Starting task 213.0 in stage 1.0 (TID 622, 192.168.33.13, executor 2, partition 213, ANY, 4614 bytes)
18/09/26 11:36:14 INFO TaskSetManager: Starting task 214.0 in stage 1.0 (TID 623, 192.168.33.11, executor 5, partition 214, ANY, 4614 bytes)
18/09/26 11:36:14 INFO TaskSetManager: Starting task 215.0 in stage 1.0 (TID 624, 192.168.33.13, executor 2, partition 215, ANY, 4614 bytes)
18/09/26 11:36:14 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 596) in 205101 ms on 192.168.33.13 (executor 2) (136/409)
18/09/26 11:36:16 INFO TaskSetManager: Starting task 216.0 in stage 1.0 (TID 625, 192.168.33.12, executor 3, partition 216, ANY, 4614 bytes)
18/09/26 11:36:16 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 598) in 196071 ms on 192.168.33.12 (executor 3) (137/409)
18/09/26 11:36:20 INFO TaskSetManager: Starting task 217.0 in stage 1.0 (TID 626, 192.168.33.13, executor 2, partition 217, ANY, 4614 bytes)
18/09/26 11:36:20 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 582) in 309791 ms on 192.168.33.13 (executor 2) (138/409)
18/09/26 11:36:24 INFO TaskSetManager: Starting task 218.0 in stage 1.0 (TID 627, 192.168.33.15, executor 0, partition 218, NODE_LOCAL, 4614 bytes)
18/09/26 11:36:24 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 423) in 1226362 ms on 192.168.33.15 (executor 0) (139/409)
18/09/26 11:36:28 INFO TaskSetManager: Starting task 219.0 in stage 1.0 (TID 628, 192.168.33.11, executor 5, partition 219, ANY, 4614 bytes)
18/09/26 11:36:28 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 590) in 252708 ms on 192.168.33.11 (executor 5) (140/409)
18/09/26 11:36:32 INFO TaskSetManager: Starting task 220.0 in stage 1.0 (TID 629, 192.168.33.15, executor 0, partition 220, NODE_LOCAL, 4614 bytes)
18/09/26 11:36:32 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 421) in 1234803 ms on 192.168.33.15 (executor 0) (141/409)
18/09/26 11:36:33 INFO TaskSetManager: Starting task 221.0 in stage 1.0 (TID 630, 192.168.33.15, executor 0, partition 221, NODE_LOCAL, 4614 bytes)
18/09/26 11:36:33 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 413) in 1235310 ms on 192.168.33.15 (executor 0) (142/409)
18/09/26 11:36:33 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 584) in 315241 ms on 192.168.33.11 (executor 5) (143/409)
18/09/26 11:36:37 INFO TaskSetManager: Starting task 222.0 in stage 1.0 (TID 631, 192.168.33.11, executor 5, partition 222, ANY, 4614 bytes)
18/09/26 11:37:01 INFO TaskSetManager: Starting task 223.0 in stage 1.0 (TID 632, 192.168.33.12, executor 3, partition 223, ANY, 4614 bytes)
18/09/26 11:37:01 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 588) in 304933 ms on 192.168.33.12 (executor 3) (144/409)
18/09/26 11:37:06 INFO TaskSetManager: Starting task 224.0 in stage 1.0 (TID 633, 192.168.33.15, executor 0, partition 224, NODE_LOCAL, 4614 bytes)
18/09/26 11:37:06 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 429) in 1267934 ms on 192.168.33.15 (executor 0) (145/409)
18/09/26 11:37:07 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 589) in 304573 ms on 192.168.33.12 (executor 3) (146/409)
18/09/26 11:37:07 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 602) in 225730 ms on 192.168.33.12 (executor 3) (147/409)
18/09/26 11:37:09 INFO TaskSetManager: Starting task 225.0 in stage 1.0 (TID 634, 192.168.33.12, executor 3, partition 225, ANY, 4614 bytes)
18/09/26 11:37:09 INFO TaskSetManager: Starting task 226.0 in stage 1.0 (TID 635, 192.168.33.12, executor 3, partition 226, ANY, 4614 bytes)
18/09/26 11:37:09 INFO TaskSetManager: Starting task 227.0 in stage 1.0 (TID 636, 192.168.33.15, executor 0, partition 227, NODE_LOCAL, 4614 bytes)
18/09/26 11:37:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 410) in 1271201 ms on 192.168.33.15 (executor 0) (148/409)
18/09/26 11:37:16 INFO TaskSetManager: Starting task 228.0 in stage 1.0 (TID 637, 192.168.33.14, executor 4, partition 228, ANY, 4614 bytes)
18/09/26 11:37:16 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 574) in 433449 ms on 192.168.33.14 (executor 4) (149/409)
18/09/26 11:37:27 INFO TaskSetManager: Starting task 229.0 in stage 1.0 (TID 638, 192.168.33.12, executor 3, partition 229, ANY, 4614 bytes)
18/09/26 11:37:27 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 601) in 260290 ms on 192.168.33.12 (executor 3) (150/409)
18/09/26 11:37:36 INFO TaskSetManager: Starting task 230.0 in stage 1.0 (TID 639, 192.168.33.15, executor 0, partition 230, NODE_LOCAL, 4614 bytes)
18/09/26 11:37:36 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 526) in 816972 ms on 192.168.33.15 (executor 0) (151/409)
18/09/26 11:37:40 INFO TaskSetManager: Starting task 231.0 in stage 1.0 (TID 640, 192.168.33.15, executor 0, partition 231, NODE_LOCAL, 4614 bytes)
18/09/26 11:37:40 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 432) in 1302561 ms on 192.168.33.15 (executor 0) (152/409)
18/09/26 11:37:54 INFO TaskSetManager: Starting task 232.0 in stage 1.0 (TID 641, 192.168.33.14, executor 4, partition 232, ANY, 4614 bytes)
18/09/26 11:37:54 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 605) in 223586 ms on 192.168.33.14 (executor 4) (153/409)
18/09/26 11:38:06 INFO TaskSetManager: Starting task 233.0 in stage 1.0 (TID 642, 192.168.33.14, executor 4, partition 233, ANY, 4614 bytes)
18/09/26 11:38:06 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 573) in 489006 ms on 192.168.33.14 (executor 4) (154/409)
18/09/26 11:38:15 INFO TaskSetManager: Starting task 234.0 in stage 1.0 (TID 643, 192.168.33.15, executor 0, partition 234, NODE_LOCAL, 4614 bytes)
18/09/26 11:38:15 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 417) in 1337803 ms on 192.168.33.15 (executor 0) (155/409)
18/09/26 11:38:21 INFO TaskSetManager: Starting task 235.0 in stage 1.0 (TID 644, 192.168.33.10, executor 1, partition 235, ANY, 4614 bytes)
18/09/26 11:38:21 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 485) in 1340307 ms on 192.168.33.10 (executor 1) (156/409)
18/09/26 11:38:24 INFO TaskSetManager: Starting task 236.0 in stage 1.0 (TID 645, 192.168.33.10, executor 1, partition 236, ANY, 4614 bytes)
18/09/26 11:38:24 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 453) in 1343304 ms on 192.168.33.10 (executor 1) (157/409)
18/09/26 11:38:24 INFO TaskSetManager: Starting task 237.0 in stage 1.0 (TID 646, 192.168.33.14, executor 4, partition 237, ANY, 4614 bytes)
18/09/26 11:38:24 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 608) in 233341 ms on 192.168.33.14 (executor 4) (158/409)
18/09/26 11:38:32 INFO TaskSetManager: Starting task 238.0 in stage 1.0 (TID 647, 192.168.33.13, executor 2, partition 238, ANY, 4614 bytes)
18/09/26 11:38:32 INFO TaskSetManager: Finished task 201.0 in stage 1.0 (TID 610) in 212161 ms on 192.168.33.13 (executor 2) (159/409)
18/09/26 11:38:33 INFO TaskSetManager: Starting task 239.0 in stage 1.0 (TID 648, 192.168.33.13, executor 2, partition 239, ANY, 4614 bytes)
18/09/26 11:38:33 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 600) in 330981 ms on 192.168.33.13 (executor 2) (160/409)
18/09/26 11:38:37 INFO TaskSetManager: Starting task 240.0 in stage 1.0 (TID 649, 192.168.33.14, executor 4, partition 240, ANY, 4614 bytes)
18/09/26 11:38:37 INFO TaskSetManager: Finished task 210.0 in stage 1.0 (TID 619) in 158656 ms on 192.168.33.14 (executor 4) (161/409)
18/09/26 11:39:05 INFO TaskSetManager: Starting task 241.0 in stage 1.0 (TID 650, 192.168.33.13, executor 2, partition 241, ANY, 4614 bytes)
18/09/26 11:39:05 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 592) in 401512 ms on 192.168.33.13 (executor 2) (162/409)
18/09/26 11:39:16 INFO TaskSetManager: Starting task 242.0 in stage 1.0 (TID 651, 192.168.33.15, executor 0, partition 242, NODE_LOCAL, 4614 bytes)
18/09/26 11:39:16 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 427) in 1398492 ms on 192.168.33.15 (executor 0) (163/409)
18/09/26 11:39:24 INFO TaskSetManager: Starting task 243.0 in stage 1.0 (TID 652, 192.168.33.13, executor 2, partition 243, ANY, 4614 bytes)
18/09/26 11:39:24 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 595) in 396385 ms on 192.168.33.13 (executor 2) (164/409)
18/09/26 11:39:35 INFO TaskSetManager: Starting task 244.0 in stage 1.0 (TID 653, 192.168.33.12, executor 3, partition 244, ANY, 4614 bytes)
18/09/26 11:39:35 INFO TaskSetManager: Finished task 205.0 in stage 1.0 (TID 614) in 234659 ms on 192.168.33.12 (executor 3) (165/409)
18/09/26 11:39:40 INFO TaskSetManager: Starting task 245.0 in stage 1.0 (TID 654, 192.168.33.10, executor 1, partition 245, ANY, 4614 bytes)
18/09/26 11:39:40 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 487) in 1419504 ms on 192.168.33.10 (executor 1) (166/409)
18/09/26 11:39:46 INFO TaskSetManager: Starting task 246.0 in stage 1.0 (TID 655, 192.168.33.11, executor 5, partition 246, ANY, 4614 bytes)
18/09/26 11:39:46 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 604) in 357186 ms on 192.168.33.11 (executor 5) (167/409)
18/09/26 11:39:52 INFO TaskSetManager: Starting task 247.0 in stage 1.0 (TID 656, 192.168.33.10, executor 1, partition 247, ANY, 4614 bytes)
18/09/26 11:39:52 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 482) in 1430890 ms on 192.168.33.10 (executor 1) (168/409)
18/09/26 11:39:58 INFO TaskSetManager: Starting task 248.0 in stage 1.0 (TID 657, 192.168.33.12, executor 3, partition 248, ANY, 4614 bytes)
18/09/26 11:39:58 INFO TaskSetManager: Finished task 216.0 in stage 1.0 (TID 625) in 222416 ms on 192.168.33.12 (executor 3) (169/409)
18/09/26 11:40:02 INFO TaskSetManager: Starting task 249.0 in stage 1.0 (TID 658, 192.168.33.15, executor 0, partition 249, NODE_LOCAL, 4614 bytes)
18/09/26 11:40:02 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 534) in 901517 ms on 192.168.33.15 (executor 0) (170/409)
18/09/26 11:40:05 INFO TaskSetManager: Finished task 222.0 in stage 1.0 (TID 631) in 208195 ms on 192.168.33.11 (executor 5) (171/409)
18/09/26 11:40:06 INFO TaskSetManager: Starting task 250.0 in stage 1.0 (TID 659, 192.168.33.11, executor 5, partition 250, ANY, 4614 bytes)
18/09/26 11:40:17 INFO TaskSetManager: Starting task 251.0 in stage 1.0 (TID 660, 192.168.33.13, executor 2, partition 251, ANY, 4614 bytes)
18/09/26 11:40:17 INFO TaskSetManager: Finished task 217.0 in stage 1.0 (TID 626) in 236986 ms on 192.168.33.13 (executor 2) (172/409)
18/09/26 11:40:36 INFO TaskSetManager: Starting task 252.0 in stage 1.0 (TID 661, 192.168.33.14, executor 4, partition 252, ANY, 4614 bytes)
18/09/26 11:40:36 INFO TaskSetManager: Finished task 207.0 in stage 1.0 (TID 616) in 288635 ms on 192.168.33.14 (executor 4) (173/409)
18/09/26 11:40:42 INFO TaskSetManager: Starting task 253.0 in stage 1.0 (TID 662, 192.168.33.15, executor 0, partition 253, NODE_LOCAL, 4614 bytes)
18/09/26 11:40:42 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 411) in 1484795 ms on 192.168.33.15 (executor 0) (174/409)
18/09/26 11:40:44 INFO TaskSetManager: Finished task 202.0 in stage 1.0 (TID 611) in 324070 ms on 192.168.33.11 (executor 5) (175/409)
18/09/26 11:40:45 INFO TaskSetManager: Finished task 219.0 in stage 1.0 (TID 628) in 257033 ms on 192.168.33.11 (executor 5) (176/409)
18/09/26 11:40:46 INFO TaskSetManager: Starting task 254.0 in stage 1.0 (TID 663, 192.168.33.11, executor 5, partition 254, ANY, 4614 bytes)
18/09/26 11:40:46 INFO TaskSetManager: Starting task 255.0 in stage 1.0 (TID 664, 192.168.33.11, executor 5, partition 255, ANY, 4614 bytes)
18/09/26 11:40:48 INFO TaskSetManager: Starting task 256.0 in stage 1.0 (TID 665, 192.168.33.14, executor 4, partition 256, ANY, 4614 bytes)
18/09/26 11:40:48 INFO TaskSetManager: Finished task 211.0 in stage 1.0 (TID 620) in 284966 ms on 192.168.33.14 (executor 4) (177/409)
18/09/26 11:40:57 INFO TaskSetManager: Starting task 257.0 in stage 1.0 (TID 666, 192.168.33.12, executor 3, partition 257, ANY, 4614 bytes)
18/09/26 11:40:57 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 603) in 443601 ms on 192.168.33.12 (executor 3) (178/409)
18/09/26 11:41:06 INFO TaskSetManager: Starting task 258.0 in stage 1.0 (TID 667, 192.168.33.12, executor 3, partition 258, ANY, 4614 bytes)
18/09/26 11:41:06 INFO TaskSetManager: Finished task 225.0 in stage 1.0 (TID 634) in 236911 ms on 192.168.33.12 (executor 3) (179/409)
18/09/26 11:41:11 INFO TaskSetManager: Starting task 259.0 in stage 1.0 (TID 668, 192.168.33.13, executor 2, partition 259, ANY, 4614 bytes)
18/09/26 11:41:11 INFO TaskSetManager: Finished task 215.0 in stage 1.0 (TID 624) in 297581 ms on 192.168.33.13 (executor 2) (180/409)
18/09/26 11:41:23 INFO TaskSetManager: Starting task 260.0 in stage 1.0 (TID 669, 192.168.33.12, executor 3, partition 260, ANY, 4614 bytes)
18/09/26 11:41:23 INFO TaskSetManager: Finished task 209.0 in stage 1.0 (TID 618) in 326107 ms on 192.168.33.12 (executor 3) (181/409)
18/09/26 11:41:28 INFO TaskSetManager: Starting task 261.0 in stage 1.0 (TID 670, 192.168.33.11, executor 5, partition 261, ANY, 4614 bytes)
18/09/26 11:41:28 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 607) in 419704 ms on 192.168.33.11 (executor 5) (182/409)
18/09/26 11:41:30 INFO TaskSetManager: Starting task 262.0 in stage 1.0 (TID 671, 192.168.33.12, executor 3, partition 262, ANY, 4614 bytes)
18/09/26 11:41:30 INFO TaskSetManager: Finished task 229.0 in stage 1.0 (TID 638) in 242935 ms on 192.168.33.12 (executor 3) (183/409)
18/09/26 11:41:32 INFO TaskSetManager: Starting task 263.0 in stage 1.0 (TID 672, 192.168.33.11, executor 5, partition 263, ANY, 4614 bytes)
18/09/26 11:41:32 INFO TaskSetManager: Finished task 214.0 in stage 1.0 (TID 623) in 318302 ms on 192.168.33.11 (executor 5) (184/409)
18/09/26 11:41:49 INFO TaskSetManager: Starting task 264.0 in stage 1.0 (TID 673, 192.168.33.12, executor 3, partition 264, ANY, 4614 bytes)
18/09/26 11:41:49 INFO TaskSetManager: Finished task 226.0 in stage 1.0 (TID 635) in 280335 ms on 192.168.33.12 (executor 3) (185/409)
18/09/26 11:42:08 INFO TaskSetManager: Starting task 265.0 in stage 1.0 (TID 674, 192.168.33.13, executor 2, partition 265, ANY, 4614 bytes)
18/09/26 11:42:08 INFO TaskSetManager: Finished task 200.0 in stage 1.0 (TID 609) in 441305 ms on 192.168.33.13 (executor 2) (186/409)
18/09/26 11:42:11 INFO TaskSetManager: Starting task 266.0 in stage 1.0 (TID 675, 192.168.33.12, executor 3, partition 266, ANY, 4614 bytes)
18/09/26 11:42:11 INFO TaskSetManager: Finished task 223.0 in stage 1.0 (TID 632) in 310514 ms on 192.168.33.12 (executor 3) (187/409)
18/09/26 11:42:27 INFO TaskSetManager: Starting task 267.0 in stage 1.0 (TID 676, 192.168.33.15, executor 0, partition 267, NODE_LOCAL, 4614 bytes)
18/09/26 11:42:27 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 536) in 1035481 ms on 192.168.33.15 (executor 0) (188/409)
18/09/26 11:42:27 INFO TaskSetManager: Finished task 239.0 in stage 1.0 (TID 648) in 234031 ms on 192.168.33.13 (executor 2) (189/409)
18/09/26 11:42:31 INFO TaskSetManager: Starting task 268.0 in stage 1.0 (TID 677, 192.168.33.15, executor 0, partition 268, NODE_LOCAL, 4614 bytes)
18/09/26 11:42:31 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 416) in 1592860 ms on 192.168.33.15 (executor 0) (190/409)
18/09/26 11:42:34 INFO TaskSetManager: Starting task 269.0 in stage 1.0 (TID 678, 192.168.33.13, executor 2, partition 269, ANY, 4614 bytes)
18/09/26 11:42:36 INFO TaskSetManager: Starting task 270.0 in stage 1.0 (TID 679, 192.168.33.12, executor 3, partition 270, ANY, 4614 bytes)
18/09/26 11:42:36 INFO TaskSetManager: Finished task 244.0 in stage 1.0 (TID 653) in 180417 ms on 192.168.33.12 (executor 3) (191/409)
18/09/26 11:42:41 INFO TaskSetManager: Starting task 271.0 in stage 1.0 (TID 680, 192.168.33.13, executor 2, partition 271, ANY, 4614 bytes)
18/09/26 11:42:41 INFO TaskSetManager: Finished task 238.0 in stage 1.0 (TID 647) in 248759 ms on 192.168.33.13 (executor 2) (192/409)
18/09/26 11:43:00 INFO TaskSetManager: Starting task 272.0 in stage 1.0 (TID 681, 192.168.33.14, executor 4, partition 272, ANY, 4614 bytes)
18/09/26 11:43:00 INFO TaskSetManager: Finished task 228.0 in stage 1.0 (TID 637) in 343699 ms on 192.168.33.14 (executor 4) (193/409)
18/09/26 11:43:08 INFO TaskSetManager: Starting task 273.0 in stage 1.0 (TID 682, 192.168.33.14, executor 4, partition 273, ANY, 4614 bytes)
18/09/26 11:43:08 INFO TaskSetManager: Finished task 232.0 in stage 1.0 (TID 641) in 313636 ms on 192.168.33.14 (executor 4) (194/409)
18/09/26 11:43:18 INFO TaskSetManager: Starting task 274.0 in stage 1.0 (TID 683, 192.168.33.14, executor 4, partition 274, ANY, 4614 bytes)
18/09/26 11:43:18 INFO TaskSetManager: Finished task 240.0 in stage 1.0 (TID 649) in 281533 ms on 192.168.33.14 (executor 4) (195/409)
18/09/26 11:43:21 INFO TaskSetManager: Starting task 275.0 in stage 1.0 (TID 684, 192.168.33.15, executor 0, partition 275, NODE_LOCAL, 4614 bytes)
18/09/26 11:43:21 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 547) in 1017912 ms on 192.168.33.15 (executor 0) (196/409)
18/09/26 11:43:30 INFO TaskSetManager: Starting task 276.0 in stage 1.0 (TID 685, 192.168.33.15, executor 0, partition 276, NODE_LOCAL, 4614 bytes)
18/09/26 11:43:30 INFO TaskSetManager: Finished task 220.0 in stage 1.0 (TID 629) in 417086 ms on 192.168.33.15 (executor 0) (197/409)
18/09/26 11:43:30 INFO TaskSetManager: Finished task 251.0 in stage 1.0 (TID 660) in 192452 ms on 192.168.33.13 (executor 2) (198/409)
18/09/26 11:43:30 INFO TaskSetManager: Finished task 237.0 in stage 1.0 (TID 646) in 305813 ms on 192.168.33.14 (executor 4) (199/409)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.10:43403 in memory (size: 2.5 KB, free: 366.3 MB)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.15:35408 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.11:38333 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.13:33570 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.12:35074 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:43:32 INFO TaskSetManager: Starting task 277.0 in stage 1.0 (TID 686, 192.168.33.15, executor 0, partition 277, NODE_LOCAL, 4614 bytes)
18/09/26 11:43:32 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 537) in 1096862 ms on 192.168.33.15 (executor 0) (200/409)
18/09/26 11:43:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.14:34961 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:43:36 INFO TaskSetManager: Starting task 278.0 in stage 1.0 (TID 687, 192.168.33.13, executor 2, partition 278, ANY, 4614 bytes)
18/09/26 11:43:36 INFO TaskSetManager: Starting task 279.0 in stage 1.0 (TID 688, 192.168.33.14, executor 4, partition 279, ANY, 4614 bytes)
18/09/26 11:43:36 INFO TaskSetManager: Starting task 280.0 in stage 1.0 (TID 689, 192.168.33.13, executor 2, partition 280, ANY, 4614 bytes)
18/09/26 11:43:36 INFO TaskSetManager: Finished task 241.0 in stage 1.0 (TID 650) in 271398 ms on 192.168.33.13 (executor 2) (201/409)
18/09/26 11:43:38 INFO TaskSetManager: Starting task 281.0 in stage 1.0 (TID 690, 192.168.33.15, executor 0, partition 281, NODE_LOCAL, 4614 bytes)
18/09/26 11:43:38 INFO TaskSetManager: Finished task 231.0 in stage 1.0 (TID 640) in 357513 ms on 192.168.33.15 (executor 0) (202/409)
18/09/26 11:43:39 INFO TaskSetManager: Finished task 259.0 in stage 1.0 (TID 668) in 147524 ms on 192.168.33.13 (executor 2) (203/409)
18/09/26 11:43:42 INFO TaskSetManager: Starting task 282.0 in stage 1.0 (TID 691, 192.168.33.13, executor 2, partition 282, ANY, 4614 bytes)
18/09/26 11:44:06 INFO TaskSetManager: Starting task 283.0 in stage 1.0 (TID 692, 192.168.33.12, executor 3, partition 283, ANY, 4614 bytes)
18/09/26 11:44:06 INFO TaskSetManager: Finished task 257.0 in stage 1.0 (TID 666) in 188585 ms on 192.168.33.12 (executor 3) (204/409)
18/09/26 11:44:22 INFO TaskSetManager: Starting task 284.0 in stage 1.0 (TID 693, 192.168.33.13, executor 2, partition 284, ANY, 4614 bytes)
18/09/26 11:44:22 INFO TaskSetManager: Finished task 213.0 in stage 1.0 (TID 622) in 488682 ms on 192.168.33.13 (executor 2) (205/409)
18/09/26 11:44:27 INFO TaskSetManager: Starting task 285.0 in stage 1.0 (TID 694, 192.168.33.14, executor 4, partition 285, ANY, 4614 bytes)
18/09/26 11:44:27 INFO TaskSetManager: Finished task 252.0 in stage 1.0 (TID 661) in 230749 ms on 192.168.33.14 (executor 4) (206/409)
18/09/26 11:44:28 INFO TaskSetManager: Starting task 286.0 in stage 1.0 (TID 695, 192.168.33.13, executor 2, partition 286, ANY, 4614 bytes)
18/09/26 11:44:28 INFO TaskSetManager: Finished task 243.0 in stage 1.0 (TID 652) in 303520 ms on 192.168.33.13 (executor 2) (207/409)
18/09/26 11:44:28 INFO TaskSetManager: Starting task 287.0 in stage 1.0 (TID 696, 192.168.33.12, executor 3, partition 287, ANY, 4614 bytes)
18/09/26 11:44:28 INFO TaskSetManager: Finished task 248.0 in stage 1.0 (TID 657) in 269906 ms on 192.168.33.12 (executor 3) (208/409)
18/09/26 11:44:32 INFO TaskSetManager: Starting task 288.0 in stage 1.0 (TID 697, 192.168.33.11, executor 5, partition 288, ANY, 4614 bytes)
18/09/26 11:44:32 INFO TaskSetManager: Finished task 246.0 in stage 1.0 (TID 655) in 286064 ms on 192.168.33.11 (executor 5) (209/409)
18/09/26 11:44:33 INFO TaskSetManager: Starting task 289.0 in stage 1.0 (TID 698, 192.168.33.15, executor 0, partition 289, NODE_LOCAL, 4614 bytes)
18/09/26 11:44:33 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 594) in 713409 ms on 192.168.33.15 (executor 0) (210/409)
18/09/26 11:44:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.10:41196 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 11:44:37 INFO TaskSetManager: Starting task 290.0 in stage 1.0 (TID 699, 192.168.33.12, executor 3, partition 290, ANY, 4614 bytes)
18/09/26 11:44:37 INFO TaskSetManager: Finished task 258.0 in stage 1.0 (TID 667) in 211061 ms on 192.168.33.12 (executor 3) (211/409)
18/09/26 11:44:44 INFO TaskSetManager: Starting task 291.0 in stage 1.0 (TID 700, 192.168.33.14, executor 4, partition 291, ANY, 4614 bytes)
18/09/26 11:44:44 INFO TaskSetManager: Finished task 233.0 in stage 1.0 (TID 642) in 398058 ms on 192.168.33.14 (executor 4) (212/409)
18/09/26 11:44:54 INFO TaskSetManager: Starting task 292.0 in stage 1.0 (TID 701, 192.168.33.14, executor 4, partition 292, ANY, 4614 bytes)
18/09/26 11:44:54 INFO TaskSetManager: Finished task 256.0 in stage 1.0 (TID 665) in 245930 ms on 192.168.33.14 (executor 4) (213/409)
18/09/26 11:45:06 INFO TaskSetManager: Starting task 293.0 in stage 1.0 (TID 702, 192.168.33.11, executor 5, partition 293, ANY, 4614 bytes)
18/09/26 11:45:06 INFO TaskSetManager: Finished task 263.0 in stage 1.0 (TID 672) in 214114 ms on 192.168.33.11 (executor 5) (214/409)
18/09/26 11:45:10 INFO TaskSetManager: Starting task 294.0 in stage 1.0 (TID 703, 192.168.33.11, executor 5, partition 294, ANY, 4614 bytes)
18/09/26 11:45:10 INFO TaskSetManager: Finished task 250.0 in stage 1.0 (TID 659) in 304535 ms on 192.168.33.11 (executor 5) (215/409)
18/09/26 11:45:30 INFO TaskSetManager: Starting task 295.0 in stage 1.0 (TID 704, 192.168.33.11, executor 5, partition 295, ANY, 4614 bytes)
18/09/26 11:45:30 INFO TaskSetManager: Finished task 255.0 in stage 1.0 (TID 664) in 283861 ms on 192.168.33.11 (executor 5) (216/409)
18/09/26 11:45:31 INFO TaskSetManager: Starting task 296.0 in stage 1.0 (TID 705, 192.168.33.12, executor 3, partition 296, ANY, 4614 bytes)
18/09/26 11:45:31 INFO TaskSetManager: Finished task 264.0 in stage 1.0 (TID 673) in 221703 ms on 192.168.33.12 (executor 3) (217/409)
18/09/26 11:45:35 INFO TaskSetManager: Starting task 297.0 in stage 1.0 (TID 706, 192.168.33.15, executor 0, partition 297, NODE_LOCAL, 4614 bytes)
18/09/26 11:45:35 INFO TaskSetManager: Finished task 203.0 in stage 1.0 (TID 612) in 602241 ms on 192.168.33.15 (executor 0) (218/409)
18/09/26 11:45:42 INFO TaskSetManager: Starting task 298.0 in stage 1.0 (TID 707, 192.168.33.13, executor 2, partition 298, ANY, 4614 bytes)
18/09/26 11:45:42 INFO TaskSetManager: Finished task 269.0 in stage 1.0 (TID 678) in 188138 ms on 192.168.33.13 (executor 2) (219/409)
18/09/26 11:45:49 INFO TaskSetManager: Starting task 299.0 in stage 1.0 (TID 708, 192.168.33.12, executor 3, partition 299, ANY, 4614 bytes)
18/09/26 11:45:49 INFO TaskSetManager: Finished task 266.0 in stage 1.0 (TID 675) in 217360 ms on 192.168.33.12 (executor 3) (220/409)
18/09/26 11:46:03 INFO TaskSetManager: Starting task 300.0 in stage 1.0 (TID 709, 192.168.33.15, executor 0, partition 300, NODE_LOCAL, 4614 bytes)
18/09/26 11:46:03 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 522) in 1333692 ms on 192.168.33.15 (executor 0) (221/409)
18/09/26 11:46:13 INFO TaskSetManager: Starting task 301.0 in stage 1.0 (TID 710, 192.168.33.12, executor 3, partition 301, ANY, 4614 bytes)
18/09/26 11:46:13 INFO TaskSetManager: Finished task 262.0 in stage 1.0 (TID 671) in 282983 ms on 192.168.33.12 (executor 3) (222/409)
18/09/26 11:46:53 INFO TaskSetManager: Starting task 302.0 in stage 1.0 (TID 711, 192.168.33.15, executor 0, partition 302, NODE_LOCAL, 4614 bytes)
18/09/26 11:46:53 INFO TaskSetManager: Finished task 208.0 in stage 1.0 (TID 617) in 661704 ms on 192.168.33.15 (executor 0) (223/409)
18/09/26 11:46:56 INFO TaskSetManager: Starting task 303.0 in stage 1.0 (TID 712, 192.168.33.15, executor 0, partition 303, NODE_LOCAL, 4614 bytes)
18/09/26 11:46:56 INFO TaskSetManager: Finished task 234.0 in stage 1.0 (TID 643) in 520636 ms on 192.168.33.15 (executor 0) (224/409)
18/09/26 11:46:58 INFO TaskSetManager: Starting task 304.0 in stage 1.0 (TID 713, 192.168.33.15, executor 0, partition 304, NODE_LOCAL, 4614 bytes)
18/09/26 11:46:58 INFO TaskSetManager: Finished task 227.0 in stage 1.0 (TID 636) in 588931 ms on 192.168.33.15 (executor 0) (225/409)
18/09/26 11:46:58 INFO TaskSetManager: Finished task 271.0 in stage 1.0 (TID 680) in 257558 ms on 192.168.33.13 (executor 2) (226/409)
18/09/26 11:47:02 INFO TaskSetManager: Starting task 305.0 in stage 1.0 (TID 714, 192.168.33.13, executor 2, partition 305, ANY, 4614 bytes)
18/09/26 11:47:08 INFO TaskSetManager: Starting task 306.0 in stage 1.0 (TID 715, 192.168.33.14, executor 4, partition 306, ANY, 4614 bytes)
18/09/26 11:47:08 INFO TaskSetManager: Finished task 274.0 in stage 1.0 (TID 683) in 229547 ms on 192.168.33.14 (executor 4) (227/409)
18/09/26 11:47:15 INFO TaskSetManager: Starting task 307.0 in stage 1.0 (TID 716, 192.168.33.14, executor 4, partition 307, ANY, 4614 bytes)
18/09/26 11:47:15 INFO TaskSetManager: Finished task 279.0 in stage 1.0 (TID 688) in 218805 ms on 192.168.33.14 (executor 4) (228/409)
18/09/26 11:47:17 INFO TaskSetManager: Starting task 308.0 in stage 1.0 (TID 717, 192.168.33.15, executor 0, partition 308, NODE_LOCAL, 4614 bytes)
18/09/26 11:47:17 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 559) in 1123300 ms on 192.168.33.15 (executor 0) (229/409)
18/09/26 11:47:18 INFO TaskSetManager: Starting task 309.0 in stage 1.0 (TID 718, 192.168.33.15, executor 0, partition 309, NODE_LOCAL, 4614 bytes)
18/09/26 11:47:18 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 523) in 1408213 ms on 192.168.33.15 (executor 0) (230/409)
18/09/26 11:47:29 INFO TaskSetManager: Starting task 310.0 in stage 1.0 (TID 719, 192.168.33.14, executor 4, partition 310, ANY, 4614 bytes)
18/09/26 11:47:29 INFO TaskSetManager: Finished task 273.0 in stage 1.0 (TID 682) in 261225 ms on 192.168.33.14 (executor 4) (231/409)
18/09/26 11:47:32 INFO TaskSetManager: Starting task 311.0 in stage 1.0 (TID 720, 192.168.33.15, executor 0, partition 311, NODE_LOCAL, 4614 bytes)
18/09/26 11:47:32 INFO TaskSetManager: Finished task 249.0 in stage 1.0 (TID 658) in 450214 ms on 192.168.33.15 (executor 0) (232/409)
18/09/26 11:47:34 INFO TaskSetManager: Starting task 312.0 in stage 1.0 (TID 721, 192.168.33.15, executor 0, partition 312, NODE_LOCAL, 4614 bytes)
18/09/26 11:47:34 INFO TaskSetManager: Finished task 212.0 in stage 1.0 (TID 621) in 683939 ms on 192.168.33.15 (executor 0) (233/409)
18/09/26 11:47:39 INFO TaskSetManager: Starting task 313.0 in stage 1.0 (TID 722, 192.168.33.11, executor 5, partition 313, ANY, 4614 bytes)
18/09/26 11:47:39 INFO TaskSetManager: Finished task 261.0 in stage 1.0 (TID 670) in 371125 ms on 192.168.33.11 (executor 5) (234/409)
18/09/26 11:47:42 INFO TaskSetManager: Starting task 314.0 in stage 1.0 (TID 723, 192.168.33.14, executor 4, partition 314, ANY, 4614 bytes)
18/09/26 11:47:42 INFO TaskSetManager: Finished task 272.0 in stage 1.0 (TID 681) in 281459 ms on 192.168.33.14 (executor 4) (235/409)
18/09/26 11:47:51 INFO TaskSetManager: Starting task 315.0 in stage 1.0 (TID 724, 192.168.33.13, executor 2, partition 315, ANY, 4614 bytes)
18/09/26 11:47:51 INFO TaskSetManager: Finished task 265.0 in stage 1.0 (TID 674) in 342946 ms on 192.168.33.13 (executor 2) (236/409)
18/09/26 11:47:51 INFO TaskSetManager: Starting task 316.0 in stage 1.0 (TID 725, 192.168.33.13, executor 2, partition 316, ANY, 4614 bytes)
18/09/26 11:47:51 INFO TaskSetManager: Finished task 282.0 in stage 1.0 (TID 691) in 249230 ms on 192.168.33.13 (executor 2) (237/409)
18/09/26 11:48:14 INFO TaskSetManager: Starting task 317.0 in stage 1.0 (TID 726, 192.168.33.13, executor 2, partition 317, ANY, 4614 bytes)
18/09/26 11:48:14 INFO TaskSetManager: Finished task 280.0 in stage 1.0 (TID 689) in 277833 ms on 192.168.33.13 (executor 2) (238/409)
18/09/26 11:48:18 INFO TaskSetManager: Starting task 318.0 in stage 1.0 (TID 727, 192.168.33.15, executor 0, partition 318, NODE_LOCAL, 4614 bytes)
18/09/26 11:48:18 INFO TaskSetManager: Finished task 218.0 in stage 1.0 (TID 627) in 714393 ms on 192.168.33.15 (executor 0) (239/409)
18/09/26 11:48:30 INFO TaskSetManager: Starting task 319.0 in stage 1.0 (TID 728, 192.168.33.15, executor 0, partition 319, NODE_LOCAL, 4614 bytes)
18/09/26 11:48:30 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 527) in 1468109 ms on 192.168.33.15 (executor 0) (240/409)
18/09/26 11:48:31 INFO TaskSetManager: Starting task 320.0 in stage 1.0 (TID 729, 192.168.33.15, executor 0, partition 320, NODE_LOCAL, 4614 bytes)
18/09/26 11:48:31 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 606) in 854614 ms on 192.168.33.15 (executor 0) (241/409)
18/09/26 11:48:33 INFO TaskSetManager: Starting task 321.0 in stage 1.0 (TID 730, 192.168.33.15, executor 0, partition 321, NODE_LOCAL, 4614 bytes)
18/09/26 11:48:33 INFO TaskSetManager: Finished task 221.0 in stage 1.0 (TID 630) in 720197 ms on 192.168.33.15 (executor 0) (242/409)
18/09/26 11:48:48 INFO TaskSetManager: Starting task 322.0 in stage 1.0 (TID 731, 192.168.33.12, executor 3, partition 322, ANY, 4614 bytes)
18/09/26 11:48:48 INFO TaskSetManager: Finished task 283.0 in stage 1.0 (TID 692) in 281944 ms on 192.168.33.12 (executor 3) (243/409)
18/09/26 11:48:50 INFO TaskSetManager: Starting task 323.0 in stage 1.0 (TID 732, 192.168.33.12, executor 3, partition 323, ANY, 4614 bytes)
18/09/26 11:48:50 INFO TaskSetManager: Finished task 296.0 in stage 1.0 (TID 705) in 199697 ms on 192.168.33.12 (executor 3) (244/409)
18/09/26 11:48:58 INFO TaskSetManager: Starting task 324.0 in stage 1.0 (TID 733, 192.168.33.15, executor 0, partition 324, NODE_LOCAL, 4614 bytes)
18/09/26 11:48:58 INFO TaskSetManager: Finished task 242.0 in stage 1.0 (TID 651) in 581533 ms on 192.168.33.15 (executor 0) (245/409)
18/09/26 11:49:03 INFO TaskSetManager: Starting task 325.0 in stage 1.0 (TID 734, 192.168.33.12, executor 3, partition 325, ANY, 4614 bytes)
18/09/26 11:49:03 INFO TaskSetManager: Finished task 290.0 in stage 1.0 (TID 699) in 265960 ms on 192.168.33.12 (executor 3) (246/409)
18/09/26 11:49:04 INFO TaskSetManager: Starting task 326.0 in stage 1.0 (TID 735, 192.168.33.14, executor 4, partition 326, ANY, 4614 bytes)
18/09/26 11:49:04 INFO TaskSetManager: Finished task 292.0 in stage 1.0 (TID 701) in 250403 ms on 192.168.33.14 (executor 4) (247/409)
18/09/26 11:49:16 INFO TaskSetManager: Starting task 327.0 in stage 1.0 (TID 736, 192.168.33.12, executor 3, partition 327, ANY, 4614 bytes)
18/09/26 11:49:16 INFO TaskSetManager: Finished task 260.0 in stage 1.0 (TID 669) in 472913 ms on 192.168.33.12 (executor 3) (248/409)
18/09/26 11:49:31 INFO TaskSetManager: Starting task 328.0 in stage 1.0 (TID 737, 192.168.33.14, executor 4, partition 328, ANY, 4614 bytes)
18/09/26 11:49:31 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 508) in 1685450 ms on 192.168.33.14 (executor 4) (249/409)
18/09/26 11:49:34 INFO TaskSetManager: Starting task 329.0 in stage 1.0 (TID 738, 192.168.33.14, executor 4, partition 329, ANY, 4614 bytes)
18/09/26 11:49:34 INFO TaskSetManager: Finished task 291.0 in stage 1.0 (TID 700) in 289824 ms on 192.168.33.14 (executor 4) (250/409)
18/09/26 11:49:37 INFO TaskSetManager: Starting task 330.0 in stage 1.0 (TID 739, 192.168.33.11, executor 5, partition 330, ANY, 4614 bytes)
18/09/26 11:49:37 INFO TaskSetManager: Finished task 288.0 in stage 1.0 (TID 697) in 304171 ms on 192.168.33.11 (executor 5) (251/409)
18/09/26 11:49:39 INFO TaskSetManager: Starting task 331.0 in stage 1.0 (TID 740, 192.168.33.12, executor 3, partition 331, ANY, 4614 bytes)
18/09/26 11:49:39 INFO TaskSetManager: Finished task 287.0 in stage 1.0 (TID 696) in 310829 ms on 192.168.33.12 (executor 3) (252/409)
18/09/26 11:49:58 INFO TaskSetManager: Starting task 332.0 in stage 1.0 (TID 741, 192.168.33.13, executor 2, partition 332, ANY, 4614 bytes)
18/09/26 11:49:58 INFO TaskSetManager: Finished task 278.0 in stage 1.0 (TID 687) in 381967 ms on 192.168.33.13 (executor 2) (253/409)
18/09/26 11:49:58 INFO TaskSetManager: Starting task 333.0 in stage 1.0 (TID 742, 192.168.33.14, executor 4, partition 333, ANY, 4614 bytes)
18/09/26 11:49:58 INFO TaskSetManager: Finished task 285.0 in stage 1.0 (TID 694) in 331028 ms on 192.168.33.14 (executor 4) (254/409)
18/09/26 11:50:00 INFO TaskSetManager: Starting task 334.0 in stage 1.0 (TID 743, 192.168.33.13, executor 2, partition 334, ANY, 4614 bytes)
18/09/26 11:50:00 INFO TaskSetManager: Finished task 284.0 in stage 1.0 (TID 693) in 337332 ms on 192.168.33.13 (executor 2) (255/409)
18/09/26 11:50:11 INFO TaskSetManager: Starting task 335.0 in stage 1.0 (TID 744, 192.168.33.12, executor 3, partition 335, ANY, 4614 bytes)
18/09/26 11:50:11 INFO TaskSetManager: Finished task 301.0 in stage 1.0 (TID 710) in 238351 ms on 192.168.33.12 (executor 3) (256/409)
18/09/26 11:50:18 INFO TaskSetManager: Starting task 336.0 in stage 1.0 (TID 745, 192.168.33.13, executor 2, partition 336, ANY, 4614 bytes)
18/09/26 11:50:18 INFO TaskSetManager: Finished task 286.0 in stage 1.0 (TID 695) in 350404 ms on 192.168.33.13 (executor 2) (257/409)
18/09/26 11:50:21 INFO TaskSetManager: Starting task 337.0 in stage 1.0 (TID 746, 192.168.33.14, executor 4, partition 337, ANY, 4614 bytes)
18/09/26 11:50:21 INFO TaskSetManager: Finished task 310.0 in stage 1.0 (TID 719) in 171573 ms on 192.168.33.14 (executor 4) (258/409)
18/09/26 11:50:25 INFO TaskSetManager: Starting task 338.0 in stage 1.0 (TID 747, 192.168.33.11, executor 5, partition 338, ANY, 4614 bytes)
18/09/26 11:50:25 INFO TaskSetManager: Finished task 254.0 in stage 1.0 (TID 663) in 579214 ms on 192.168.33.11 (executor 5) (259/409)
18/09/26 11:50:26 INFO TaskSetManager: Starting task 339.0 in stage 1.0 (TID 748, 192.168.33.11, executor 5, partition 339, ANY, 4614 bytes)
18/09/26 11:50:26 INFO TaskSetManager: Finished task 295.0 in stage 1.0 (TID 704) in 296664 ms on 192.168.33.11 (executor 5) (260/409)
18/09/26 11:50:28 INFO TaskSetManager: Starting task 340.0 in stage 1.0 (TID 749, 192.168.33.11, executor 5, partition 340, ANY, 4614 bytes)
18/09/26 11:50:28 INFO TaskSetManager: Finished task 293.0 in stage 1.0 (TID 702) in 321898 ms on 192.168.33.11 (executor 5) (261/409)
18/09/26 11:50:34 INFO TaskSetManager: Starting task 341.0 in stage 1.0 (TID 750, 192.168.33.12, executor 3, partition 341, ANY, 4614 bytes)
18/09/26 11:50:34 INFO TaskSetManager: Finished task 299.0 in stage 1.0 (TID 708) in 284893 ms on 192.168.33.12 (executor 3) (262/409)
18/09/26 11:51:51 INFO TaskSetManager: Starting task 342.0 in stage 1.0 (TID 751, 192.168.33.14, executor 4, partition 342, ANY, 4614 bytes)
18/09/26 11:51:51 INFO TaskSetManager: Finished task 314.0 in stage 1.0 (TID 723) in 249502 ms on 192.168.33.14 (executor 4) (263/409)
18/09/26 11:52:10 INFO TaskSetManager: Starting task 343.0 in stage 1.0 (TID 752, 192.168.33.14, executor 4, partition 343, ANY, 4614 bytes)
18/09/26 11:52:10 INFO TaskSetManager: Finished task 306.0 in stage 1.0 (TID 715) in 302336 ms on 192.168.33.14 (executor 4) (264/409)
18/09/26 11:52:12 INFO TaskSetManager: Starting task 344.0 in stage 1.0 (TID 753, 192.168.33.14, executor 4, partition 344, ANY, 4614 bytes)
18/09/26 11:52:12 INFO TaskSetManager: Finished task 307.0 in stage 1.0 (TID 716) in 297680 ms on 192.168.33.14 (executor 4) (265/409)
18/09/26 11:52:26 INFO TaskSetManager: Starting task 345.0 in stage 1.0 (TID 754, 192.168.33.13, executor 2, partition 345, ANY, 4614 bytes)
18/09/26 11:52:26 INFO TaskSetManager: Finished task 315.0 in stage 1.0 (TID 724) in 275018 ms on 192.168.33.13 (executor 2) (266/409)
18/09/26 11:52:35 INFO TaskSetManager: Starting task 346.0 in stage 1.0 (TID 755, 192.168.33.13, executor 2, partition 346, ANY, 4614 bytes)
18/09/26 11:52:35 INFO TaskSetManager: Finished task 317.0 in stage 1.0 (TID 726) in 261514 ms on 192.168.33.13 (executor 2) (267/409)
18/09/26 11:52:39 INFO TaskSetManager: Starting task 347.0 in stage 1.0 (TID 756, 192.168.33.12, executor 3, partition 347, ANY, 4614 bytes)
18/09/26 11:52:39 INFO TaskSetManager: Finished task 322.0 in stage 1.0 (TID 731) in 231449 ms on 192.168.33.12 (executor 3) (268/409)
18/09/26 11:53:06 INFO TaskSetManager: Starting task 348.0 in stage 1.0 (TID 757, 192.168.33.14, executor 4, partition 348, ANY, 4614 bytes)
18/09/26 11:53:06 INFO TaskSetManager: Finished task 337.0 in stage 1.0 (TID 746) in 165417 ms on 192.168.33.14 (executor 4) (269/409)
18/09/26 11:53:16 INFO TaskSetManager: Starting task 349.0 in stage 1.0 (TID 758, 192.168.33.13, executor 2, partition 349, ANY, 4614 bytes)
18/09/26 11:53:16 INFO TaskSetManager: Finished task 298.0 in stage 1.0 (TID 707) in 454615 ms on 192.168.33.13 (executor 2) (270/409)
18/09/26 11:53:20 INFO TaskSetManager: Starting task 350.0 in stage 1.0 (TID 759, 192.168.33.11, executor 5, partition 350, ANY, 4614 bytes)
18/09/26 11:53:20 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 549) in 1603418 ms on 192.168.33.11 (executor 5) (271/409)
18/09/26 11:53:32 INFO TaskSetManager: Starting task 351.0 in stage 1.0 (TID 760, 192.168.33.11, executor 5, partition 351, ANY, 4614 bytes)
18/09/26 11:53:32 INFO TaskSetManager: Finished task 330.0 in stage 1.0 (TID 739) in 235000 ms on 192.168.33.11 (executor 5) (272/409)
18/09/26 11:53:33 INFO TaskSetManager: Starting task 352.0 in stage 1.0 (TID 761, 192.168.33.13, executor 2, partition 352, ANY, 4614 bytes)
18/09/26 11:53:33 INFO TaskSetManager: Finished task 305.0 in stage 1.0 (TID 714) in 391155 ms on 192.168.33.13 (executor 2) (273/409)
18/09/26 11:53:52 INFO TaskSetManager: Starting task 353.0 in stage 1.0 (TID 762, 192.168.33.12, executor 3, partition 353, ANY, 4614 bytes)
18/09/26 11:53:52 INFO TaskSetManager: Finished task 331.0 in stage 1.0 (TID 740) in 252515 ms on 192.168.33.12 (executor 3) (274/409)
18/09/26 11:54:10 INFO TaskSetManager: Starting task 354.0 in stage 1.0 (TID 763, 192.168.33.12, executor 3, partition 354, ANY, 4614 bytes)
18/09/26 11:54:10 INFO TaskSetManager: Finished task 327.0 in stage 1.0 (TID 736) in 294058 ms on 192.168.33.12 (executor 3) (275/409)
18/09/26 11:54:13 INFO TaskSetManager: Starting task 355.0 in stage 1.0 (TID 764, 192.168.33.11, executor 5, partition 355, ANY, 4614 bytes)
18/09/26 11:54:13 INFO TaskSetManager: Finished task 313.0 in stage 1.0 (TID 722) in 394236 ms on 192.168.33.11 (executor 5) (276/409)
18/09/26 11:54:38 INFO TaskSetManager: Starting task 356.0 in stage 1.0 (TID 765, 192.168.33.12, executor 3, partition 356, ANY, 4614 bytes)
18/09/26 11:54:38 INFO TaskSetManager: Finished task 323.0 in stage 1.0 (TID 732) in 347887 ms on 192.168.33.12 (executor 3) (277/409)
18/09/26 11:54:45 INFO TaskSetManager: Starting task 357.0 in stage 1.0 (TID 766, 192.168.33.11, executor 5, partition 357, ANY, 4614 bytes)
18/09/26 11:54:45 INFO TaskSetManager: Finished task 339.0 in stage 1.0 (TID 748) in 258764 ms on 192.168.33.11 (executor 5) (278/409)
18/09/26 11:54:50 INFO TaskSetManager: Starting task 358.0 in stage 1.0 (TID 767, 192.168.33.11, executor 5, partition 358, ANY, 4614 bytes)
18/09/26 11:54:50 INFO TaskSetManager: Finished task 338.0 in stage 1.0 (TID 747) in 264641 ms on 192.168.33.11 (executor 5) (279/409)
18/09/26 11:55:00 INFO TaskSetManager: Starting task 359.0 in stage 1.0 (TID 768, 192.168.33.14, executor 4, partition 359, ANY, 4614 bytes)
18/09/26 11:55:00 INFO TaskSetManager: Finished task 329.0 in stage 1.0 (TID 738) in 326573 ms on 192.168.33.14 (executor 4) (280/409)
18/09/26 11:55:04 INFO TaskSetManager: Starting task 360.0 in stage 1.0 (TID 769, 192.168.33.13, executor 2, partition 360, ANY, 4614 bytes)
18/09/26 11:55:04 INFO TaskSetManager: Finished task 332.0 in stage 1.0 (TID 741) in 306279 ms on 192.168.33.13 (executor 2) (281/409)
18/09/26 11:55:18 INFO TaskSetManager: Starting task 361.0 in stage 1.0 (TID 770, 192.168.33.12, executor 3, partition 361, ANY, 4614 bytes)
18/09/26 11:55:18 INFO TaskSetManager: Finished task 335.0 in stage 1.0 (TID 744) in 307170 ms on 192.168.33.12 (executor 3) (282/409)
18/09/26 11:55:28 INFO TaskSetManager: Starting task 362.0 in stage 1.0 (TID 771, 192.168.33.11, executor 5, partition 362, ANY, 4614 bytes)
18/09/26 11:55:28 INFO TaskSetManager: Finished task 294.0 in stage 1.0 (TID 703) in 617883 ms on 192.168.33.11 (executor 5) (283/409)
18/09/26 11:55:45 INFO TaskSetManager: Starting task 363.0 in stage 1.0 (TID 772, 192.168.33.14, executor 4, partition 363, ANY, 4614 bytes)
18/09/26 11:55:45 INFO TaskSetManager: Finished task 333.0 in stage 1.0 (TID 742) in 347120 ms on 192.168.33.14 (executor 4) (284/409)
18/09/26 11:56:04 INFO TaskSetManager: Starting task 364.0 in stage 1.0 (TID 773, 192.168.33.13, executor 2, partition 364, ANY, 4614 bytes)
18/09/26 11:56:04 INFO TaskSetManager: Finished task 336.0 in stage 1.0 (TID 745) in 345519 ms on 192.168.33.13 (executor 2) (285/409)
18/09/26 11:56:16 INFO TaskSetManager: Starting task 365.0 in stage 1.0 (TID 774, 192.168.33.14, executor 4, partition 365, ANY, 4614 bytes)
18/09/26 11:56:16 INFO TaskSetManager: Finished task 328.0 in stage 1.0 (TID 737) in 404853 ms on 192.168.33.14 (executor 4) (286/409)
18/09/26 11:56:22 INFO TaskSetManager: Starting task 366.0 in stage 1.0 (TID 775, 192.168.33.12, executor 3, partition 366, ANY, 4614 bytes)
18/09/26 11:56:22 INFO TaskSetManager: Finished task 347.0 in stage 1.0 (TID 756) in 222770 ms on 192.168.33.12 (executor 3) (287/409)
18/09/26 11:56:25 INFO TaskSetManager: Starting task 367.0 in stage 1.0 (TID 776, 192.168.33.13, executor 2, partition 367, ANY, 4614 bytes)
18/09/26 11:56:25 INFO TaskSetManager: Finished task 334.0 in stage 1.0 (TID 743) in 385597 ms on 192.168.33.13 (executor 2) (288/409)
18/09/26 11:56:33 INFO TaskSetManager: Starting task 368.0 in stage 1.0 (TID 777, 192.168.33.13, executor 2, partition 368, ANY, 4614 bytes)
18/09/26 11:56:33 INFO TaskSetManager: Finished task 346.0 in stage 1.0 (TID 755) in 237935 ms on 192.168.33.13 (executor 2) (289/409)
18/09/26 11:56:59 INFO TaskSetManager: Starting task 369.0 in stage 1.0 (TID 778, 192.168.33.13, executor 2, partition 369, ANY, 4614 bytes)
18/09/26 11:56:59 INFO TaskSetManager: Finished task 349.0 in stage 1.0 (TID 758) in 222514 ms on 192.168.33.13 (executor 2) (290/409)
18/09/26 11:57:24 INFO TaskSetManager: Starting task 370.0 in stage 1.0 (TID 779, 192.168.33.12, executor 3, partition 370, ANY, 4614 bytes)
18/09/26 11:57:24 INFO TaskSetManager: Finished task 325.0 in stage 1.0 (TID 734) in 501824 ms on 192.168.33.12 (executor 3) (291/409)
18/09/26 11:57:29 INFO TaskSetManager: Starting task 371.0 in stage 1.0 (TID 780, 192.168.33.11, executor 5, partition 371, ANY, 4614 bytes)
18/09/26 11:57:29 INFO TaskSetManager: Finished task 340.0 in stage 1.0 (TID 749) in 421137 ms on 192.168.33.11 (executor 5) (292/409)
18/09/26 11:57:50 INFO TaskSetManager: Starting task 372.0 in stage 1.0 (TID 781, 192.168.33.14, executor 4, partition 372, ANY, 4614 bytes)
18/09/26 11:57:50 INFO TaskSetManager: Finished task 342.0 in stage 1.0 (TID 751) in 359024 ms on 192.168.33.14 (executor 4) (293/409)
18/09/26 11:57:52 INFO TaskSetManager: Starting task 373.0 in stage 1.0 (TID 782, 192.168.33.11, executor 5, partition 373, ANY, 4614 bytes)
18/09/26 11:57:52 INFO TaskSetManager: Finished task 350.0 in stage 1.0 (TID 759) in 272450 ms on 192.168.33.11 (executor 5) (294/409)
18/09/26 11:57:57 INFO TaskSetManager: Starting task 374.0 in stage 1.0 (TID 783, 192.168.33.13, executor 2, partition 374, ANY, 4614 bytes)
18/09/26 11:57:57 INFO TaskSetManager: Finished task 345.0 in stage 1.0 (TID 754) in 330990 ms on 192.168.33.13 (executor 2) (295/409)
18/09/26 11:58:54 INFO TaskSetManager: Starting task 375.0 in stage 1.0 (TID 784, 192.168.33.13, executor 2, partition 375, ANY, 4614 bytes)
18/09/26 11:58:54 INFO TaskSetManager: Finished task 352.0 in stage 1.0 (TID 761) in 321287 ms on 192.168.33.13 (executor 2) (296/409)
18/09/26 11:59:05 INFO TaskSetManager: Starting task 376.0 in stage 1.0 (TID 785, 192.168.33.11, executor 5, partition 376, ANY, 4614 bytes)
18/09/26 11:59:05 INFO TaskSetManager: Finished task 355.0 in stage 1.0 (TID 764) in 291502 ms on 192.168.33.11 (executor 5) (297/409)
18/09/26 11:59:35 INFO TaskSetManager: Starting task 377.0 in stage 1.0 (TID 786, 192.168.33.14, executor 4, partition 377, ANY, 4614 bytes)
18/09/26 11:59:35 INFO TaskSetManager: Finished task 343.0 in stage 1.0 (TID 752) in 444841 ms on 192.168.33.14 (executor 4) (298/409)
18/09/26 11:59:36 INFO TaskSetManager: Starting task 378.0 in stage 1.0 (TID 787, 192.168.33.11, executor 5, partition 378, ANY, 4614 bytes)
18/09/26 11:59:36 INFO TaskSetManager: Finished task 357.0 in stage 1.0 (TID 766) in 290856 ms on 192.168.33.11 (executor 5) (299/409)
18/09/26 11:59:45 INFO TaskSetManager: Starting task 379.0 in stage 1.0 (TID 788, 192.168.33.13, executor 2, partition 379, ANY, 4614 bytes)
18/09/26 11:59:45 INFO TaskSetManager: Finished task 364.0 in stage 1.0 (TID 773) in 220762 ms on 192.168.33.13 (executor 2) (300/409)
18/09/26 11:59:54 INFO TaskSetManager: Starting task 380.0 in stage 1.0 (TID 789, 192.168.33.14, executor 4, partition 380, ANY, 4614 bytes)
18/09/26 11:59:54 INFO TaskSetManager: Finished task 344.0 in stage 1.0 (TID 753) in 461730 ms on 192.168.33.14 (executor 4) (301/409)
18/09/26 12:00:16 INFO TaskSetManager: Starting task 381.0 in stage 1.0 (TID 790, 192.168.33.13, executor 2, partition 381, ANY, 4614 bytes)
18/09/26 12:00:16 INFO TaskSetManager: Finished task 360.0 in stage 1.0 (TID 769) in 312185 ms on 192.168.33.13 (executor 2) (302/409)
18/09/26 12:00:21 INFO TaskSetManager: Starting task 382.0 in stage 1.0 (TID 791, 192.168.33.12, executor 3, partition 382, ANY, 4614 bytes)
18/09/26 12:00:21 INFO TaskSetManager: Finished task 353.0 in stage 1.0 (TID 762) in 389018 ms on 192.168.33.12 (executor 3) (303/409)
18/09/26 12:00:47 INFO TaskSetManager: Starting task 383.0 in stage 1.0 (TID 792, 192.168.33.14, executor 4, partition 383, ANY, 4614 bytes)
18/09/26 12:00:47 INFO TaskSetManager: Finished task 348.0 in stage 1.0 (TID 757) in 461159 ms on 192.168.33.14 (executor 4) (304/409)
18/09/26 12:01:15 INFO TaskSetManager: Starting task 384.0 in stage 1.0 (TID 793, 192.168.33.12, executor 3, partition 384, ANY, 4614 bytes)
18/09/26 12:01:15 INFO TaskSetManager: Finished task 354.0 in stage 1.0 (TID 763) in 424524 ms on 192.168.33.12 (executor 3) (305/409)
18/09/26 12:01:24 INFO TaskSetManager: Starting task 385.0 in stage 1.0 (TID 794, 192.168.33.13, executor 2, partition 385, ANY, 4614 bytes)
18/09/26 12:01:24 INFO TaskSetManager: Finished task 367.0 in stage 1.0 (TID 776) in 298616 ms on 192.168.33.13 (executor 2) (306/409)
18/09/26 12:01:31 INFO TaskSetManager: Starting task 386.0 in stage 1.0 (TID 795, 192.168.33.13, executor 2, partition 386, ANY, 4614 bytes)
18/09/26 12:01:31 INFO TaskSetManager: Finished task 368.0 in stage 1.0 (TID 777) in 297287 ms on 192.168.33.13 (executor 2) (307/409)
18/09/26 12:03:16 INFO TaskSetManager: Starting task 387.0 in stage 1.0 (TID 796, 192.168.33.11, executor 5, partition 387, ANY, 4614 bytes)
18/09/26 12:03:16 INFO TaskSetManager: Finished task 362.0 in stage 1.0 (TID 771) in 467685 ms on 192.168.33.11 (executor 5) (308/409)
18/09/26 12:03:46 INFO TaskSetManager: Starting task 388.0 in stage 1.0 (TID 797, 192.168.33.14, executor 4, partition 388, ANY, 4614 bytes)
18/09/26 12:03:46 INFO TaskSetManager: Finished task 359.0 in stage 1.0 (TID 768) in 525268 ms on 192.168.33.14 (executor 4) (309/409)
18/09/26 12:04:49 INFO TaskSetManager: Starting task 389.0 in stage 1.0 (TID 798, 192.168.33.11, executor 5, partition 389, ANY, 4614 bytes)
18/09/26 12:04:49 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 597) in 1915271 ms on 192.168.33.11 (executor 5) (310/409)
18/09/26 12:04:53 INFO TaskSetManager: Starting task 390.0 in stage 1.0 (TID 799, 192.168.33.11, executor 5, partition 390, ANY, 4614 bytes)
18/09/26 12:04:53 INFO TaskSetManager: Finished task 351.0 in stage 1.0 (TID 760) in 681717 ms on 192.168.33.11 (executor 5) (311/409)
18/09/26 12:04:57 INFO TaskSetManager: Starting task 391.0 in stage 1.0 (TID 800, 192.168.33.12, executor 3, partition 391, ANY, 4614 bytes)
18/09/26 12:04:57 INFO TaskSetManager: Finished task 361.0 in stage 1.0 (TID 770) in 578610 ms on 192.168.33.12 (executor 3) (312/409)
18/09/26 12:05:22 INFO TaskSetManager: Starting task 392.0 in stage 1.0 (TID 801, 192.168.33.12, executor 3, partition 392, ANY, 4614 bytes)
18/09/26 12:05:22 INFO TaskSetManager: Finished task 366.0 in stage 1.0 (TID 775) in 539643 ms on 192.168.33.12 (executor 3) (313/409)
18/09/26 12:06:24 INFO TaskSetManager: Starting task 393.0 in stage 1.0 (TID 802, 192.168.33.11, executor 5, partition 393, ANY, 4614 bytes)
18/09/26 12:06:24 INFO TaskSetManager: Finished task 358.0 in stage 1.0 (TID 767) in 694304 ms on 192.168.33.11 (executor 5) (314/409)
18/09/26 12:06:31 INFO TaskSetManager: Starting task 394.0 in stage 1.0 (TID 803, 192.168.33.11, executor 5, partition 394, ANY, 4614 bytes)
18/09/26 12:06:31 INFO TaskSetManager: Finished task 373.0 in stage 1.0 (TID 782) in 518939 ms on 192.168.33.11 (executor 5) (315/409)
18/09/26 12:06:41 INFO TaskSetManager: Starting task 395.0 in stage 1.0 (TID 804, 192.168.33.11, executor 5, partition 395, ANY, 4614 bytes)
18/09/26 12:06:41 INFO TaskSetManager: Finished task 371.0 in stage 1.0 (TID 780) in 552249 ms on 192.168.33.11 (executor 5) (316/409)
18/09/26 12:07:08 INFO TaskSetManager: Starting task 396.0 in stage 1.0 (TID 805, 192.168.33.11, executor 5, partition 396, ANY, 4614 bytes)
18/09/26 12:07:08 INFO TaskSetManager: Finished task 376.0 in stage 1.0 (TID 785) in 483294 ms on 192.168.33.11 (executor 5) (317/409)
18/09/26 12:08:14 INFO TaskSetManager: Starting task 397.0 in stage 1.0 (TID 806, 192.168.33.11, executor 5, partition 397, ANY, 4614 bytes)
18/09/26 12:08:14 INFO TaskSetManager: Finished task 378.0 in stage 1.0 (TID 787) in 518225 ms on 192.168.33.11 (executor 5) (318/409)
18/09/26 12:08:15 INFO TaskSetManager: Starting task 398.0 in stage 1.0 (TID 807, 192.168.33.12, executor 3, partition 398, ANY, 4614 bytes)
18/09/26 12:08:15 INFO TaskSetManager: Finished task 370.0 in stage 1.0 (TID 779) in 650373 ms on 192.168.33.12 (executor 3) (319/409)
18/09/26 12:09:02 INFO TaskSetManager: Starting task 399.0 in stage 1.0 (TID 808, 192.168.33.13, executor 2, partition 399, ANY, 4614 bytes)
18/09/26 12:09:02 INFO TaskSetManager: Finished task 374.0 in stage 1.0 (TID 783) in 664853 ms on 192.168.33.13 (executor 2) (320/409)
18/09/26 12:11:13 INFO TaskSetManager: Starting task 400.0 in stage 1.0 (TID 809, 192.168.33.11, executor 5, partition 400, ANY, 4614 bytes)
18/09/26 12:11:13 INFO TaskSetManager: Finished task 387.0 in stage 1.0 (TID 796) in 477328 ms on 192.168.33.11 (executor 5) (321/409)
18/09/26 12:12:09 INFO TaskSetManager: Starting task 401.0 in stage 1.0 (TID 810, 192.168.33.11, executor 5, partition 401, ANY, 4614 bytes)
18/09/26 12:12:09 INFO TaskSetManager: Finished task 389.0 in stage 1.0 (TID 798) in 440226 ms on 192.168.33.11 (executor 5) (322/409)
18/09/26 12:12:18 INFO TaskSetManager: Starting task 402.0 in stage 1.0 (TID 811, 192.168.33.13, executor 2, partition 402, ANY, 4614 bytes)
18/09/26 12:12:18 INFO TaskSetManager: Finished task 375.0 in stage 1.0 (TID 784) in 804245 ms on 192.168.33.13 (executor 2) (323/409)
18/09/26 12:13:24 INFO TaskSetManager: Starting task 403.0 in stage 1.0 (TID 812, 192.168.33.13, executor 2, partition 403, ANY, 4614 bytes)
18/09/26 12:13:24 INFO TaskSetManager: Finished task 379.0 in stage 1.0 (TID 788) in 819276 ms on 192.168.33.13 (executor 2) (324/409)
18/09/26 12:14:55 INFO TaskSetManager: Starting task 404.0 in stage 1.0 (TID 813, 192.168.33.11, executor 5, partition 404, ANY, 4614 bytes)
18/09/26 12:14:55 INFO TaskSetManager: Finished task 390.0 in stage 1.0 (TID 799) in 601256 ms on 192.168.33.11 (executor 5) (325/409)
18/09/26 12:15:03 INFO TaskSetManager: Starting task 405.0 in stage 1.0 (TID 814, 192.168.33.13, executor 2, partition 405, ANY, 4614 bytes)
18/09/26 12:15:03 INFO TaskSetManager: Finished task 381.0 in stage 1.0 (TID 790) in 886494 ms on 192.168.33.13 (executor 2) (326/409)
18/09/26 12:16:25 INFO TaskSetManager: Starting task 406.0 in stage 1.0 (TID 815, 192.168.33.13, executor 2, partition 406, ANY, 4614 bytes)
18/09/26 12:16:25 INFO TaskSetManager: Finished task 385.0 in stage 1.0 (TID 794) in 900962 ms on 192.168.33.13 (executor 2) (327/409)
18/09/26 12:16:52 INFO TaskSetManager: Starting task 407.0 in stage 1.0 (TID 816, 192.168.33.11, executor 5, partition 407, ANY, 4614 bytes)
18/09/26 12:16:52 INFO TaskSetManager: Finished task 393.0 in stage 1.0 (TID 802) in 628478 ms on 192.168.33.11 (executor 5) (328/409)
18/09/26 12:16:57 INFO TaskSetManager: Starting task 408.0 in stage 1.0 (TID 817, 192.168.33.14, executor 4, partition 408, ANY, 4614 bytes)
18/09/26 12:16:57 INFO TaskSetManager: Finished task 363.0 in stage 1.0 (TID 772) in 1272230 ms on 192.168.33.14 (executor 4) (329/409)
18/09/26 12:17:13 INFO TaskSetManager: Finished task 394.0 in stage 1.0 (TID 803) in 641430 ms on 192.168.33.11 (executor 5) (330/409)
18/09/26 12:18:15 INFO TaskSetManager: Finished task 372.0 in stage 1.0 (TID 781) in 1225225 ms on 192.168.33.14 (executor 4) (331/409)
18/09/26 12:18:17 INFO TaskSetManager: Finished task 386.0 in stage 1.0 (TID 795) in 1005922 ms on 192.168.33.13 (executor 2) (332/409)
18/09/26 12:18:25 INFO TaskSetManager: Finished task 395.0 in stage 1.0 (TID 804) in 703525 ms on 192.168.33.11 (executor 5) (333/409)
18/09/26 12:19:31 INFO TaskSetManager: Finished task 270.0 in stage 1.0 (TID 679) in 2215747 ms on 192.168.33.12 (executor 3) (334/409)
18/09/26 12:19:35 INFO TaskSetManager: Finished task 399.0 in stage 1.0 (TID 808) in 633562 ms on 192.168.33.13 (executor 2) (335/409)
18/09/26 12:21:34 INFO TaskSetManager: Finished task 377.0 in stage 1.0 (TID 786) in 1318612 ms on 192.168.33.14 (executor 4) (336/409)
18/09/26 12:21:48 INFO TaskSetManager: Finished task 405.0 in stage 1.0 (TID 814) in 405462 ms on 192.168.33.13 (executor 2) (337/409)
18/09/26 12:21:52 INFO TaskSetManager: Finished task 365.0 in stage 1.0 (TID 774) in 1536071 ms on 192.168.33.14 (executor 4) (338/409)
18/09/26 12:22:18 INFO TaskSetManager: Finished task 403.0 in stage 1.0 (TID 812) in 534644 ms on 192.168.33.13 (executor 2) (339/409)
18/09/26 12:22:34 INFO TaskSetManager: Finished task 397.0 in stage 1.0 (TID 806) in 860301 ms on 192.168.33.11 (executor 5) (340/409)
18/09/26 12:22:39 INFO TaskSetManager: Finished task 402.0 in stage 1.0 (TID 811) in 621034 ms on 192.168.33.13 (executor 2) (341/409)
18/09/26 12:22:45 INFO TaskSetManager: Finished task 380.0 in stage 1.0 (TID 789) in 1371145 ms on 192.168.33.14 (executor 4) (342/409)
18/09/26 12:23:32 INFO TaskSetManager: Finished task 369.0 in stage 1.0 (TID 778) in 1593151 ms on 192.168.33.13 (executor 2) (343/409)
18/09/26 12:23:48 INFO TaskSetManager: Finished task 382.0 in stage 1.0 (TID 791) in 1407433 ms on 192.168.33.12 (executor 3) (344/409)
18/09/26 12:23:55 INFO TaskSetManager: Finished task 383.0 in stage 1.0 (TID 792) in 1388186 ms on 192.168.33.14 (executor 4) (345/409)
18/09/26 12:23:59 INFO TaskSetManager: Finished task 384.0 in stage 1.0 (TID 793) in 1364869 ms on 192.168.33.12 (executor 3) (346/409)
18/09/26 12:24:02 INFO TaskSetManager: Finished task 400.0 in stage 1.0 (TID 809) in 769044 ms on 192.168.33.11 (executor 5) (347/409)
18/09/26 12:24:03 INFO TaskSetManager: Finished task 406.0 in stage 1.0 (TID 815) in 457916 ms on 192.168.33.13 (executor 2) (348/409)
18/09/26 12:24:14 INFO TaskSetManager: Finished task 396.0 in stage 1.0 (TID 805) in 1026065 ms on 192.168.33.11 (executor 5) (349/409)
18/09/26 12:25:24 INFO TaskSetManager: Finished task 401.0 in stage 1.0 (TID 810) in 794877 ms on 192.168.33.11 (executor 5) (350/409)
18/09/26 12:27:00 INFO TaskSetManager: Finished task 404.0 in stage 1.0 (TID 813) in 725770 ms on 192.168.33.11 (executor 5) (351/409)
18/09/26 12:27:23 INFO TaskSetManager: Finished task 407.0 in stage 1.0 (TID 816) in 630732 ms on 192.168.33.11 (executor 5) (352/409)
18/09/26 12:30:38 INFO TaskSetManager: Finished task 391.0 in stage 1.0 (TID 800) in 1541422 ms on 192.168.33.12 (executor 3) (353/409)
18/09/26 12:31:58 INFO TaskSetManager: Finished task 392.0 in stage 1.0 (TID 801) in 1596289 ms on 192.168.33.12 (executor 3) (354/409)
18/09/26 12:32:21 INFO TaskSetManager: Finished task 398.0 in stage 1.0 (TID 807) in 1446630 ms on 192.168.33.12 (executor 3) (355/409)
18/09/26 12:32:41 INFO TaskSetManager: Finished task 408.0 in stage 1.0 (TID 817) in 943623 ms on 192.168.33.14 (executor 4) (356/409)
18/09/26 12:33:32 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 474) in 4651632 ms on 192.168.33.10 (executor 1) (357/409)
18/09/26 12:34:57 INFO TaskSetManager: Finished task 388.0 in stage 1.0 (TID 797) in 1871254 ms on 192.168.33.14 (executor 4) (358/409)
18/09/26 12:36:04 INFO TaskSetManager: Finished task 316.0 in stage 1.0 (TID 725) in 2893010 ms on 192.168.33.13 (executor 2) (359/409)
18/09/26 12:47:39 INFO TaskSetManager: Finished task 326.0 in stage 1.0 (TID 735) in 3514170 ms on 192.168.33.14 (executor 4) (360/409)
18/09/26 12:47:39 INFO TaskSetManager: Finished task 341.0 in stage 1.0 (TID 750) in 3424921 ms on 192.168.33.12 (executor 3) (361/409)
18/09/26 12:54:09 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 599) in 4866460 ms on 192.168.33.10 (executor 1) (362/409)
18/09/26 12:54:35 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 591) in 4933667 ms on 192.168.33.10 (executor 1) (363/409)
18/09/26 13:01:12 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 580) in 5414543 ms on 192.168.33.10 (executor 1) (364/409)
18/09/26 13:13:10 INFO TaskSetManager: Finished task 356.0 in stage 1.0 (TID 765) in 4711757 ms on 192.168.33.12 (executor 3) (365/409)
18/09/26 13:24:46 WARN TaskSetManager: Lost task 300.0 in stage 1.0 (TID 709, 192.168.33.15, executor 0): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.HashSet$HashTrieSet.updated0(HashSet.scala:546)
	at scala.collection.immutable.HashSet$HashTrieSet.updated0(HashSet.scala:543)
	at scala.collection.immutable.HashSet.$plus(HashSet.scala:84)
	at scala.collection.immutable.HashSet$SerializationProxy.readObject(HashSet.scala:1038)
	at sun.reflect.GeneratedMethodAccessor60.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2176)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2285)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2209)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2067)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1571)
	at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1973)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator.readNextItem(ExternalAppendOnlyMap.scala:514)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator.hasNext(ExternalAppendOnlyMap.scala:534)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap$SpillableIterator.readNext(ExternalAppendOnlyMap.scala:597)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap$SpillableIterator.next(ExternalAppendOnlyMap.scala:608)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap$SpillableIterator.next(ExternalAppendOnlyMap.scala:569)
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:30)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)

18/09/26 13:24:46 INFO TaskSetManager: Starting task 300.1 in stage 1.0 (TID 818, 192.168.33.15, executor 0, partition 300, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:12 WARN TransportChannelHandler: Exception in connection from /192.168.33.15:56464
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:221)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:899)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:275)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/09/26 13:31:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/0 is now EXITED (Command exited with code 52)
18/09/26 13:31:12 INFO StandaloneSchedulerBackend: Executor app-20180926111330-0006/0 removed: Command exited with code 52
18/09/26 13:31:12 ERROR TaskSchedulerImpl: Lost executor 0 on 192.168.33.15: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 150), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 114), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 15), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 6), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 18), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 0), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 9), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 21), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 12), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 218), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 227), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 3), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 185), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 212), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 221), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 203), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 125), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 197), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 242), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 128), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 11), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 20), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 23), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 5), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 14), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 113), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 17), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 8), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 2), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 208), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 220), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 10), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 19), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 118), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 127), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 1), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 22), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 13), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 4), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 249), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 16), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 231), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 7), so marking it as still running
18/09/26 13:31:12 WARN TaskSetManager: Lost task 311.0 in stage 1.0 (TID 720, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 234), so marking it as still running
18/09/26 13:31:12 WARN TaskSetManager: Lost task 320.0 in stage 1.0 (TID 729, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 117), so marking it as still running
18/09/26 13:31:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 138), so marking it as still running
18/09/26 13:31:12 WARN TaskSetManager: Lost task 281.0 in stage 1.0 (TID 690, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 308.0 in stage 1.0 (TID 717, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 230.0 in stage 1.0 (TID 639, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 302.0 in stage 1.0 (TID 711, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 275.0 in stage 1.0 (TID 684, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 224.0 in stage 1.0 (TID 633, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 319.0 in stage 1.0 (TID 728, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 300.1 in stage 1.0 (TID 818, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 277.0 in stage 1.0 (TID 686, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 268.0 in stage 1.0 (TID 677, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 304.0 in stage 1.0 (TID 713, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 289.0 in stage 1.0 (TID 698, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 253.0 in stage 1.0 (TID 662, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 324.0 in stage 1.0 (TID 733, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 297.0 in stage 1.0 (TID 706, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 318.0 in stage 1.0 (TID 727, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 309.0 in stage 1.0 (TID 718, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 267.0 in stage 1.0 (TID 676, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 276.0 in stage 1.0 (TID 685, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 312.0 in stage 1.0 (TID 721, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 321.0 in stage 1.0 (TID 730, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 WARN TaskSetManager: Lost task 303.0 in stage 1.0 (TID 712, 192.168.33.15, executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 13:31:12 INFO DAGScheduler: Executor lost: 0 (epoch 1)
18/09/26 13:31:12 INFO BlockManagerMaster: Removal of executor 0 requested
18/09/26 13:31:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0
18/09/26 13:31:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
18/09/26 13:31:12 INFO TaskSetManager: Starting task 303.1 in stage 1.0 (TID 819, 192.168.33.14, executor 4, partition 303, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 321.1 in stage 1.0 (TID 820, 192.168.33.13, executor 2, partition 321, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 312.1 in stage 1.0 (TID 821, 192.168.33.12, executor 3, partition 312, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 276.1 in stage 1.0 (TID 822, 192.168.33.11, executor 5, partition 276, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 267.1 in stage 1.0 (TID 823, 192.168.33.10, executor 1, partition 267, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 309.1 in stage 1.0 (TID 824, 192.168.33.14, executor 4, partition 309, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 318.1 in stage 1.0 (TID 825, 192.168.33.13, executor 2, partition 318, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 297.1 in stage 1.0 (TID 826, 192.168.33.12, executor 3, partition 297, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 324.1 in stage 1.0 (TID 827, 192.168.33.11, executor 5, partition 324, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 253.1 in stage 1.0 (TID 828, 192.168.33.10, executor 1, partition 253, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 289.1 in stage 1.0 (TID 829, 192.168.33.14, executor 4, partition 289, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 304.1 in stage 1.0 (TID 830, 192.168.33.13, executor 2, partition 304, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 268.1 in stage 1.0 (TID 831, 192.168.33.12, executor 3, partition 268, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 277.1 in stage 1.0 (TID 832, 192.168.33.11, executor 5, partition 277, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 300.2 in stage 1.0 (TID 833, 192.168.33.10, executor 1, partition 300, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 319.1 in stage 1.0 (TID 834, 192.168.33.14, executor 4, partition 319, ANY, 4614 bytes)
18/09/26 13:31:12 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 192.168.33.15, 35408, None)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 224.1 in stage 1.0 (TID 835, 192.168.33.13, executor 2, partition 224, ANY, 4614 bytes)
18/09/26 13:31:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
18/09/26 13:31:12 INFO TaskSetManager: Starting task 275.1 in stage 1.0 (TID 836, 192.168.33.12, executor 3, partition 275, ANY, 4614 bytes)
18/09/26 13:31:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/6 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/26 13:31:12 INFO TaskSetManager: Starting task 302.1 in stage 1.0 (TID 837, 192.168.33.11, executor 5, partition 302, ANY, 4614 bytes)
18/09/26 13:31:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/6 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/26 13:31:12 INFO TaskSetManager: Starting task 230.1 in stage 1.0 (TID 838, 192.168.33.10, executor 1, partition 230, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 308.1 in stage 1.0 (TID 839, 192.168.33.14, executor 4, partition 308, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 281.1 in stage 1.0 (TID 840, 192.168.33.13, executor 2, partition 281, ANY, 4614 bytes)
18/09/26 13:31:12 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
18/09/26 13:31:12 INFO TaskSetManager: Starting task 320.1 in stage 1.0 (TID 841, 192.168.33.12, executor 3, partition 320, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 311.1 in stage 1.0 (TID 842, 192.168.33.11, executor 5, partition 311, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 138.1 in stage 1.0 (TID 843, 192.168.33.14, executor 4, partition 138, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 117.1 in stage 1.0 (TID 844, 192.168.33.13, executor 2, partition 117, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 234.1 in stage 1.0 (TID 845, 192.168.33.12, executor 3, partition 234, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 7.1 in stage 1.0 (TID 846, 192.168.33.11, executor 5, partition 7, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 231.1 in stage 1.0 (TID 847, 192.168.33.14, executor 4, partition 231, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 16.1 in stage 1.0 (TID 848, 192.168.33.13, executor 2, partition 16, ANY, 4614 bytes)
18/09/26 13:31:12 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 1)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 249.1 in stage 1.0 (TID 849, 192.168.33.12, executor 3, partition 249, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 4.1 in stage 1.0 (TID 850, 192.168.33.11, executor 5, partition 4, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 13.1 in stage 1.0 (TID 851, 192.168.33.14, executor 4, partition 13, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 22.1 in stage 1.0 (TID 852, 192.168.33.13, executor 2, partition 22, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 1.1 in stage 1.0 (TID 853, 192.168.33.12, executor 3, partition 1, ANY, 4614 bytes)
18/09/26 13:31:12 INFO TaskSetManager: Starting task 127.1 in stage 1.0 (TID 854, 192.168.33.11, executor 5, partition 127, ANY, 4614 bytes)
18/09/26 13:31:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/6 is now RUNNING
18/09/26 13:31:12 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 0 (305/409, false)
18/09/26 13:31:12 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 0 (319/409, false)
18/09/26 13:31:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:57102) with ID 6
18/09/26 13:31:15 INFO TaskSetManager: Starting task 118.1 in stage 1.0 (TID 855, 192.168.33.15, executor 6, partition 118, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 19.1 in stage 1.0 (TID 856, 192.168.33.15, executor 6, partition 19, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 10.1 in stage 1.0 (TID 857, 192.168.33.15, executor 6, partition 10, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 220.1 in stage 1.0 (TID 858, 192.168.33.15, executor 6, partition 220, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 208.1 in stage 1.0 (TID 859, 192.168.33.15, executor 6, partition 208, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 2.1 in stage 1.0 (TID 860, 192.168.33.15, executor 6, partition 2, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 8.1 in stage 1.0 (TID 861, 192.168.33.15, executor 6, partition 8, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 17.1 in stage 1.0 (TID 862, 192.168.33.15, executor 6, partition 17, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 113.1 in stage 1.0 (TID 863, 192.168.33.15, executor 6, partition 113, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 14.1 in stage 1.0 (TID 864, 192.168.33.15, executor 6, partition 14, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 5.1 in stage 1.0 (TID 865, 192.168.33.15, executor 6, partition 5, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 23.1 in stage 1.0 (TID 866, 192.168.33.15, executor 6, partition 23, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 20.1 in stage 1.0 (TID 867, 192.168.33.15, executor 6, partition 20, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 11.1 in stage 1.0 (TID 868, 192.168.33.15, executor 6, partition 11, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 128.1 in stage 1.0 (TID 869, 192.168.33.15, executor 6, partition 128, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 242.1 in stage 1.0 (TID 870, 192.168.33.15, executor 6, partition 242, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 197.1 in stage 1.0 (TID 871, 192.168.33.15, executor 6, partition 197, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 125.1 in stage 1.0 (TID 872, 192.168.33.15, executor 6, partition 125, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 203.1 in stage 1.0 (TID 873, 192.168.33.15, executor 6, partition 203, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 221.1 in stage 1.0 (TID 874, 192.168.33.15, executor 6, partition 221, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 212.1 in stage 1.0 (TID 875, 192.168.33.15, executor 6, partition 212, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 185.1 in stage 1.0 (TID 876, 192.168.33.15, executor 6, partition 185, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 3.1 in stage 1.0 (TID 877, 192.168.33.15, executor 6, partition 3, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO TaskSetManager: Starting task 227.1 in stage 1.0 (TID 878, 192.168.33.15, executor 6, partition 227, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:15 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:41164 with 15.8 GB RAM, BlockManagerId(6, 192.168.33.15, 41164, None)
18/09/26 13:31:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.15:41164 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:31:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.15:57102
18/09/26 13:31:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 69363 bytes
18/09/26 13:31:19 INFO TaskSetManager: Starting task 218.1 in stage 1.0 (TID 879, 192.168.33.15, executor 6, partition 218, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 12.1 in stage 1.0 (TID 880, 192.168.33.15, executor 6, partition 12, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 21.1 in stage 1.0 (TID 881, 192.168.33.15, executor 6, partition 21, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 9.1 in stage 1.0 (TID 882, 192.168.33.15, executor 6, partition 9, NODE_LOCAL, 4614 bytes)
18/09/26 13:31:19 WARN TaskSetManager: Lost task 113.1 in stage 1.0 (TID 863, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=113, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 113.1 in stage 1.0 (TID 863) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 128.1 in stage 1.0 (TID 869, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=128, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 128.1 in stage 1.0 (TID 869) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 212.1 in stage 1.0 (TID 875, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=212, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 212.1 in stage 1.0 (TID 875) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 220.1 in stage 1.0 (TID 858, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=220, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 220.1 in stage 1.0 (TID 858) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 8.1 in stage 1.0 (TID 861, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 8.1 in stage 1.0 (TID 861) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 INFO DAGScheduler: Marking ShuffleMapStage 1 (flatMap at Partitioning.scala:78) as failed due to a fetch failure from ShuffleMapStage 0 (flatMap at Partitioning.scala:52)
18/09/26 13:31:19 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) failed in 8121,388 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 13:31:19 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:31:19 WARN TaskSetManager: Lost task 3.1 in stage 1.0 (TID 877, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=3, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 3.1 in stage 1.0 (TID 877) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 11.1 in stage 1.0 (TID 868, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=11, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 11.1 in stage 1.0 (TID 868) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 20.1 in stage 1.0 (TID 867, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=20, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 20.1 in stage 1.0 (TID 867) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 5.1 in stage 1.0 (TID 865, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 5.1 in stage 1.0 (TID 865) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 208.1 in stage 1.0 (TID 859, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=208, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 208.1 in stage 1.0 (TID 859) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 242.1 in stage 1.0 (TID 870, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=242, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 242.1 in stage 1.0 (TID 870) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 118.1 in stage 1.0 (TID 855, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=118, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 118.1 in stage 1.0 (TID 855) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 203.1 in stage 1.0 (TID 873, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=203, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 203.1 in stage 1.0 (TID 873) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 19.1 in stage 1.0 (TID 856, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=19, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 19.1 in stage 1.0 (TID 856) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 2.1 in stage 1.0 (TID 860, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=2, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 2.1 in stage 1.0 (TID 860) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 125.1 in stage 1.0 (TID 872, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=125, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 125.1 in stage 1.0 (TID 872) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 14.1 in stage 1.0 (TID 864, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=14, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 14.1 in stage 1.0 (TID 864) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 221.1 in stage 1.0 (TID 874, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=221, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 221.1 in stage 1.0 (TID 874) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 197.1 in stage 1.0 (TID 871, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=197, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 197.1 in stage 1.0 (TID 871) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 227.1 in stage 1.0 (TID 878, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=227, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 227.1 in stage 1.0 (TID 878) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 185.1 in stage 1.0 (TID 876, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=185, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 185.1 in stage 1.0 (TID 876) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 17.1 in stage 1.0 (TID 862, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=17, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 17.1 in stage 1.0 (TID 862) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 23.1 in stage 1.0 (TID 866, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=23, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 23.1 in stage 1.0 (TID 866) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 10.1 in stage 1.0 (TID 857, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=10, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 10.1 in stage 1.0 (TID 857) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 12.1 in stage 1.0 (TID 880, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=12, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 12.1 in stage 1.0 (TID 880) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 9.1 in stage 1.0 (TID 882, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 9.1 in stage 1.0 (TID 882) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 21.1 in stage 1.0 (TID 881, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=21, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 21.1 in stage 1.0 (TID 881) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 WARN TaskSetManager: Lost task 218.1 in stage 1.0 (TID 879, 192.168.33.15, executor 6): FetchFailed(null, shuffleId=5, mapId=-1, reduceId=218, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 13:31:19 INFO TaskSetManager: Task 218.1 in stage 1.0 (TID 879) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:19 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:31:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 13:31:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.3 KB, free 365.9 MB)
18/09/26 13:31:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 13:31:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.10:43403 (size: 2.5 KB, free: 366.3 MB)
18/09/26 13:31:19 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/09/26 13:31:19 INFO DAGScheduler: Submitting 104 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(4, 10, 16, 22, 28, 34, 40, 46, 48, 50, 52, 54, 56, 58, 60))
18/09/26 13:31:19 INFO TaskSchedulerImpl: Adding task set 0.1 with 104 tasks
18/09/26 13:31:19 INFO TaskSetManager: Starting task 0.0 in stage 0.1 (TID 883, 192.168.33.15, executor 6, partition 4, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 1.0 in stage 0.1 (TID 884, 192.168.33.15, executor 6, partition 10, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 2.0 in stage 0.1 (TID 885, 192.168.33.15, executor 6, partition 16, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 3.0 in stage 0.1 (TID 886, 192.168.33.15, executor 6, partition 22, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 4.0 in stage 0.1 (TID 887, 192.168.33.15, executor 6, partition 28, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 5.0 in stage 0.1 (TID 888, 192.168.33.15, executor 6, partition 34, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 6.0 in stage 0.1 (TID 889, 192.168.33.15, executor 6, partition 40, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 7.0 in stage 0.1 (TID 890, 192.168.33.15, executor 6, partition 46, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 8.0 in stage 0.1 (TID 891, 192.168.33.15, executor 6, partition 48, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 9.0 in stage 0.1 (TID 892, 192.168.33.15, executor 6, partition 50, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 10.0 in stage 0.1 (TID 893, 192.168.33.15, executor 6, partition 52, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 11.0 in stage 0.1 (TID 894, 192.168.33.15, executor 6, partition 54, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 12.0 in stage 0.1 (TID 895, 192.168.33.15, executor 6, partition 56, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 13.0 in stage 0.1 (TID 896, 192.168.33.15, executor 6, partition 58, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 14.0 in stage 0.1 (TID 897, 192.168.33.15, executor 6, partition 60, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 15.0 in stage 0.1 (TID 898, 192.168.33.15, executor 6, partition 62, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 16.0 in stage 0.1 (TID 899, 192.168.33.15, executor 6, partition 64, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 17.0 in stage 0.1 (TID 900, 192.168.33.15, executor 6, partition 66, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 18.0 in stage 0.1 (TID 901, 192.168.33.15, executor 6, partition 68, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 19.0 in stage 0.1 (TID 902, 192.168.33.15, executor 6, partition 70, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 20.0 in stage 0.1 (TID 903, 192.168.33.15, executor 6, partition 72, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 21.0 in stage 0.1 (TID 904, 192.168.33.15, executor 6, partition 74, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 22.0 in stage 0.1 (TID 905, 192.168.33.15, executor 6, partition 76, ANY, 4879 bytes)
18/09/26 13:31:19 INFO TaskSetManager: Starting task 23.0 in stage 0.1 (TID 906, 192.168.33.15, executor 6, partition 78, ANY, 4879 bytes)
18/09/26 13:31:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.15:41164 (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:31:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.15:41164 (size: 27.9 KB, free: 15.8 GB)
18/09/26 13:31:51 INFO TaskSetManager: Starting task 24.0 in stage 0.1 (TID 907, 192.168.33.15, executor 6, partition 112, ANY, 4879 bytes)
18/09/26 13:31:51 INFO TaskSetManager: Finished task 14.0 in stage 0.1 (TID 897) in 31699 ms on 192.168.33.15 (executor 6) (1/104)
18/09/26 13:31:52 INFO TaskSetManager: Starting task 25.0 in stage 0.1 (TID 908, 192.168.33.15, executor 6, partition 113, ANY, 4879 bytes)
18/09/26 13:31:52 INFO TaskSetManager: Finished task 0.0 in stage 0.1 (TID 883) in 32461 ms on 192.168.33.15 (executor 6) (2/104)
18/09/26 13:31:52 INFO TaskSetManager: Starting task 26.0 in stage 0.1 (TID 909, 192.168.33.15, executor 6, partition 114, ANY, 4879 bytes)
18/09/26 13:31:52 INFO TaskSetManager: Finished task 17.0 in stage 0.1 (TID 900) in 32547 ms on 192.168.33.15 (executor 6) (3/104)
18/09/26 13:31:52 INFO TaskSetManager: Starting task 27.0 in stage 0.1 (TID 910, 192.168.33.15, executor 6, partition 115, ANY, 4879 bytes)
18/09/26 13:31:52 INFO TaskSetManager: Finished task 10.0 in stage 0.1 (TID 893) in 32594 ms on 192.168.33.15 (executor 6) (4/104)
18/09/26 13:31:52 INFO TaskSetManager: Starting task 28.0 in stage 0.1 (TID 911, 192.168.33.15, executor 6, partition 118, ANY, 4879 bytes)
18/09/26 13:31:52 INFO TaskSetManager: Finished task 21.0 in stage 0.1 (TID 904) in 32632 ms on 192.168.33.15 (executor 6) (5/104)
18/09/26 13:31:52 INFO TaskSetManager: Starting task 29.0 in stage 0.1 (TID 912, 192.168.33.15, executor 6, partition 121, ANY, 4879 bytes)
18/09/26 13:31:52 INFO TaskSetManager: Finished task 19.0 in stage 0.1 (TID 902) in 33055 ms on 192.168.33.15 (executor 6) (6/104)
18/09/26 13:31:53 INFO TaskSetManager: Starting task 30.0 in stage 0.1 (TID 913, 192.168.33.15, executor 6, partition 123, ANY, 4879 bytes)
18/09/26 13:31:53 INFO TaskSetManager: Finished task 22.0 in stage 0.1 (TID 905) in 33306 ms on 192.168.33.15 (executor 6) (7/104)
18/09/26 13:31:53 INFO TaskSetManager: Starting task 31.0 in stage 0.1 (TID 914, 192.168.33.15, executor 6, partition 124, ANY, 4879 bytes)
18/09/26 13:31:53 INFO TaskSetManager: Finished task 5.0 in stage 0.1 (TID 888) in 33972 ms on 192.168.33.15 (executor 6) (8/104)
18/09/26 13:31:53 INFO TaskSetManager: Starting task 32.0 in stage 0.1 (TID 915, 192.168.33.15, executor 6, partition 125, ANY, 4879 bytes)
18/09/26 13:31:53 INFO TaskSetManager: Finished task 3.0 in stage 0.1 (TID 886) in 34039 ms on 192.168.33.15 (executor 6) (9/104)
18/09/26 13:31:54 INFO TaskSetManager: Starting task 33.0 in stage 0.1 (TID 916, 192.168.33.13, executor 2, partition 127, ANY, 4879 bytes)
18/09/26 13:31:54 WARN TaskSetManager: Lost task 16.1 in stage 1.0 (TID 848, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:31:54 INFO TaskSetManager: Task 16.1 in stage 1.0 (TID 848) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:54 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:31:54 INFO TaskSetManager: Starting task 34.0 in stage 0.1 (TID 917, 192.168.33.15, executor 6, partition 131, ANY, 4879 bytes)
18/09/26 13:31:54 INFO TaskSetManager: Finished task 4.0 in stage 0.1 (TID 887) in 34454 ms on 192.168.33.15 (executor 6) (10/104)
18/09/26 13:31:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.13:33570 (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:31:54 INFO TaskSetManager: Starting task 35.0 in stage 0.1 (TID 918, 192.168.33.15, executor 6, partition 132, ANY, 4879 bytes)
18/09/26 13:31:54 INFO TaskSetManager: Finished task 2.0 in stage 0.1 (TID 885) in 34488 ms on 192.168.33.15 (executor 6) (11/104)
18/09/26 13:31:54 INFO TaskSetManager: Starting task 36.0 in stage 0.1 (TID 919, 192.168.33.15, executor 6, partition 135, ANY, 4879 bytes)
18/09/26 13:31:54 INFO TaskSetManager: Finished task 12.0 in stage 0.1 (TID 895) in 34554 ms on 192.168.33.15 (executor 6) (12/104)
18/09/26 13:31:54 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:31:54 INFO TaskSetManager: Starting task 37.0 in stage 0.1 (TID 920, 192.168.33.15, executor 6, partition 136, ANY, 4879 bytes)
18/09/26 13:31:54 INFO TaskSetManager: Finished task 16.0 in stage 0.1 (TID 899) in 34577 ms on 192.168.33.15 (executor 6) (13/104)
18/09/26 13:31:54 INFO TaskSetManager: Starting task 38.0 in stage 0.1 (TID 921, 192.168.33.15, executor 6, partition 137, ANY, 4879 bytes)
18/09/26 13:31:54 INFO TaskSetManager: Finished task 8.0 in stage 0.1 (TID 891) in 34760 ms on 192.168.33.15 (executor 6) (14/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 39.0 in stage 0.1 (TID 922, 192.168.33.15, executor 6, partition 139, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 7.0 in stage 0.1 (TID 890) in 35168 ms on 192.168.33.15 (executor 6) (15/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 40.0 in stage 0.1 (TID 923, 192.168.33.15, executor 6, partition 140, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 15.0 in stage 0.1 (TID 898) in 35375 ms on 192.168.33.15 (executor 6) (16/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 41.0 in stage 0.1 (TID 924, 192.168.33.15, executor 6, partition 141, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 9.0 in stage 0.1 (TID 892) in 35491 ms on 192.168.33.15 (executor 6) (17/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 42.0 in stage 0.1 (TID 925, 192.168.33.15, executor 6, partition 142, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 20.0 in stage 0.1 (TID 903) in 35563 ms on 192.168.33.15 (executor 6) (18/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 43.0 in stage 0.1 (TID 926, 192.168.33.15, executor 6, partition 144, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 11.0 in stage 0.1 (TID 894) in 35796 ms on 192.168.33.15 (executor 6) (19/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 44.0 in stage 0.1 (TID 927, 192.168.33.15, executor 6, partition 145, ANY, 4879 bytes)
18/09/26 13:31:55 INFO TaskSetManager: Finished task 13.0 in stage 0.1 (TID 896) in 35928 ms on 192.168.33.15 (executor 6) (20/104)
18/09/26 13:31:55 INFO TaskSetManager: Starting task 45.0 in stage 0.1 (TID 928, 192.168.33.13, executor 2, partition 149, ANY, 4879 bytes)
18/09/26 13:31:55 WARN TaskSetManager: Lost task 281.1 in stage 1.0 (TID 840, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=237, reduceId=281, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:31:55 INFO TaskSetManager: Task 281.1 in stage 1.0 (TID 840) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:55 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:31:56 INFO TaskSetManager: Starting task 46.0 in stage 0.1 (TID 929, 192.168.33.15, executor 6, partition 150, ANY, 4879 bytes)
18/09/26 13:31:56 INFO TaskSetManager: Starting task 47.0 in stage 0.1 (TID 930, 192.168.33.15, executor 6, partition 151, ANY, 4879 bytes)
18/09/26 13:31:56 INFO TaskSetManager: Finished task 18.0 in stage 0.1 (TID 901) in 36249 ms on 192.168.33.15 (executor 6) (21/104)
18/09/26 13:31:56 INFO TaskSetManager: Finished task 23.0 in stage 0.1 (TID 906) in 36248 ms on 192.168.33.15 (executor 6) (22/104)
18/09/26 13:31:56 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:31:56 INFO TaskSetManager: Starting task 48.0 in stage 0.1 (TID 931, 192.168.33.11, executor 5, partition 201, ANY, 4879 bytes)
18/09/26 13:31:56 WARN TaskSetManager: Lost task 311.1 in stage 1.0 (TID 842, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=311, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:31:56 INFO TaskSetManager: Task 311.1 in stage 1.0 (TID 842) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:56 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:31:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.11:38333 (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:31:56 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:31:56 INFO TaskSetManager: Starting task 49.0 in stage 0.1 (TID 932, 192.168.33.15, executor 6, partition 216, ANY, 4879 bytes)
18/09/26 13:31:56 INFO TaskSetManager: Finished task 6.0 in stage 0.1 (TID 889) in 36859 ms on 192.168.33.15 (executor 6) (23/104)
18/09/26 13:31:58 INFO TaskSetManager: Starting task 50.0 in stage 0.1 (TID 933, 192.168.33.13, executor 2, partition 220, ANY, 4879 bytes)
18/09/26 13:31:58 WARN TaskSetManager: Lost task 321.1 in stage 1.0 (TID 820, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=321, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:31:58 INFO TaskSetManager: Task 321.1 in stage 1.0 (TID 820) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:58 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:31:58 INFO TaskSetManager: Starting task 51.0 in stage 0.1 (TID 934, 192.168.33.15, executor 6, partition 221, ANY, 4879 bytes)
18/09/26 13:31:58 INFO TaskSetManager: Finished task 1.0 in stage 0.1 (TID 884) in 38353 ms on 192.168.33.15 (executor 6) (24/104)
18/09/26 13:31:58 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:31:59 INFO TaskSetManager: Starting task 52.0 in stage 0.1 (TID 935, 192.168.33.11, executor 5, partition 223, ANY, 4879 bytes)
18/09/26 13:31:59 WARN TaskSetManager: Lost task 276.1 in stage 1.0 (TID 822, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=276, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:31:59 INFO TaskSetManager: Task 276.1 in stage 1.0 (TID 822) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:31:59 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:00 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:04 INFO TaskSetManager: Starting task 53.0 in stage 0.1 (TID 936, 192.168.33.11, executor 5, partition 226, ANY, 4879 bytes)
18/09/26 13:32:04 WARN TaskSetManager: Lost task 302.1 in stage 1.0 (TID 837, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=302, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:04 INFO TaskSetManager: Task 302.1 in stage 1.0 (TID 837) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:04 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:04 INFO TaskSetManager: Starting task 54.0 in stage 0.1 (TID 937, 192.168.33.14, executor 4, partition 229, ANY, 4879 bytes)
18/09/26 13:32:04 WARN TaskSetManager: Lost task 231.1 in stage 1.0 (TID 847, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=231, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:04 INFO TaskSetManager: Task 231.1 in stage 1.0 (TID 847) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:04 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.14:34961 (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:32:05 INFO TaskSetManager: Starting task 55.0 in stage 0.1 (TID 938, 192.168.33.13, executor 2, partition 230, ANY, 4879 bytes)
18/09/26 13:32:05 WARN TaskSetManager: Lost task 318.1 in stage 1.0 (TID 825, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=309, reduceId=318, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:05 INFO TaskSetManager: Task 318.1 in stage 1.0 (TID 825) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:05 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:05 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:06 INFO TaskSetManager: Starting task 56.0 in stage 0.1 (TID 939, 192.168.33.14, executor 4, partition 237, ANY, 4879 bytes)
18/09/26 13:32:06 WARN TaskSetManager: Lost task 13.1 in stage 1.0 (TID 851, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:06 INFO TaskSetManager: Task 13.1 in stage 1.0 (TID 851) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:06 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:06 INFO TaskSetManager: Starting task 57.0 in stage 0.1 (TID 940, 192.168.33.14, executor 4, partition 240, ANY, 4879 bytes)
18/09/26 13:32:06 WARN TaskSetManager: Lost task 138.1 in stage 1.0 (TID 843, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=138, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:06 INFO TaskSetManager: Task 138.1 in stage 1.0 (TID 843) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:06 INFO TaskSetManager: Starting task 58.0 in stage 0.1 (TID 941, 192.168.33.13, executor 2, partition 241, ANY, 4879 bytes)
18/09/26 13:32:06 WARN TaskSetManager: Lost task 22.1 in stage 1.0 (TID 852, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=151, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:06 INFO TaskSetManager: Task 22.1 in stage 1.0 (TID 852) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:06 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:08 INFO TaskSetManager: Starting task 59.0 in stage 0.1 (TID 942, 192.168.33.14, executor 4, partition 242, ANY, 4879 bytes)
18/09/26 13:32:08 WARN TaskSetManager: Lost task 309.1 in stage 1.0 (TID 824, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=326, reduceId=309, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:08 INFO TaskSetManager: Task 309.1 in stage 1.0 (TID 824) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:08 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:08 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:09 INFO TaskSetManager: Starting task 60.0 in stage 0.1 (TID 943, 192.168.33.13, executor 2, partition 243, ANY, 4879 bytes)
18/09/26 13:32:09 WARN TaskSetManager: Lost task 117.1 in stage 1.0 (TID 844, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=329, reduceId=117, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:09 INFO TaskSetManager: Task 117.1 in stage 1.0 (TID 844) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:09 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:09 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:09 INFO TaskSetManager: Starting task 61.0 in stage 0.1 (TID 944, 192.168.33.11, executor 5, partition 244, ANY, 4879 bytes)
18/09/26 13:32:09 WARN TaskSetManager: Lost task 324.1 in stage 1.0 (TID 827, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=324, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:09 INFO TaskSetManager: Task 324.1 in stage 1.0 (TID 827) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:09 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:10 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:11 INFO TaskSetManager: Starting task 62.0 in stage 0.1 (TID 945, 192.168.33.11, executor 5, partition 245, ANY, 4879 bytes)
18/09/26 13:32:11 INFO TaskSetManager: Finished task 48.0 in stage 0.1 (TID 931) in 14954 ms on 192.168.33.11 (executor 5) (25/104)
18/09/26 13:32:11 INFO TaskSetManager: Starting task 63.0 in stage 0.1 (TID 946, 192.168.33.11, executor 5, partition 246, ANY, 4879 bytes)
18/09/26 13:32:11 WARN TaskSetManager: Lost task 4.1 in stage 1.0 (TID 850, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=240, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:11 INFO TaskSetManager: Task 4.1 in stage 1.0 (TID 850) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:11 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:11 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:13 INFO TaskSetManager: Starting task 64.0 in stage 0.1 (TID 947, 192.168.33.14, executor 4, partition 247, ANY, 4879 bytes)
18/09/26 13:32:13 WARN TaskSetManager: Lost task 319.1 in stage 1.0 (TID 834, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=408, reduceId=319, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:13 INFO TaskSetManager: Task 319.1 in stage 1.0 (TID 834) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:13 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:13 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:14 INFO TaskSetManager: Starting task 65.0 in stage 0.1 (TID 948, 192.168.33.14, executor 4, partition 253, ANY, 4879 bytes)
18/09/26 13:32:14 WARN TaskSetManager: Lost task 289.1 in stage 1.0 (TID 829, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=289, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:14 INFO TaskSetManager: Task 289.1 in stage 1.0 (TID 829) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:14 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:14 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:15 INFO TaskSetManager: Starting task 66.0 in stage 0.1 (TID 949, 192.168.33.11, executor 5, partition 254, ANY, 4879 bytes)
18/09/26 13:32:15 WARN TaskSetManager: Lost task 277.1 in stage 1.0 (TID 832, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=346, reduceId=277, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:15 INFO TaskSetManager: Task 277.1 in stage 1.0 (TID 832) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:15 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:15 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:17 INFO TaskSetManager: Starting task 67.0 in stage 0.1 (TID 950, 192.168.33.13, executor 2, partition 255, ANY, 4879 bytes)
18/09/26 13:32:17 WARN TaskSetManager: Lost task 224.1 in stage 1.0 (TID 835, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=224, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:17 INFO TaskSetManager: Task 224.1 in stage 1.0 (TID 835) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:17 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:17 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:18 INFO TaskSetManager: Starting task 68.0 in stage 0.1 (TID 951, 192.168.33.13, executor 2, partition 256, ANY, 4879 bytes)
18/09/26 13:32:18 INFO TaskSetManager: Finished task 33.0 in stage 0.1 (TID 916) in 23956 ms on 192.168.33.13 (executor 2) (26/104)
18/09/26 13:32:19 INFO TaskSetManager: Starting task 69.0 in stage 0.1 (TID 952, 192.168.33.13, executor 2, partition 257, ANY, 4879 bytes)
18/09/26 13:32:19 INFO TaskSetManager: Finished task 45.0 in stage 0.1 (TID 928) in 23223 ms on 192.168.33.13 (executor 2) (27/104)
18/09/26 13:32:19 INFO TaskSetManager: Starting task 70.0 in stage 0.1 (TID 953, 192.168.33.13, executor 2, partition 259, ANY, 4879 bytes)
18/09/26 13:32:19 WARN TaskSetManager: Lost task 304.1 in stage 1.0 (TID 830, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=237, reduceId=304, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:19 INFO TaskSetManager: Task 304.1 in stage 1.0 (TID 830) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:19 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:19 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:19 INFO TaskSetManager: Starting task 71.0 in stage 0.1 (TID 954, 192.168.33.11, executor 5, partition 260, ANY, 4879 bytes)
18/09/26 13:32:19 WARN TaskSetManager: Lost task 127.1 in stage 1.0 (TID 854, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=127, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:19 INFO TaskSetManager: Task 127.1 in stage 1.0 (TID 854) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:19 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:19 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:20 INFO TaskSetManager: Starting task 72.0 in stage 0.1 (TID 955, 192.168.33.15, executor 6, partition 267, ANY, 4879 bytes)
18/09/26 13:32:20 INFO TaskSetManager: Finished task 26.0 in stage 0.1 (TID 909) in 27867 ms on 192.168.33.15 (executor 6) (28/104)
18/09/26 13:32:22 INFO TaskSetManager: Starting task 73.0 in stage 0.1 (TID 956, 192.168.33.15, executor 6, partition 289, ANY, 4879 bytes)
18/09/26 13:32:22 INFO TaskSetManager: Finished task 30.0 in stage 0.1 (TID 913) in 29000 ms on 192.168.33.15 (executor 6) (29/104)
18/09/26 13:32:22 INFO TaskSetManager: Starting task 74.0 in stage 0.1 (TID 957, 192.168.33.15, executor 6, partition 296, ANY, 4879 bytes)
18/09/26 13:32:22 INFO TaskSetManager: Finished task 28.0 in stage 0.1 (TID 911) in 29821 ms on 192.168.33.15 (executor 6) (30/104)
18/09/26 13:32:22 INFO TaskSetManager: Starting task 75.0 in stage 0.1 (TID 958, 192.168.33.15, executor 6, partition 297, ANY, 4879 bytes)
18/09/26 13:32:22 INFO TaskSetManager: Finished task 24.0 in stage 0.1 (TID 907) in 31313 ms on 192.168.33.15 (executor 6) (31/104)
18/09/26 13:32:23 INFO TaskSetManager: Starting task 76.0 in stage 0.1 (TID 959, 192.168.33.11, executor 5, partition 301, ANY, 4879 bytes)
18/09/26 13:32:23 INFO TaskSetManager: Finished task 53.0 in stage 0.1 (TID 936) in 19285 ms on 192.168.33.11 (executor 5) (32/104)
18/09/26 13:32:23 INFO TaskSetManager: Starting task 77.0 in stage 0.1 (TID 960, 192.168.33.13, executor 2, partition 302, ANY, 4879 bytes)
18/09/26 13:32:23 INFO TaskSetManager: Finished task 50.0 in stage 0.1 (TID 933) in 25306 ms on 192.168.33.13 (executor 2) (33/104)
18/09/26 13:32:23 INFO TaskSetManager: Starting task 78.0 in stage 0.1 (TID 961, 192.168.33.15, executor 6, partition 309, ANY, 4879 bytes)
18/09/26 13:32:23 INFO TaskSetManager: Finished task 25.0 in stage 0.1 (TID 908) in 31439 ms on 192.168.33.15 (executor 6) (34/104)
18/09/26 13:32:23 INFO TaskSetManager: Starting task 79.0 in stage 0.1 (TID 962, 192.168.33.15, executor 6, partition 313, ANY, 4879 bytes)
18/09/26 13:32:23 INFO TaskSetManager: Finished task 27.0 in stage 0.1 (TID 910) in 31549 ms on 192.168.33.15 (executor 6) (35/104)
18/09/26 13:32:24 INFO TaskSetManager: Starting task 80.0 in stage 0.1 (TID 963, 192.168.33.15, executor 6, partition 316, ANY, 4879 bytes)
18/09/26 13:32:24 INFO TaskSetManager: Finished task 35.0 in stage 0.1 (TID 918) in 30409 ms on 192.168.33.15 (executor 6) (36/104)
18/09/26 13:32:24 INFO TaskSetManager: Starting task 81.0 in stage 0.1 (TID 964, 192.168.33.15, executor 6, partition 319, ANY, 4879 bytes)
18/09/26 13:32:24 INFO TaskSetManager: Finished task 29.0 in stage 0.1 (TID 912) in 31859 ms on 192.168.33.15 (executor 6) (37/104)
18/09/26 13:32:24 INFO TaskSetManager: Starting task 82.0 in stage 0.1 (TID 965, 192.168.33.14, executor 4, partition 322, ANY, 4879 bytes)
18/09/26 13:32:24 WARN TaskSetManager: Lost task 303.1 in stage 1.0 (TID 819, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=243, reduceId=303, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:24 INFO TaskSetManager: Task 303.1 in stage 1.0 (TID 819) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:25 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:25 INFO TaskSetManager: Starting task 83.0 in stage 0.1 (TID 966, 192.168.33.14, executor 4, partition 326, ANY, 4879 bytes)
18/09/26 13:32:25 INFO TaskSetManager: Finished task 54.0 in stage 0.1 (TID 937) in 20945 ms on 192.168.33.14 (executor 4) (38/104)
18/09/26 13:32:25 INFO TaskSetManager: Starting task 84.0 in stage 0.1 (TID 967, 192.168.33.15, executor 6, partition 329, ANY, 4879 bytes)
18/09/26 13:32:25 INFO TaskSetManager: Finished task 31.0 in stage 0.1 (TID 914) in 31527 ms on 192.168.33.15 (executor 6) (39/104)
18/09/26 13:32:25 INFO TaskSetManager: Starting task 85.0 in stage 0.1 (TID 968, 192.168.33.15, executor 6, partition 331, ANY, 4879 bytes)
18/09/26 13:32:25 INFO TaskSetManager: Finished task 34.0 in stage 0.1 (TID 917) in 31216 ms on 192.168.33.15 (executor 6) (40/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 86.0 in stage 0.1 (TID 969, 192.168.33.15, executor 6, partition 333, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 40.0 in stage 0.1 (TID 923) in 30793 ms on 192.168.33.15 (executor 6) (41/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 87.0 in stage 0.1 (TID 970, 192.168.33.13, executor 2, partition 335, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 55.0 in stage 0.1 (TID 938) in 20264 ms on 192.168.33.13 (executor 2) (42/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 88.0 in stage 0.1 (TID 971, 192.168.33.15, executor 6, partition 336, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 32.0 in stage 0.1 (TID 915) in 32210 ms on 192.168.33.15 (executor 6) (43/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 89.0 in stage 0.1 (TID 972, 192.168.33.15, executor 6, partition 337, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 47.0 in stage 0.1 (TID 930) in 30119 ms on 192.168.33.15 (executor 6) (44/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 90.0 in stage 0.1 (TID 973, 192.168.33.15, executor 6, partition 339, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 46.0 in stage 0.1 (TID 929) in 30432 ms on 192.168.33.15 (executor 6) (45/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 91.0 in stage 0.1 (TID 974, 192.168.33.14, executor 4, partition 341, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 56.0 in stage 0.1 (TID 939) in 20427 ms on 192.168.33.14 (executor 4) (46/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 92.0 in stage 0.1 (TID 975, 192.168.33.15, executor 6, partition 346, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 37.0 in stage 0.1 (TID 920) in 32181 ms on 192.168.33.15 (executor 6) (47/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 93.0 in stage 0.1 (TID 976, 192.168.33.15, executor 6, partition 350, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 44.0 in stage 0.1 (TID 927) in 31030 ms on 192.168.33.15 (executor 6) (48/104)
18/09/26 13:32:26 INFO TaskSetManager: Starting task 94.0 in stage 0.1 (TID 977, 192.168.33.15, executor 6, partition 352, ANY, 4879 bytes)
18/09/26 13:32:26 INFO TaskSetManager: Finished task 42.0 in stage 0.1 (TID 925) in 31457 ms on 192.168.33.15 (executor 6) (49/104)
18/09/26 13:32:27 INFO TaskSetManager: Starting task 95.0 in stage 0.1 (TID 978, 192.168.33.14, executor 4, partition 357, ANY, 4879 bytes)
18/09/26 13:32:27 WARN TaskSetManager: Lost task 308.1 in stage 1.0 (TID 839, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=308, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:27 INFO TaskSetManager: Task 308.1 in stage 1.0 (TID 839) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:27 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:27 INFO TaskSetManager: Starting task 96.0 in stage 0.1 (TID 979, 192.168.33.15, executor 6, partition 380, ANY, 4879 bytes)
18/09/26 13:32:27 INFO TaskSetManager: Finished task 38.0 in stage 0.1 (TID 921) in 32595 ms on 192.168.33.15 (executor 6) (50/104)
18/09/26 13:32:27 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:27 INFO TaskSetManager: Starting task 97.0 in stage 0.1 (TID 980, 192.168.33.14, executor 4, partition 386, ANY, 4879 bytes)
18/09/26 13:32:27 INFO TaskSetManager: Finished task 57.0 in stage 0.1 (TID 940) in 21205 ms on 192.168.33.14 (executor 4) (51/104)
18/09/26 13:32:27 INFO TaskSetManager: Starting task 98.0 in stage 0.1 (TID 981, 192.168.33.15, executor 6, partition 387, ANY, 4879 bytes)
18/09/26 13:32:27 INFO TaskSetManager: Finished task 41.0 in stage 0.1 (TID 924) in 32220 ms on 192.168.33.15 (executor 6) (52/104)
18/09/26 13:32:27 INFO TaskSetManager: Starting task 99.0 in stage 0.1 (TID 982, 192.168.33.15, executor 6, partition 390, ANY, 4879 bytes)
18/09/26 13:32:27 INFO TaskSetManager: Finished task 49.0 in stage 0.1 (TID 932) in 31158 ms on 192.168.33.15 (executor 6) (53/104)
18/09/26 13:32:27 INFO TaskSetManager: Starting task 100.0 in stage 0.1 (TID 983, 192.168.33.15, executor 6, partition 391, ANY, 4879 bytes)
18/09/26 13:32:27 INFO TaskSetManager: Finished task 36.0 in stage 0.1 (TID 919) in 33554 ms on 192.168.33.15 (executor 6) (54/104)
18/09/26 13:32:28 INFO TaskSetManager: Starting task 101.0 in stage 0.1 (TID 984, 192.168.33.15, executor 6, partition 394, ANY, 4879 bytes)
18/09/26 13:32:28 INFO TaskSetManager: Finished task 39.0 in stage 0.1 (TID 922) in 33003 ms on 192.168.33.15 (executor 6) (55/104)
18/09/26 13:32:28 INFO TaskSetManager: Starting task 102.0 in stage 0.1 (TID 985, 192.168.33.11, executor 5, partition 400, ANY, 4879 bytes)
18/09/26 13:32:28 INFO TaskSetManager: Finished task 52.0 in stage 0.1 (TID 935) in 28492 ms on 192.168.33.11 (executor 5) (56/104)
18/09/26 13:32:28 INFO TaskSetManager: Starting task 103.0 in stage 0.1 (TID 986, 192.168.33.13, executor 2, partition 408, ANY, 4879 bytes)
18/09/26 13:32:28 INFO TaskSetManager: Finished task 60.0 in stage 0.1 (TID 943) in 19437 ms on 192.168.33.13 (executor 2) (57/104)
18/09/26 13:32:28 INFO TaskSetManager: Finished task 58.0 in stage 0.1 (TID 941) in 22726 ms on 192.168.33.13 (executor 2) (58/104)
18/09/26 13:32:29 INFO TaskSetManager: Finished task 61.0 in stage 0.1 (TID 944) in 19010 ms on 192.168.33.11 (executor 5) (59/104)
18/09/26 13:32:29 INFO TaskSetManager: Finished task 43.0 in stage 0.1 (TID 926) in 33454 ms on 192.168.33.15 (executor 6) (60/104)
18/09/26 13:32:29 INFO TaskSetManager: Finished task 51.0 in stage 0.1 (TID 934) in 30899 ms on 192.168.33.15 (executor 6) (61/104)
18/09/26 13:32:29 INFO TaskSetManager: Finished task 59.0 in stage 0.1 (TID 942) in 20656 ms on 192.168.33.14 (executor 4) (62/104)
18/09/26 13:32:29 INFO TaskSetManager: Finished task 62.0 in stage 0.1 (TID 945) in 18304 ms on 192.168.33.11 (executor 5) (63/104)
18/09/26 13:32:31 WARN TaskSetManager: Lost task 7.1 in stage 1.0 (TID 846, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:32:31 INFO TaskSetManager: Task 7.1 in stage 1.0 (TID 846) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:32:31 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 13:32:31 INFO DAGScheduler: Resubmitting failed stages
18/09/26 13:32:31 INFO TaskSetManager: Finished task 63.0 in stage 0.1 (TID 946) in 20156 ms on 192.168.33.11 (executor 5) (64/104)
18/09/26 13:32:31 INFO TaskSetManager: Finished task 66.0 in stage 0.1 (TID 949) in 16202 ms on 192.168.33.11 (executor 5) (65/104)
18/09/26 13:32:32 INFO TaskSetManager: Finished task 64.0 in stage 0.1 (TID 947) in 18659 ms on 192.168.33.14 (executor 4) (66/104)
18/09/26 13:32:33 INFO TaskSetManager: Finished task 65.0 in stage 0.1 (TID 948) in 19002 ms on 192.168.33.14 (executor 4) (67/104)
18/09/26 13:32:34 INFO TaskSetManager: Finished task 68.0 in stage 0.1 (TID 951) in 16226 ms on 192.168.33.13 (executor 2) (68/104)
18/09/26 13:32:34 INFO TaskSetManager: Finished task 67.0 in stage 0.1 (TID 950) in 17533 ms on 192.168.33.13 (executor 2) (69/104)
18/09/26 13:32:36 INFO TaskSetManager: Finished task 71.0 in stage 0.1 (TID 954) in 16806 ms on 192.168.33.11 (executor 5) (70/104)
18/09/26 13:32:36 INFO TaskSetManager: Finished task 69.0 in stage 0.1 (TID 952) in 17671 ms on 192.168.33.13 (executor 2) (71/104)
18/09/26 13:32:37 INFO TaskSetManager: Finished task 70.0 in stage 0.1 (TID 953) in 17941 ms on 192.168.33.13 (executor 2) (72/104)
18/09/26 13:32:37 INFO TaskSetManager: Finished task 76.0 in stage 0.1 (TID 959) in 13937 ms on 192.168.33.11 (executor 5) (73/104)
18/09/26 13:32:39 INFO TaskSetManager: Finished task 77.0 in stage 0.1 (TID 960) in 15885 ms on 192.168.33.13 (executor 2) (74/104)
18/09/26 13:32:40 INFO TaskSetManager: Finished task 87.0 in stage 0.1 (TID 970) in 14320 ms on 192.168.33.13 (executor 2) (75/104)
18/09/26 13:32:40 INFO TaskSetManager: Finished task 82.0 in stage 0.1 (TID 965) in 15518 ms on 192.168.33.14 (executor 4) (76/104)
18/09/26 13:32:40 INFO TaskSetManager: Finished task 83.0 in stage 0.1 (TID 966) in 15704 ms on 192.168.33.14 (executor 4) (77/104)
18/09/26 13:32:41 INFO TaskSetManager: Finished task 102.0 in stage 0.1 (TID 985) in 12892 ms on 192.168.33.11 (executor 5) (78/104)
18/09/26 13:32:42 INFO TaskSetManager: Finished task 103.0 in stage 0.1 (TID 986) in 14224 ms on 192.168.33.13 (executor 2) (79/104)
18/09/26 13:32:43 INFO TaskSetManager: Finished task 95.0 in stage 0.1 (TID 978) in 16122 ms on 192.168.33.14 (executor 4) (80/104)
18/09/26 13:32:43 INFO TaskSetManager: Finished task 97.0 in stage 0.1 (TID 980) in 16065 ms on 192.168.33.14 (executor 4) (81/104)
18/09/26 13:32:43 INFO TaskSetManager: Finished task 91.0 in stage 0.1 (TID 974) in 17012 ms on 192.168.33.14 (executor 4) (82/104)
18/09/26 13:32:44 INFO TaskSetManager: Finished task 73.0 in stage 0.1 (TID 956) in 22446 ms on 192.168.33.15 (executor 6) (83/104)
18/09/26 13:32:46 INFO TaskSetManager: Finished task 72.0 in stage 0.1 (TID 955) in 26695 ms on 192.168.33.15 (executor 6) (84/104)
18/09/26 13:32:47 INFO TaskSetManager: Finished task 74.0 in stage 0.1 (TID 957) in 24881 ms on 192.168.33.15 (executor 6) (85/104)
18/09/26 13:32:49 INFO TaskSetManager: Finished task 99.0 in stage 0.1 (TID 982) in 21630 ms on 192.168.33.15 (executor 6) (86/104)
18/09/26 13:32:49 INFO TaskSetManager: Finished task 79.0 in stage 0.1 (TID 962) in 25551 ms on 192.168.33.15 (executor 6) (87/104)
18/09/26 13:32:49 INFO TaskSetManager: Finished task 89.0 in stage 0.1 (TID 972) in 23369 ms on 192.168.33.15 (executor 6) (88/104)
18/09/26 13:32:49 INFO TaskSetManager: Finished task 78.0 in stage 0.1 (TID 961) in 26017 ms on 192.168.33.15 (executor 6) (89/104)
18/09/26 13:32:49 INFO TaskSetManager: Finished task 90.0 in stage 0.1 (TID 973) in 23328 ms on 192.168.33.15 (executor 6) (90/104)
18/09/26 13:32:50 INFO TaskSetManager: Finished task 86.0 in stage 0.1 (TID 969) in 24609 ms on 192.168.33.15 (executor 6) (91/104)
18/09/26 13:32:50 INFO TaskSetManager: Finished task 81.0 in stage 0.1 (TID 964) in 26136 ms on 192.168.33.15 (executor 6) (92/104)
18/09/26 13:32:51 INFO TaskSetManager: Finished task 100.0 in stage 0.1 (TID 983) in 23516 ms on 192.168.33.15 (executor 6) (93/104)
18/09/26 13:32:51 INFO TaskSetManager: Finished task 80.0 in stage 0.1 (TID 963) in 26850 ms on 192.168.33.15 (executor 6) (94/104)
18/09/26 13:32:51 INFO TaskSetManager: Finished task 93.0 in stage 0.1 (TID 976) in 24959 ms on 192.168.33.15 (executor 6) (95/104)
18/09/26 13:32:51 INFO TaskSetManager: Finished task 75.0 in stage 0.1 (TID 958) in 28991 ms on 192.168.33.15 (executor 6) (96/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 101.0 in stage 0.1 (TID 984) in 24027 ms on 192.168.33.15 (executor 6) (97/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 85.0 in stage 0.1 (TID 968) in 26565 ms on 192.168.33.15 (executor 6) (98/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 84.0 in stage 0.1 (TID 967) in 26879 ms on 192.168.33.15 (executor 6) (99/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 92.0 in stage 0.1 (TID 975) in 25704 ms on 192.168.33.15 (executor 6) (100/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 88.0 in stage 0.1 (TID 971) in 26321 ms on 192.168.33.15 (executor 6) (101/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 94.0 in stage 0.1 (TID 977) in 25688 ms on 192.168.33.15 (executor 6) (102/104)
18/09/26 13:32:52 INFO TaskSetManager: Finished task 98.0 in stage 0.1 (TID 981) in 25211 ms on 192.168.33.15 (executor 6) (103/104)
18/09/26 13:32:53 INFO TaskSetManager: Finished task 96.0 in stage 0.1 (TID 979) in 25895 ms on 192.168.33.15 (executor 6) (104/104)
18/09/26 13:32:53 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 93,255 s
18/09/26 13:32:53 INFO DAGScheduler: looking for newly runnable stages
18/09/26 13:32:53 INFO DAGScheduler: running: Set()
18/09/26 13:32:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 13:32:53 INFO DAGScheduler: failed: Set()
18/09/26 13:32:53 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/26 13:32:53 INFO TaskSchedulerImpl: Removed TaskSet 0.1, whose tasks have all completed, from pool 
18/09/26 13:32:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/26 13:32:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1836.0 B, free 365.9 MB)
18/09/26 13:32:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.10:43403 (size: 1836.0 B, free: 366.3 MB)
18/09/26 13:32:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/09/26 13:32:53 INFO DAGScheduler: Submitting 90 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 13:32:53 INFO TaskSchedulerImpl: Adding task set 1.1 with 90 tasks
18/09/26 13:32:53 INFO TaskSetManager: Starting task 0.0 in stage 1.1 (TID 987, 192.168.33.11, executor 5, partition 0, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 1.0 in stage 1.1 (TID 988, 192.168.33.14, executor 4, partition 1, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 2.0 in stage 1.1 (TID 989, 192.168.33.15, executor 6, partition 2, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 3.0 in stage 1.1 (TID 990, 192.168.33.13, executor 2, partition 3, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 4.0 in stage 1.1 (TID 991, 192.168.33.11, executor 5, partition 4, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 5.0 in stage 1.1 (TID 992, 192.168.33.14, executor 4, partition 5, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 6.0 in stage 1.1 (TID 993, 192.168.33.15, executor 6, partition 6, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 7.0 in stage 1.1 (TID 994, 192.168.33.13, executor 2, partition 7, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 8.0 in stage 1.1 (TID 995, 192.168.33.11, executor 5, partition 8, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 9.0 in stage 1.1 (TID 996, 192.168.33.14, executor 4, partition 9, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 10.0 in stage 1.1 (TID 997, 192.168.33.15, executor 6, partition 10, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 11.0 in stage 1.1 (TID 998, 192.168.33.13, executor 2, partition 11, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 12.0 in stage 1.1 (TID 999, 192.168.33.11, executor 5, partition 12, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 13.0 in stage 1.1 (TID 1000, 192.168.33.14, executor 4, partition 13, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 14.0 in stage 1.1 (TID 1001, 192.168.33.15, executor 6, partition 14, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 15.0 in stage 1.1 (TID 1002, 192.168.33.13, executor 2, partition 15, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 16.0 in stage 1.1 (TID 1003, 192.168.33.11, executor 5, partition 16, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 17.0 in stage 1.1 (TID 1004, 192.168.33.14, executor 4, partition 17, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 18.0 in stage 1.1 (TID 1005, 192.168.33.15, executor 6, partition 18, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 19.0 in stage 1.1 (TID 1006, 192.168.33.13, executor 2, partition 19, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 20.0 in stage 1.1 (TID 1007, 192.168.33.11, executor 5, partition 20, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 21.0 in stage 1.1 (TID 1008, 192.168.33.14, executor 4, partition 21, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 22.0 in stage 1.1 (TID 1009, 192.168.33.15, executor 6, partition 22, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 23.0 in stage 1.1 (TID 1010, 192.168.33.13, executor 2, partition 23, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 24.0 in stage 1.1 (TID 1011, 192.168.33.11, executor 5, partition 29, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 25.0 in stage 1.1 (TID 1012, 192.168.33.14, executor 4, partition 39, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 26.0 in stage 1.1 (TID 1013, 192.168.33.15, executor 6, partition 64, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 27.0 in stage 1.1 (TID 1014, 192.168.33.13, executor 2, partition 69, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 28.0 in stage 1.1 (TID 1015, 192.168.33.11, executor 5, partition 74, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 29.0 in stage 1.1 (TID 1016, 192.168.33.14, executor 4, partition 113, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 30.0 in stage 1.1 (TID 1017, 192.168.33.15, executor 6, partition 114, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 31.0 in stage 1.1 (TID 1018, 192.168.33.13, executor 2, partition 117, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 32.0 in stage 1.1 (TID 1019, 192.168.33.15, executor 6, partition 118, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 33.0 in stage 1.1 (TID 1020, 192.168.33.15, executor 6, partition 125, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 34.0 in stage 1.1 (TID 1021, 192.168.33.15, executor 6, partition 127, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 35.0 in stage 1.1 (TID 1022, 192.168.33.15, executor 6, partition 128, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 36.0 in stage 1.1 (TID 1023, 192.168.33.15, executor 6, partition 133, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 37.0 in stage 1.1 (TID 1024, 192.168.33.15, executor 6, partition 138, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 38.0 in stage 1.1 (TID 1025, 192.168.33.15, executor 6, partition 150, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 39.0 in stage 1.1 (TID 1026, 192.168.33.15, executor 6, partition 153, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 40.0 in stage 1.1 (TID 1027, 192.168.33.15, executor 6, partition 154, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 41.0 in stage 1.1 (TID 1028, 192.168.33.15, executor 6, partition 155, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 42.0 in stage 1.1 (TID 1029, 192.168.33.15, executor 6, partition 159, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 43.0 in stage 1.1 (TID 1030, 192.168.33.15, executor 6, partition 168, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 44.0 in stage 1.1 (TID 1031, 192.168.33.15, executor 6, partition 169, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 45.0 in stage 1.1 (TID 1032, 192.168.33.15, executor 6, partition 170, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 46.0 in stage 1.1 (TID 1033, 192.168.33.15, executor 6, partition 172, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO TaskSetManager: Starting task 47.0 in stage 1.1 (TID 1034, 192.168.33.15, executor 6, partition 185, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:32:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.13:33570 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:32:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.14:34961 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:32:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.15:41164 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:32:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.14:34961 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:32:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:37206
18/09/26 13:32:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.15:57102
18/09/26 13:32:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.13:33570 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:32:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.13:43042
18/09/26 13:32:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.11:38333 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:32:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.15:41164 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 13:32:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.10:43403 in memory (size: 2.5 KB, free: 366.3 MB)
18/09/26 13:32:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 92502 bytes
18/09/26 13:32:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.11:38333 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:32:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.11:43502
18/09/26 13:33:45 INFO TaskSetManager: Starting task 48.0 in stage 1.1 (TID 1035, 192.168.33.12, executor 3, partition 197, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:33:45 WARN TaskSetManager: Lost task 249.1 in stage 1.0 (TID 849, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=249, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:33:45 INFO TaskSetManager: Task 249.1 in stage 1.0 (TID 849) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:33:45 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 249) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:33:51 INFO TaskSetManager: Starting task 49.0 in stage 1.1 (TID 1036, 192.168.33.12, executor 3, partition 203, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:33:51 WARN TaskSetManager: Lost task 268.1 in stage 1.0 (TID 831, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=302, reduceId=268, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:33:51 INFO TaskSetManager: Task 268.1 in stage 1.0 (TID 831) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:33:51 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 268) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:01 INFO TaskSetManager: Starting task 50.0 in stage 1.1 (TID 1037, 192.168.33.12, executor 3, partition 204, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:01 WARN TaskSetManager: Lost task 1.1 in stage 1.0 (TID 853, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=242, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:01 INFO TaskSetManager: Task 1.1 in stage 1.0 (TID 853) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:01 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 1) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:04 INFO TaskSetManager: Starting task 51.0 in stage 1.1 (TID 1038, 192.168.33.12, executor 3, partition 206, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:04 WARN TaskSetManager: Lost task 234.1 in stage 1.0 (TID 845, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=234, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:04 INFO TaskSetManager: Task 234.1 in stage 1.0 (TID 845) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:04 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 234) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:05 INFO TaskSetManager: Starting task 52.0 in stage 1.1 (TID 1039, 192.168.33.12, executor 3, partition 208, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:05 WARN TaskSetManager: Lost task 312.1 in stage 1.0 (TID 821, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=297, reduceId=312, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:05 INFO TaskSetManager: Task 312.1 in stage 1.0 (TID 821) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:05 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 312) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:05 INFO TaskSetManager: Starting task 53.0 in stage 1.1 (TID 1040, 192.168.33.12, executor 3, partition 212, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:05 WARN TaskSetManager: Lost task 275.1 in stage 1.0 (TID 836, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=4, reduceId=275, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:05 INFO TaskSetManager: Task 275.1 in stage 1.0 (TID 836) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:05 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 275) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:06 INFO TaskSetManager: Starting task 54.0 in stage 1.1 (TID 1041, 192.168.33.12, executor 3, partition 218, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:06 WARN TaskSetManager: Lost task 297.1 in stage 1.0 (TID 826, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=302, reduceId=297, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:06 INFO TaskSetManager: Task 297.1 in stage 1.0 (TID 826) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:06 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 297) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:14 INFO TaskSetManager: Starting task 55.0 in stage 1.1 (TID 1042, 192.168.33.12, executor 3, partition 220, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:34:14 WARN TaskSetManager: Lost task 320.1 in stage 1.0 (TID 841, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(0, 192.168.33.15, 35408, None), shuffleId=5, mapId=313, reduceId=320, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.15:35408
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.15:35408
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 13:34:14 INFO TaskSetManager: Task 320.1 in stage 1.0 (TID 841) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 13:34:14 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 320) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 13:34:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.12:35074 (size: 1836.0 B, free: 15.8 GB)
18/09/26 13:34:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.12:37794
18/09/26 13:49:54 INFO TaskSetManager: Starting task 56.0 in stage 1.1 (TID 1043, 192.168.33.15, executor 6, partition 221, PROCESS_LOCAL, 4614 bytes)
18/09/26 13:49:54 INFO TaskSetManager: Finished task 47.0 in stage 1.1 (TID 1034) in 1021781 ms on 192.168.33.15 (executor 6) (1/90)
18/09/26 14:19:30 INFO TaskSetManager: Starting task 57.0 in stage 1.1 (TID 1044, 192.168.33.10, executor 1, partition 224, PROCESS_LOCAL, 4614 bytes)
18/09/26 14:19:30 WARN TaskSetManager: Lost task 29.0 in stage 1.0 (TID 438, 192.168.33.10, executor 1): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.reflect.Array.newInstance(Array.java:75)
	at scala.reflect.ClassTag$class.newArray(ClassTag.scala:61)
	at scala.reflect.ClassTag$$anon$1.newArray(ClassTag.scala:152)
	at scala.Array$.ofDim(Array.scala:218)
	at scala.collection.mutable.ArrayOps$class.$colon$plus(ArrayOps.scala:57)
	at scala.collection.mutable.ArrayOps$ofRef.$colon$plus(ArrayOps.scala:186)
	at david.sc_dbscan.objects.Partition$$anonfun$addNoeuds$1.apply$mcVI$sp(Partition.scala:12)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at david.sc_dbscan.objects.Partition.addNoeuds(Partition.scala:11)
	at david.sc_dbscan.process.Partitioning$$anonfun$3.apply(Partitioning.scala:81)
	at david.sc_dbscan.process.Partitioning$$anonfun$3.apply(Partitioning.scala:78)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 14:19:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.10:41196 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:19:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.10:37738
18/09/26 14:19:31 INFO TaskSetManager: Starting task 58.0 in stage 1.1 (TID 1045, 192.168.33.14, executor 4, partition 227, PROCESS_LOCAL, 4614 bytes)
18/09/26 14:19:31 WARN TaskSetManager: Lost task 9.0 in stage 1.1 (TID 996, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=344, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731713, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731713, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
18/09/26 14:19:31 INFO TaskSetManager: Task 9.0 in stage 1.1 (TID 996) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:19:31 INFO DAGScheduler: Marking ShuffleMapStage 1 (flatMap at Partitioning.scala:78) as failed due to a fetch failure from ShuffleMapStage 0 (flatMap at Partitioning.scala:52)
18/09/26 14:19:31 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) failed in 2798,310 s due to org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731713, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731713, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

18/09/26 14:19:31 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:19:31 INFO DAGScheduler: Executor lost: 1 (epoch 32)
18/09/26 14:19:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/09/26 14:19:31 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 192.168.33.10, 41196, None)
18/09/26 14:19:31 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
18/09/26 14:19:31 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 32)
18/09/26 14:19:31 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 1 (336/409, false)
18/09/26 14:19:31 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 1 (298/409, false)
18/09/26 14:19:31 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:19:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 14:19:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 365.9 MB)
18/09/26 14:19:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 14:19:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.10:43403 (size: 2.5 KB, free: 366.3 MB)
18/09/26 14:19:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/09/26 14:19:31 INFO DAGScheduler: Submitting 73 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(5, 11, 17, 23, 29, 35, 41, 47, 49, 51, 53, 55, 57, 59, 61))
18/09/26 14:19:31 INFO TaskSchedulerImpl: Adding task set 0.2 with 73 tasks
18/09/26 14:19:32 INFO TaskSetManager: Starting task 0.0 in stage 0.2 (TID 1046, 192.168.33.11, executor 5, partition 5, ANY, 4879 bytes)
18/09/26 14:19:32 WARN TaskSetManager: Lost task 12.0 in stage 1.1 (TID 999, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=344, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731694, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731694, chunkIndex=66}: java.io.FileNotFoundException: /data0/store/spark-local/spark-007804d7-e667-4ae2-ab79-6aaf298e4e9b/executor-b0fb3889-4686-4156-9890-929a22fe30ae/blockmgr-ffbc4094-3644-4c19-abe6-a591d80d14eb/2f/shuffle_5_344_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
18/09/26 14:19:32 INFO TaskSetManager: Task 12.0 in stage 1.1 (TID 999) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:19:32 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:19:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.11:38333 (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:19:32 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:19:44 INFO TaskSetManager: Starting task 1.0 in stage 0.2 (TID 1047, 192.168.33.11, executor 5, partition 11, ANY, 4879 bytes)
18/09/26 14:19:44 INFO TaskSetManager: Finished task 0.0 in stage 0.2 (TID 1046) in 12091 ms on 192.168.33.11 (executor 5) (1/73)
18/09/26 14:19:58 INFO TaskSetManager: Starting task 2.0 in stage 0.2 (TID 1048, 192.168.33.11, executor 5, partition 17, ANY, 4879 bytes)
18/09/26 14:19:58 INFO TaskSetManager: Finished task 1.0 in stage 0.2 (TID 1047) in 14449 ms on 192.168.33.11 (executor 5) (2/73)
18/09/26 14:20:14 INFO TaskSetManager: Starting task 3.0 in stage 0.2 (TID 1049, 192.168.33.11, executor 5, partition 23, ANY, 4879 bytes)
18/09/26 14:20:14 INFO TaskSetManager: Finished task 2.0 in stage 0.2 (TID 1048) in 15746 ms on 192.168.33.11 (executor 5) (3/73)
18/09/26 14:20:15 INFO TaskSetManager: Starting task 4.0 in stage 0.2 (TID 1050, 192.168.33.14, executor 4, partition 29, ANY, 4879 bytes)
18/09/26 14:20:15 WARN TaskSetManager: Lost task 58.0 in stage 1.1 (TID 1045, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=227, message=
org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731792, chunkIndex=0}: java.io.FileNotFoundException: /data2/store/spark-local/spark-65dd04bf-e319-46d3-9730-47839c98dcc3/executor-acb760c9-af60-4d2a-8d2e-dc66e4426c80/blockmgr-f8835bd4-d3f4-47d0-b32c-2e72268a91e0/37/shuffle_5_5_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731792, chunkIndex=0}: java.io.FileNotFoundException: /data2/store/spark-local/spark-65dd04bf-e319-46d3-9730-47839c98dcc3/executor-acb760c9-af60-4d2a-8d2e-dc66e4426c80/blockmgr-f8835bd4-d3f4-47d0-b32c-2e72268a91e0/37/shuffle_5_5_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
18/09/26 14:20:15 INFO TaskSetManager: Task 58.0 in stage 1.1 (TID 1045) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:15 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:20:15 INFO TaskSetManager: Starting task 5.0 in stage 0.2 (TID 1051, 192.168.33.15, executor 6, partition 35, ANY, 4879 bytes)
18/09/26 14:20:15 WARN TaskSetManager: Lost task 42.0 in stage 1.1 (TID 1029, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=325, reduceId=159, message=
org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731740, chunkIndex=0}: java.io.FileNotFoundException: /data5/store/spark-local/spark-ef1b33f6-c821-4994-a5d5-0ef2e467e99b/executor-385d141e-e792-4eec-a138-7e283a1f38c7/blockmgr-6dfdf4c6-6f92-420b-bb3d-97bfc1e9d73d/38/shuffle_5_325_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731740, chunkIndex=0}: java.io.FileNotFoundException: /data5/store/spark-local/spark-ef1b33f6-c821-4994-a5d5-0ef2e467e99b/executor-385d141e-e792-4eec-a138-7e283a1f38c7/blockmgr-6dfdf4c6-6f92-420b-bb3d-97bfc1e9d73d/38/shuffle_5_325_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
18/09/26 14:20:15 INFO TaskSetManager: Task 42.0 in stage 1.1 (TID 1029) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.15:41164 (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:20:15 INFO TaskSetManager: Starting task 6.0 in stage 0.2 (TID 1052, 192.168.33.13, executor 2, partition 41, ANY, 4879 bytes)
18/09/26 14:20:15 WARN TaskSetManager: Lost task 3.0 in stage 1.1 (TID 990, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId{streamId=231558731741, chunkIndex=0}: java.io.FileNotFoundException: /data2/store/spark-local/spark-65dd04bf-e319-46d3-9730-47839c98dcc3/executor-acb760c9-af60-4d2a-8d2e-dc66e4426c80/blockmgr-f8835bd4-d3f4-47d0-b32c-2e72268a91e0/37/shuffle_5_5_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId{streamId=231558731741, chunkIndex=0}: java.io.FileNotFoundException: /data2/store/spark-local/spark-65dd04bf-e319-46d3-9730-47839c98dcc3/executor-acb760c9-af60-4d2a-8d2e-dc66e4426c80/blockmgr-f8835bd4-d3f4-47d0-b32c-2e72268a91e0/37/shuffle_5_5_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:199)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:351)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:61)
	at org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1.apply(NettyBlockRpcServer.scala:60)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)
	at org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:125)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more

)
18/09/26 14:20:15 INFO TaskSetManager: Task 3.0 in stage 1.1 (TID 990) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:15 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:41196 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 41196, None)
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.13:33570 (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.14:34961 (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:41196 (size: 27.9 KB, free: 15.8 GB)
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.10:41196 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:20:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.10:41196 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:20:15 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:20:15 INFO TaskSetManager: Starting task 7.0 in stage 0.2 (TID 1053, 192.168.33.10, executor 1, partition 47, ANY, 4879 bytes)
18/09/26 14:20:15 WARN TaskSetManager: Lost task 300.2 in stage 1.0 (TID 833, 192.168.33.10, executor 1): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=23, reduceId=300, message=
org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/data6/store/spark-local/spark-b35d1744-7b27-4cef-888d-5e28b37cdae2/executor-bd1a2dac-98b6-415d-ab87-d10ba35c0438/blockmgr-ba32ffd7-52de-43f0-8296-fd4c412edfb0/12/shuffle_5_23_0.data, offset=43128853, length=69856}
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:408)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/data6/store/spark-local/spark-b35d1744-7b27-4cef-888d-5e28b37cdae2/executor-bd1a2dac-98b6-415d-ab87-d10ba35c0438/blockmgr-ba32ffd7-52de-43f0-8296-fd4c412edfb0/12/shuffle_5_23_0.data, offset=43128853, length=69856}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:113)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:401)
	... 22 more
Caused by: java.io.FileNotFoundException: /data6/store/spark-local/spark-b35d1744-7b27-4cef-888d-5e28b37cdae2/executor-bd1a2dac-98b6-415d-ab87-d10ba35c0438/blockmgr-ba32ffd7-52de-43f0-8296-fd4c412edfb0/12/shuffle_5_23_0.data (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:98)
	... 23 more

)
18/09/26 14:20:15 INFO TaskSetManager: Task 300.2 in stage 1.0 (TID 833) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:15 INFO DAGScheduler: Ignoring fetch failure from ShuffleMapTask(1, 300) as it's from ShuffleMapStage 1 attempt 0 and there is a more recent attempt for that stage (attempt ID 1) running
18/09/26 14:20:19 ERROR TaskSchedulerImpl: Lost executor 1 on 192.168.33.10: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 159.0 in stage 1.0 (TID 568, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 253.1 in stage 1.0 (TID 828, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 69.0 in stage 1.0 (TID 478, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 168.0 in stage 1.0 (TID 577, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 236.0 in stage 1.0 (TID 645, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 245.0 in stage 1.0 (TID 654, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 39.0 in stage 1.0 (TID 448, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 206.0 in stage 1.0 (TID 615, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 170.0 in stage 1.0 (TID 579, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 74.0 in stage 1.0 (TID 483, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 155.0 in stage 1.0 (TID 564, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 154.0 in stage 1.0 (TID 563, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 235.0 in stage 1.0 (TID 644, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 172.0 in stage 1.0 (TID 581, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 247.0 in stage 1.0 (TID 656, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 169.0 in stage 1.0 (TID 578, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 133.0 in stage 1.0 (TID 542, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 230.1 in stage 1.0 (TID 838, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 64.0 in stage 1.0 (TID 473, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 267.1 in stage 1.0 (TID 823, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 204.0 in stage 1.0 (TID 613, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 153.0 in stage 1.0 (TID 562, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/09/26 14:20:19 WARN TaskSetManager: Lost task 57.0 in stage 1.1 (TID 1044, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 WARN TaskSetManager: Lost task 7.0 in stage 0.2 (TID 1053, 192.168.33.10, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 14:20:19 INFO DAGScheduler: Executor lost: 1 (epoch 43)
18/09/26 14:20:19 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/09/26 14:20:19 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 192.168.33.10, 41196, None)
18/09/26 14:20:19 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
18/09/26 14:20:19 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 43)
18/09/26 14:20:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/1 is now EXITED (Command exited with code 52)
18/09/26 14:20:19 INFO StandaloneSchedulerBackend: Executor app-20180926111330-0006/1 removed: Command exited with code 52
18/09/26 14:20:19 INFO BlockManagerMaster: Removal of executor 1 requested
18/09/26 14:20:19 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
18/09/26 14:20:19 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
18/09/26 14:20:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/7 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 14:20:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/7 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 14:20:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/7 is now RUNNING
18/09/26 14:20:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:41482) with ID 7
18/09/26 14:20:22 INFO TaskSetManager: Starting task 7.1 in stage 0.2 (TID 1054, 192.168.33.10, executor 7, partition 47, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 8.0 in stage 0.2 (TID 1055, 192.168.33.10, executor 7, partition 49, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 9.0 in stage 0.2 (TID 1056, 192.168.33.10, executor 7, partition 51, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 10.0 in stage 0.2 (TID 1057, 192.168.33.10, executor 7, partition 53, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 11.0 in stage 0.2 (TID 1058, 192.168.33.10, executor 7, partition 55, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 12.0 in stage 0.2 (TID 1059, 192.168.33.10, executor 7, partition 57, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 13.0 in stage 0.2 (TID 1060, 192.168.33.10, executor 7, partition 59, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 14.0 in stage 0.2 (TID 1061, 192.168.33.10, executor 7, partition 61, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 15.0 in stage 0.2 (TID 1062, 192.168.33.10, executor 7, partition 63, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 16.0 in stage 0.2 (TID 1063, 192.168.33.10, executor 7, partition 65, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 17.0 in stage 0.2 (TID 1064, 192.168.33.10, executor 7, partition 67, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 18.0 in stage 0.2 (TID 1065, 192.168.33.10, executor 7, partition 69, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 19.0 in stage 0.2 (TID 1066, 192.168.33.10, executor 7, partition 71, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 20.0 in stage 0.2 (TID 1067, 192.168.33.10, executor 7, partition 73, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 21.0 in stage 0.2 (TID 1068, 192.168.33.10, executor 7, partition 75, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 22.0 in stage 0.2 (TID 1069, 192.168.33.10, executor 7, partition 77, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 23.0 in stage 0.2 (TID 1070, 192.168.33.10, executor 7, partition 79, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 24.0 in stage 0.2 (TID 1071, 192.168.33.10, executor 7, partition 157, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 25.0 in stage 0.2 (TID 1072, 192.168.33.10, executor 7, partition 168, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 26.0 in stage 0.2 (TID 1073, 192.168.33.10, executor 7, partition 169, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 27.0 in stage 0.2 (TID 1074, 192.168.33.10, executor 7, partition 171, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 28.0 in stage 0.2 (TID 1075, 192.168.33.10, executor 7, partition 172, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 29.0 in stage 0.2 (TID 1076, 192.168.33.10, executor 7, partition 173, ANY, 4879 bytes)
18/09/26 14:20:22 INFO TaskSetManager: Starting task 30.0 in stage 0.2 (TID 1077, 192.168.33.10, executor 7, partition 174, ANY, 4879 bytes)
18/09/26 14:20:22 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:38790 with 15.8 GB RAM, BlockManagerId(7, 192.168.33.10, 38790, None)
18/09/26 14:20:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.10:38790 (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:20:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:38790 (size: 27.9 KB, free: 15.8 GB)
18/09/26 14:20:25 INFO TaskSetManager: Starting task 31.0 in stage 0.2 (TID 1078, 192.168.33.15, executor 6, partition 175, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 32.0 in stage 1.1 (TID 1019, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=191, reduceId=118, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 32.0 in stage 1.1 (TID 1019) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:20:25 INFO TaskSetManager: Starting task 32.0 in stage 0.2 (TID 1079, 192.168.33.15, executor 6, partition 176, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 46.0 in stage 1.1 (TID 1033, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=183, reduceId=172, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 46.0 in stage 1.1 (TID 1033) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 33.0 in stage 0.2 (TID 1080, 192.168.33.15, executor 6, partition 177, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 36.0 in stage 1.1 (TID 1023, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=191, reduceId=133, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 36.0 in stage 1.1 (TID 1023) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 34.0 in stage 0.2 (TID 1081, 192.168.33.15, executor 6, partition 178, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 43.0 in stage 1.1 (TID 1030, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=344, reduceId=168, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 43.0 in stage 1.1 (TID 1030) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 35.0 in stage 0.2 (TID 1082, 192.168.33.15, executor 6, partition 179, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 40.0 in stage 1.1 (TID 1027, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=351, reduceId=154, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 40.0 in stage 1.1 (TID 1027) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 36.0 in stage 0.2 (TID 1083, 192.168.33.15, executor 6, partition 180, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 56.0 in stage 1.1 (TID 1043, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=321, reduceId=221, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 56.0 in stage 1.1 (TID 1043) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 37.0 in stage 0.2 (TID 1084, 192.168.33.15, executor 6, partition 181, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 26.0 in stage 1.1 (TID 1013, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=345, reduceId=64, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 26.0 in stage 1.1 (TID 1013) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 38.0 in stage 0.2 (TID 1085, 192.168.33.15, executor 6, partition 182, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 2.0 in stage 1.1 (TID 989, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 2.0 in stage 1.1 (TID 989) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 39.0 in stage 0.2 (TID 1086, 192.168.33.15, executor 6, partition 183, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 10.0 in stage 1.1 (TID 997, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=10, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 10.0 in stage 1.1 (TID 997) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 40.0 in stage 0.2 (TID 1087, 192.168.33.15, executor 6, partition 184, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 18.0 in stage 1.1 (TID 1005, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=18, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 18.0 in stage 1.1 (TID 1005) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 41.0 in stage 0.2 (TID 1088, 192.168.33.15, executor 6, partition 185, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 30.0 in stage 1.1 (TID 1017, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=114, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 30.0 in stage 1.1 (TID 1017) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 42.0 in stage 0.2 (TID 1089, 192.168.33.15, executor 6, partition 186, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 22.0 in stage 1.1 (TID 1009, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=198, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 22.0 in stage 1.1 (TID 1009) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 43.0 in stage 0.2 (TID 1090, 192.168.33.15, executor 6, partition 187, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 14.0 in stage 1.1 (TID 1001, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=314, reduceId=14, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 14.0 in stage 1.1 (TID 1001) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 44.0 in stage 0.2 (TID 1091, 192.168.33.14, executor 4, partition 189, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 5.0 in stage 1.1 (TID 992, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 5.0 in stage 1.1 (TID 992) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 45.0 in stage 0.2 (TID 1092, 192.168.33.14, executor 4, partition 191, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 25.0 in stage 1.1 (TID 1012, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=39, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 25.0 in stage 1.1 (TID 1012) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 46.0 in stage 0.2 (TID 1093, 192.168.33.14, executor 4, partition 197, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 21.0 in stage 1.1 (TID 1008, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=21, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 21.0 in stage 1.1 (TID 1008) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 47.0 in stage 0.2 (TID 1094, 192.168.33.15, executor 6, partition 198, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 34.0 in stage 1.1 (TID 1021, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=127, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 34.0 in stage 1.1 (TID 1021) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 48.0 in stage 0.2 (TID 1095, 192.168.33.14, executor 4, partition 265, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 29.0 in stage 1.1 (TID 1016, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=318, reduceId=113, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 29.0 in stage 1.1 (TID 1016) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 49.0 in stage 0.2 (TID 1096, 192.168.33.15, executor 6, partition 295, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 33.0 in stage 1.1 (TID 1020, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=125, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 33.0 in stage 1.1 (TID 1020) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 50.0 in stage 0.2 (TID 1097, 192.168.33.15, executor 6, partition 299, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 38.0 in stage 1.1 (TID 1025, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=150, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 38.0 in stage 1.1 (TID 1025) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 51.0 in stage 0.2 (TID 1098, 192.168.33.15, executor 6, partition 307, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 39.0 in stage 1.1 (TID 1026, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=153, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 39.0 in stage 1.1 (TID 1026) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 52.0 in stage 0.2 (TID 1099, 192.168.33.14, executor 4, partition 314, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 1.0 in stage 1.1 (TID 988, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 1.0 in stage 1.1 (TID 988) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 53.0 in stage 0.2 (TID 1100, 192.168.33.15, executor 6, partition 315, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 44.0 in stage 1.1 (TID 1031, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=169, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 44.0 in stage 1.1 (TID 1031) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 54.0 in stage 0.2 (TID 1101, 192.168.33.14, executor 4, partition 317, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 17.0 in stage 1.1 (TID 1004, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=17, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 17.0 in stage 1.1 (TID 1004) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 55.0 in stage 0.2 (TID 1102, 192.168.33.14, executor 4, partition 318, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 13.0 in stage 1.1 (TID 1000, 192.168.33.14, executor 4): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 13.0 in stage 1.1 (TID 1000) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 56.0 in stage 0.2 (TID 1103, 192.168.33.15, executor 6, partition 320, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 37.0 in stage 1.1 (TID 1024, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=138, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 37.0 in stage 1.1 (TID 1024) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 57.0 in stage 0.2 (TID 1104, 192.168.33.15, executor 6, partition 321, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 6.0 in stage 1.1 (TID 993, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 6.0 in stage 1.1 (TID 993) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 58.0 in stage 0.2 (TID 1105, 192.168.33.15, executor 6, partition 325, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 35.0 in stage 1.1 (TID 1022, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=332, reduceId=128, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 35.0 in stage 1.1 (TID 1022) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 59.0 in stage 0.2 (TID 1106, 192.168.33.15, executor 6, partition 327, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 41.0 in stage 1.1 (TID 1028, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=320, reduceId=155, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 41.0 in stage 1.1 (TID 1028) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO TaskSetManager: Starting task 60.0 in stage 0.2 (TID 1107, 192.168.33.15, executor 6, partition 328, ANY, 4879 bytes)
18/09/26 14:20:25 WARN TaskSetManager: Lost task 45.0 in stage 1.1 (TID 1032, 192.168.33.15, executor 6): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=320, reduceId=170, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:25 INFO TaskSetManager: Task 45.0 in stage 1.1 (TID 1032) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:25 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:20:26 INFO TaskSetManager: Starting task 61.0 in stage 0.2 (TID 1108, 192.168.33.14, executor 4, partition 330, ANY, 4879 bytes)
18/09/26 14:20:26 INFO TaskSetManager: Finished task 4.0 in stage 0.2 (TID 1050) in 11273 ms on 192.168.33.14 (executor 4) (4/73)
18/09/26 14:20:26 INFO TaskSetManager: Starting task 62.0 in stage 0.2 (TID 1109, 192.168.33.11, executor 5, partition 332, ANY, 4879 bytes)
18/09/26 14:20:26 INFO TaskSetManager: Finished task 3.0 in stage 0.2 (TID 1049) in 12478 ms on 192.168.33.11 (executor 5) (5/73)
18/09/26 14:20:27 INFO TaskSetManager: Starting task 63.0 in stage 0.2 (TID 1110, 192.168.33.13, executor 2, partition 334, ANY, 4879 bytes)
18/09/26 14:20:27 INFO TaskSetManager: Starting task 64.0 in stage 0.2 (TID 1111, 192.168.33.13, executor 2, partition 340, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 23.0 in stage 1.1 (TID 1010, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=320, reduceId=23, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 23.0 in stage 1.1 (TID 1010) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 WARN TaskSetManager: Lost task 31.0 in stage 1.1 (TID 1018, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=117, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 31.0 in stage 1.1 (TID 1018) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:20:27 INFO TaskSetManager: Starting task 65.0 in stage 0.2 (TID 1112, 192.168.33.13, executor 2, partition 343, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 27.0 in stage 1.1 (TID 1014, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=69, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 27.0 in stage 1.1 (TID 1014) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO TaskSetManager: Starting task 66.0 in stage 0.2 (TID 1113, 192.168.33.13, executor 2, partition 344, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 15.0 in stage 1.1 (TID 1002, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=15, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 15.0 in stage 1.1 (TID 1002) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO TaskSetManager: Starting task 67.0 in stage 0.2 (TID 1114, 192.168.33.13, executor 2, partition 345, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 7.0 in stage 1.1 (TID 994, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 7.0 in stage 1.1 (TID 994) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO TaskSetManager: Starting task 68.0 in stage 0.2 (TID 1115, 192.168.33.13, executor 2, partition 347, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 11.0 in stage 1.1 (TID 998, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=11, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 11.0 in stage 1.1 (TID 998) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO TaskSetManager: Starting task 69.0 in stage 0.2 (TID 1116, 192.168.33.13, executor 2, partition 349, ANY, 4879 bytes)
18/09/26 14:20:27 WARN TaskSetManager: Lost task 19.0 in stage 1.1 (TID 1006, 192.168.33.13, executor 2): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:27 INFO TaskSetManager: Task 19.0 in stage 1.1 (TID 1006) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:27 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:20:29 INFO TaskSetManager: Starting task 70.0 in stage 0.2 (TID 1117, 192.168.33.11, executor 5, partition 351, ANY, 4879 bytes)
18/09/26 14:20:29 WARN TaskSetManager: Lost task 8.0 in stage 1.1 (TID 995, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 8.0 in stage 1.1 (TID 995) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:20:29 INFO TaskSetManager: Starting task 71.0 in stage 0.2 (TID 1118, 192.168.33.11, executor 5, partition 356, ANY, 4879 bytes)
18/09/26 14:20:29 WARN TaskSetManager: Lost task 16.0 in stage 1.1 (TID 1003, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 16.0 in stage 1.1 (TID 1003) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 INFO TaskSetManager: Starting task 72.0 in stage 0.2 (TID 1119, 192.168.33.11, executor 5, partition 367, ANY, 4879 bytes)
18/09/26 14:20:29 WARN TaskSetManager: Lost task 4.0 in stage 1.1 (TID 991, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 4.0 in stage 1.1 (TID 991) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 20.0 in stage 1.1 (TID 1007, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=20, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 20.0 in stage 1.1 (TID 1007) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 0.0 in stage 1.1 (TID 987, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 0.0 in stage 1.1 (TID 987) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 24.0 in stage 1.1 (TID 1011, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=344, reduceId=29, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 24.0 in stage 1.1 (TID 1011) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 28.0 in stage 1.1 (TID 1015, 192.168.33.11, executor 5): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=74, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 28.0 in stage 1.1 (TID 1015) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 54.0 in stage 1.1 (TID 1041, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=332, reduceId=218, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 54.0 in stage 1.1 (TID 1041) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:20:29 WARN TaskSetManager: Lost task 52.0 in stage 1.1 (TID 1039, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=208, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 52.0 in stage 1.1 (TID 1039) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (flatMap at Partitioning.scala:52) and ShuffleMapStage 1 (flatMap at Partitioning.scala:78) due to fetch failure
18/09/26 14:20:29 WARN TaskSetManager: Lost task 55.0 in stage 1.1 (TID 1042, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=220, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 55.0 in stage 1.1 (TID 1042) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 51.0 in stage 1.1 (TID 1038, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=206, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 51.0 in stage 1.1 (TID 1038) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 50.0 in stage 1.1 (TID 1037, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=295, reduceId=204, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 50.0 in stage 1.1 (TID 1037) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 53.0 in stage 1.1 (TID 1040, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=307, reduceId=212, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 53.0 in stage 1.1 (TID 1040) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 49.0 in stage 1.1 (TID 1036, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=203, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 49.0 in stage 1.1 (TID 1036) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 WARN TaskSetManager: Lost task 48.0 in stage 1.1 (TID 1035, 192.168.33.12, executor 3): FetchFailed(BlockManagerId(1, 192.168.33.10, 41196, None), shuffleId=5, mapId=5, reduceId=197, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:61)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to /192.168.33.10:41196
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connexion refusée: /192.168.33.10:41196
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:631)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	... 2 more

)
18/09/26 14:20:29 INFO TaskSetManager: Task 48.0 in stage 1.1 (TID 1035) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 14:20:29 INFO TaskSchedulerImpl: Removed TaskSet 1.1, whose tasks have all completed, from pool 
18/09/26 14:20:29 INFO DAGScheduler: Resubmitting failed stages
18/09/26 14:20:31 INFO TaskSetManager: Finished task 5.0 in stage 0.2 (TID 1051) in 15950 ms on 192.168.33.15 (executor 6) (6/73)
18/09/26 14:20:35 INFO TaskSetManager: Finished task 6.0 in stage 0.2 (TID 1052) in 20236 ms on 192.168.33.13 (executor 2) (7/73)
18/09/26 14:20:38 INFO TaskSetManager: Finished task 62.0 in stage 0.2 (TID 1109) in 11478 ms on 192.168.33.11 (executor 5) (8/73)
18/09/26 14:20:39 INFO TaskSetManager: Finished task 54.0 in stage 0.2 (TID 1101) in 13920 ms on 192.168.33.14 (executor 4) (9/73)
18/09/26 14:20:40 INFO TaskSetManager: Finished task 48.0 in stage 0.2 (TID 1095) in 15471 ms on 192.168.33.14 (executor 4) (10/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 46.0 in stage 0.2 (TID 1093) in 15903 ms on 192.168.33.14 (executor 4) (11/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 45.0 in stage 0.2 (TID 1092) in 16372 ms on 192.168.33.14 (executor 4) (12/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 52.0 in stage 0.2 (TID 1099) in 16381 ms on 192.168.33.14 (executor 4) (13/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 61.0 in stage 0.2 (TID 1108) in 15287 ms on 192.168.33.14 (executor 4) (14/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 72.0 in stage 0.2 (TID 1119) in 12378 ms on 192.168.33.11 (executor 5) (15/73)
18/09/26 14:20:41 INFO TaskSetManager: Finished task 44.0 in stage 0.2 (TID 1091) in 16586 ms on 192.168.33.14 (executor 4) (16/73)
18/09/26 14:20:42 INFO TaskSetManager: Finished task 55.0 in stage 0.2 (TID 1102) in 17117 ms on 192.168.33.14 (executor 4) (17/73)
18/09/26 14:20:42 INFO TaskSetManager: Finished task 70.0 in stage 0.2 (TID 1117) in 13066 ms on 192.168.33.11 (executor 5) (18/73)
18/09/26 14:20:43 INFO TaskSetManager: Finished task 71.0 in stage 0.2 (TID 1118) in 13494 ms on 192.168.33.11 (executor 5) (19/73)
18/09/26 14:20:48 INFO TaskSetManager: Finished task 68.0 in stage 0.2 (TID 1115) in 21426 ms on 192.168.33.13 (executor 2) (20/73)
18/09/26 14:20:48 INFO TaskSetManager: Finished task 64.0 in stage 0.2 (TID 1111) in 21615 ms on 192.168.33.13 (executor 2) (21/73)
18/09/26 14:20:49 INFO TaskSetManager: Finished task 66.0 in stage 0.2 (TID 1113) in 21826 ms on 192.168.33.13 (executor 2) (22/73)
18/09/26 14:20:49 INFO TaskSetManager: Finished task 69.0 in stage 0.2 (TID 1116) in 21975 ms on 192.168.33.13 (executor 2) (23/73)
18/09/26 14:20:49 INFO TaskSetManager: Finished task 67.0 in stage 0.2 (TID 1114) in 22241 ms on 192.168.33.13 (executor 2) (24/73)
18/09/26 14:20:49 INFO TaskSetManager: Finished task 65.0 in stage 0.2 (TID 1112) in 22303 ms on 192.168.33.13 (executor 2) (25/73)
18/09/26 14:20:50 INFO TaskSetManager: Finished task 63.0 in stage 0.2 (TID 1110) in 22946 ms on 192.168.33.13 (executor 2) (26/73)
18/09/26 14:20:57 INFO TaskSetManager: Finished task 38.0 in stage 0.2 (TID 1085) in 32507 ms on 192.168.33.15 (executor 6) (27/73)
18/09/26 14:20:59 INFO TaskSetManager: Finished task 50.0 in stage 0.2 (TID 1097) in 34287 ms on 192.168.33.15 (executor 6) (28/73)
18/09/26 14:20:59 INFO TaskSetManager: Finished task 39.0 in stage 0.2 (TID 1086) in 34541 ms on 192.168.33.15 (executor 6) (29/73)
18/09/26 14:20:59 INFO TaskSetManager: Finished task 57.0 in stage 0.2 (TID 1104) in 34488 ms on 192.168.33.15 (executor 6) (30/73)
18/09/26 14:21:00 INFO TaskSetManager: Finished task 35.0 in stage 0.2 (TID 1082) in 34811 ms on 192.168.33.15 (executor 6) (31/73)
18/09/26 14:21:00 INFO TaskSetManager: Finished task 42.0 in stage 0.2 (TID 1089) in 34859 ms on 192.168.33.15 (executor 6) (32/73)
18/09/26 14:21:00 INFO TaskSetManager: Finished task 58.0 in stage 0.2 (TID 1105) in 35270 ms on 192.168.33.15 (executor 6) (33/73)
18/09/26 14:21:00 INFO TaskSetManager: Finished task 51.0 in stage 0.2 (TID 1098) in 35379 ms on 192.168.33.15 (executor 6) (34/73)
18/09/26 14:21:01 INFO TaskSetManager: Finished task 37.0 in stage 0.2 (TID 1084) in 35832 ms on 192.168.33.15 (executor 6) (35/73)
18/09/26 14:21:01 INFO TaskSetManager: Finished task 41.0 in stage 0.2 (TID 1088) in 35951 ms on 192.168.33.15 (executor 6) (36/73)
18/09/26 14:21:01 INFO TaskSetManager: Finished task 40.0 in stage 0.2 (TID 1087) in 35988 ms on 192.168.33.15 (executor 6) (37/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 32.0 in stage 0.2 (TID 1079) in 36995 ms on 192.168.33.15 (executor 6) (38/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 53.0 in stage 0.2 (TID 1100) in 36897 ms on 192.168.33.15 (executor 6) (39/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 47.0 in stage 0.2 (TID 1094) in 37353 ms on 192.168.33.15 (executor 6) (40/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 56.0 in stage 0.2 (TID 1103) in 37317 ms on 192.168.33.15 (executor 6) (41/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 36.0 in stage 0.2 (TID 1083) in 37550 ms on 192.168.33.15 (executor 6) (42/73)
18/09/26 14:21:02 INFO TaskSetManager: Finished task 33.0 in stage 0.2 (TID 1080) in 37597 ms on 192.168.33.15 (executor 6) (43/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 60.0 in stage 0.2 (TID 1107) in 37713 ms on 192.168.33.15 (executor 6) (44/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 34.0 in stage 0.2 (TID 1081) in 38026 ms on 192.168.33.15 (executor 6) (45/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 43.0 in stage 0.2 (TID 1090) in 38119 ms on 192.168.33.15 (executor 6) (46/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 49.0 in stage 0.2 (TID 1096) in 38108 ms on 192.168.33.15 (executor 6) (47/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 24.0 in stage 0.2 (TID 1071) in 41481 ms on 192.168.33.10 (executor 7) (48/73)
18/09/26 14:21:03 INFO TaskSetManager: Finished task 59.0 in stage 0.2 (TID 1106) in 38066 ms on 192.168.33.15 (executor 6) (49/73)
18/09/26 14:21:04 INFO TaskSetManager: Finished task 10.0 in stage 0.2 (TID 1057) in 42655 ms on 192.168.33.10 (executor 7) (50/73)
18/09/26 14:21:04 INFO TaskSetManager: Finished task 29.0 in stage 0.2 (TID 1076) in 42888 ms on 192.168.33.10 (executor 7) (51/73)
18/09/26 14:21:05 INFO TaskSetManager: Finished task 31.0 in stage 0.2 (TID 1078) in 39832 ms on 192.168.33.15 (executor 6) (52/73)
18/09/26 14:21:05 INFO TaskSetManager: Finished task 11.0 in stage 0.2 (TID 1058) in 43487 ms on 192.168.33.10 (executor 7) (53/73)
18/09/26 14:21:05 INFO TaskSetManager: Finished task 21.0 in stage 0.2 (TID 1068) in 43618 ms on 192.168.33.10 (executor 7) (54/73)
18/09/26 14:21:06 INFO TaskSetManager: Finished task 19.0 in stage 0.2 (TID 1066) in 44119 ms on 192.168.33.10 (executor 7) (55/73)
18/09/26 14:21:06 INFO TaskSetManager: Finished task 18.0 in stage 0.2 (TID 1065) in 44506 ms on 192.168.33.10 (executor 7) (56/73)
18/09/26 14:21:06 INFO TaskSetManager: Finished task 14.0 in stage 0.2 (TID 1061) in 44537 ms on 192.168.33.10 (executor 7) (57/73)
18/09/26 14:21:06 INFO TaskSetManager: Finished task 16.0 in stage 0.2 (TID 1063) in 44843 ms on 192.168.33.10 (executor 7) (58/73)
18/09/26 14:21:06 INFO TaskSetManager: Finished task 15.0 in stage 0.2 (TID 1062) in 44946 ms on 192.168.33.10 (executor 7) (59/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 25.0 in stage 0.2 (TID 1072) in 45460 ms on 192.168.33.10 (executor 7) (60/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 9.0 in stage 0.2 (TID 1056) in 45488 ms on 192.168.33.10 (executor 7) (61/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 12.0 in stage 0.2 (TID 1059) in 45530 ms on 192.168.33.10 (executor 7) (62/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 26.0 in stage 0.2 (TID 1073) in 45581 ms on 192.168.33.10 (executor 7) (63/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 17.0 in stage 0.2 (TID 1064) in 45696 ms on 192.168.33.10 (executor 7) (64/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 22.0 in stage 0.2 (TID 1069) in 45802 ms on 192.168.33.10 (executor 7) (65/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 28.0 in stage 0.2 (TID 1075) in 45807 ms on 192.168.33.10 (executor 7) (66/73)
18/09/26 14:21:07 INFO TaskSetManager: Finished task 30.0 in stage 0.2 (TID 1077) in 45860 ms on 192.168.33.10 (executor 7) (67/73)
18/09/26 14:21:08 INFO TaskSetManager: Finished task 13.0 in stage 0.2 (TID 1060) in 45954 ms on 192.168.33.10 (executor 7) (68/73)
18/09/26 14:21:08 INFO TaskSetManager: Finished task 8.0 in stage 0.2 (TID 1055) in 46002 ms on 192.168.33.10 (executor 7) (69/73)
18/09/26 14:21:08 INFO TaskSetManager: Finished task 20.0 in stage 0.2 (TID 1067) in 46548 ms on 192.168.33.10 (executor 7) (70/73)
18/09/26 14:21:08 INFO TaskSetManager: Finished task 27.0 in stage 0.2 (TID 1074) in 46628 ms on 192.168.33.10 (executor 7) (71/73)
18/09/26 14:21:08 INFO TaskSetManager: Finished task 7.1 in stage 0.2 (TID 1054) in 46942 ms on 192.168.33.10 (executor 7) (72/73)
18/09/26 14:21:09 INFO TaskSetManager: Finished task 23.0 in stage 0.2 (TID 1070) in 47441 ms on 192.168.33.10 (executor 7) (73/73)
18/09/26 14:21:09 INFO TaskSchedulerImpl: Removed TaskSet 0.2, whose tasks have all completed, from pool 
18/09/26 14:21:09 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 97,719 s
18/09/26 14:21:09 INFO DAGScheduler: looking for newly runnable stages
18/09/26 14:21:09 INFO DAGScheduler: running: Set()
18/09/26 14:21:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 14:21:09 INFO DAGScheduler: failed: Set()
18/09/26 14:21:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/26 14:21:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/26 14:21:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1836.0 B, free 365.9 MB)
18/09/26 14:21:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.10:43403 (size: 1836.0 B, free: 366.3 MB)
18/09/26 14:21:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/09/26 14:21:09 INFO DAGScheduler: Submitting 111 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 14:21:09 INFO TaskSchedulerImpl: Adding task set 1.2 with 111 tasks
18/09/26 14:21:09 INFO TaskSetManager: Starting task 0.0 in stage 1.2 (TID 1120, 192.168.33.15, executor 6, partition 0, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 4.0 in stage 1.2 (TID 1121, 192.168.33.14, executor 4, partition 4, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 1.0 in stage 1.2 (TID 1122, 192.168.33.15, executor 6, partition 1, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 5.0 in stage 1.2 (TID 1123, 192.168.33.14, executor 4, partition 5, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 2.0 in stage 1.2 (TID 1124, 192.168.33.15, executor 6, partition 2, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 6.0 in stage 1.2 (TID 1125, 192.168.33.14, executor 4, partition 6, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 3.0 in stage 1.2 (TID 1126, 192.168.33.15, executor 6, partition 3, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 9.0 in stage 1.2 (TID 1127, 192.168.33.14, executor 4, partition 9, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 7.0 in stage 1.2 (TID 1128, 192.168.33.15, executor 6, partition 7, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 10.0 in stage 1.2 (TID 1129, 192.168.33.14, executor 4, partition 10, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 8.0 in stage 1.2 (TID 1130, 192.168.33.15, executor 6, partition 8, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 11.0 in stage 1.2 (TID 1131, 192.168.33.14, executor 4, partition 11, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 12.0 in stage 1.2 (TID 1132, 192.168.33.15, executor 6, partition 12, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 20.0 in stage 1.2 (TID 1133, 192.168.33.14, executor 4, partition 20, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 13.0 in stage 1.2 (TID 1134, 192.168.33.15, executor 6, partition 13, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 23.0 in stage 1.2 (TID 1135, 192.168.33.14, executor 4, partition 23, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 14.0 in stage 1.2 (TID 1136, 192.168.33.15, executor 6, partition 14, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 15.0 in stage 1.2 (TID 1137, 192.168.33.15, executor 6, partition 15, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 16.0 in stage 1.2 (TID 1138, 192.168.33.15, executor 6, partition 16, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 17.0 in stage 1.2 (TID 1139, 192.168.33.15, executor 6, partition 17, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 18.0 in stage 1.2 (TID 1140, 192.168.33.15, executor 6, partition 18, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 19.0 in stage 1.2 (TID 1141, 192.168.33.15, executor 6, partition 19, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 21.0 in stage 1.2 (TID 1142, 192.168.33.15, executor 6, partition 21, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 22.0 in stage 1.2 (TID 1143, 192.168.33.15, executor 6, partition 22, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 24.0 in stage 1.2 (TID 1144, 192.168.33.15, executor 6, partition 24, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 25.0 in stage 1.2 (TID 1145, 192.168.33.15, executor 6, partition 29, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 26.0 in stage 1.2 (TID 1146, 192.168.33.15, executor 6, partition 34, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 27.0 in stage 1.2 (TID 1147, 192.168.33.15, executor 6, partition 39, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 28.0 in stage 1.2 (TID 1148, 192.168.33.15, executor 6, partition 44, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 29.0 in stage 1.2 (TID 1149, 192.168.33.15, executor 6, partition 49, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 30.0 in stage 1.2 (TID 1150, 192.168.33.15, executor 6, partition 54, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO TaskSetManager: Starting task 31.0 in stage 1.2 (TID 1151, 192.168.33.15, executor 6, partition 59, NODE_LOCAL, 4614 bytes)
18/09/26 14:21:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.14:34961 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:37206
18/09/26 14:21:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 92480 bytes
18/09/26 14:21:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.15:41164 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.15:57102
18/09/26 14:21:13 INFO TaskSetManager: Starting task 32.0 in stage 1.2 (TID 1152, 192.168.33.13, executor 2, partition 64, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 33.0 in stage 1.2 (TID 1153, 192.168.33.10, executor 7, partition 65, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 34.0 in stage 1.2 (TID 1154, 192.168.33.11, executor 5, partition 66, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 35.0 in stage 1.2 (TID 1155, 192.168.33.12, executor 3, partition 67, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 36.0 in stage 1.2 (TID 1156, 192.168.33.13, executor 2, partition 68, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 37.0 in stage 1.2 (TID 1157, 192.168.33.10, executor 7, partition 69, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 38.0 in stage 1.2 (TID 1158, 192.168.33.11, executor 5, partition 70, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 39.0 in stage 1.2 (TID 1159, 192.168.33.12, executor 3, partition 71, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 40.0 in stage 1.2 (TID 1160, 192.168.33.13, executor 2, partition 72, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 41.0 in stage 1.2 (TID 1161, 192.168.33.10, executor 7, partition 73, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 42.0 in stage 1.2 (TID 1162, 192.168.33.11, executor 5, partition 74, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 43.0 in stage 1.2 (TID 1163, 192.168.33.12, executor 3, partition 75, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 44.0 in stage 1.2 (TID 1164, 192.168.33.13, executor 2, partition 76, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 45.0 in stage 1.2 (TID 1165, 192.168.33.10, executor 7, partition 77, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 46.0 in stage 1.2 (TID 1166, 192.168.33.11, executor 5, partition 78, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 47.0 in stage 1.2 (TID 1167, 192.168.33.12, executor 3, partition 79, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 48.0 in stage 1.2 (TID 1168, 192.168.33.13, executor 2, partition 113, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 49.0 in stage 1.2 (TID 1169, 192.168.33.10, executor 7, partition 114, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 50.0 in stage 1.2 (TID 1170, 192.168.33.11, executor 5, partition 117, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 51.0 in stage 1.2 (TID 1171, 192.168.33.12, executor 3, partition 118, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 52.0 in stage 1.2 (TID 1172, 192.168.33.13, executor 2, partition 125, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 53.0 in stage 1.2 (TID 1173, 192.168.33.10, executor 7, partition 127, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 54.0 in stage 1.2 (TID 1174, 192.168.33.11, executor 5, partition 128, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 55.0 in stage 1.2 (TID 1175, 192.168.33.12, executor 3, partition 133, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 56.0 in stage 1.2 (TID 1176, 192.168.33.13, executor 2, partition 138, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 57.0 in stage 1.2 (TID 1177, 192.168.33.10, executor 7, partition 150, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 58.0 in stage 1.2 (TID 1178, 192.168.33.11, executor 5, partition 153, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 59.0 in stage 1.2 (TID 1179, 192.168.33.12, executor 3, partition 154, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 60.0 in stage 1.2 (TID 1180, 192.168.33.13, executor 2, partition 155, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 61.0 in stage 1.2 (TID 1181, 192.168.33.10, executor 7, partition 159, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 62.0 in stage 1.2 (TID 1182, 192.168.33.11, executor 5, partition 168, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 63.0 in stage 1.2 (TID 1183, 192.168.33.12, executor 3, partition 169, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 64.0 in stage 1.2 (TID 1184, 192.168.33.10, executor 7, partition 170, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 65.0 in stage 1.2 (TID 1185, 192.168.33.10, executor 7, partition 171, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 66.0 in stage 1.2 (TID 1186, 192.168.33.10, executor 7, partition 172, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 67.0 in stage 1.2 (TID 1187, 192.168.33.10, executor 7, partition 182, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 68.0 in stage 1.2 (TID 1188, 192.168.33.10, executor 7, partition 190, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 69.0 in stage 1.2 (TID 1189, 192.168.33.10, executor 7, partition 197, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 70.0 in stage 1.2 (TID 1190, 192.168.33.10, executor 7, partition 203, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 71.0 in stage 1.2 (TID 1191, 192.168.33.10, executor 7, partition 204, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 72.0 in stage 1.2 (TID 1192, 192.168.33.10, executor 7, partition 206, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 73.0 in stage 1.2 (TID 1193, 192.168.33.10, executor 7, partition 208, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 74.0 in stage 1.2 (TID 1194, 192.168.33.10, executor 7, partition 212, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 75.0 in stage 1.2 (TID 1195, 192.168.33.10, executor 7, partition 218, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 76.0 in stage 1.2 (TID 1196, 192.168.33.10, executor 7, partition 220, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 77.0 in stage 1.2 (TID 1197, 192.168.33.10, executor 7, partition 221, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 78.0 in stage 1.2 (TID 1198, 192.168.33.10, executor 7, partition 224, ANY, 4614 bytes)
18/09/26 14:21:13 INFO TaskSetManager: Starting task 79.0 in stage 1.2 (TID 1199, 192.168.33.10, executor 7, partition 227, ANY, 4614 bytes)
18/09/26 14:21:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.13:33570 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.11:38333 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.12:35074 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.11:43502
18/09/26 14:21:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.12:37794
18/09/26 14:21:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.10:38790 (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:21:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.10:41482
18/09/26 14:21:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.13:43042
18/09/26 14:23:23 INFO TaskSetManager: Starting task 80.0 in stage 1.2 (TID 1200, 192.168.33.11, executor 5, partition 230, ANY, 4614 bytes)
18/09/26 14:23:23 INFO TaskSetManager: Finished task 50.0 in stage 1.2 (TID 1170) in 130549 ms on 192.168.33.11 (executor 5) (1/111)
18/09/26 14:23:56 INFO TaskSetManager: Starting task 81.0 in stage 1.2 (TID 1201, 192.168.33.11, executor 5, partition 231, ANY, 4614 bytes)
18/09/26 14:23:56 INFO TaskSetManager: Finished task 38.0 in stage 1.2 (TID 1158) in 162906 ms on 192.168.33.11 (executor 5) (2/111)
18/09/26 14:24:04 INFO TaskSetManager: Starting task 82.0 in stage 1.2 (TID 1202, 192.168.33.11, executor 5, partition 234, ANY, 4614 bytes)
18/09/26 14:24:04 INFO TaskSetManager: Finished task 34.0 in stage 1.2 (TID 1154) in 171580 ms on 192.168.33.11 (executor 5) (3/111)
18/09/26 14:24:10 INFO TaskSetManager: Starting task 83.0 in stage 1.2 (TID 1203, 192.168.33.11, executor 5, partition 235, ANY, 4614 bytes)
18/09/26 14:24:10 INFO TaskSetManager: Finished task 58.0 in stage 1.2 (TID 1178) in 176962 ms on 192.168.33.11 (executor 5) (4/111)
18/09/26 14:24:21 INFO TaskSetManager: Starting task 84.0 in stage 1.2 (TID 1204, 192.168.33.14, executor 4, partition 236, NODE_LOCAL, 4614 bytes)
18/09/26 14:24:21 INFO TaskSetManager: Finished task 5.0 in stage 1.2 (TID 1123) in 191731 ms on 192.168.33.14 (executor 4) (5/111)
18/09/26 14:24:21 INFO TaskSetManager: Starting task 88.0 in stage 1.2 (TID 1205, 192.168.33.14, executor 4, partition 249, NODE_LOCAL, 4614 bytes)
18/09/26 14:24:21 INFO TaskSetManager: Finished task 11.0 in stage 1.2 (TID 1131) in 192451 ms on 192.168.33.14 (executor 4) (6/111)
18/09/26 14:24:23 INFO TaskSetManager: Finished task 40.0 in stage 1.2 (TID 1160) in 190023 ms on 192.168.33.13 (executor 2) (7/111)
18/09/26 14:24:24 INFO TaskSetManager: Starting task 93.0 in stage 1.2 (TID 1206, 192.168.33.14, executor 4, partition 276, NODE_LOCAL, 4614 bytes)
18/09/26 14:24:24 INFO TaskSetManager: Finished task 6.0 in stage 1.2 (TID 1125) in 194510 ms on 192.168.33.14 (executor 4) (8/111)
18/09/26 14:24:27 INFO TaskSetManager: Starting task 85.0 in stage 1.2 (TID 1207, 192.168.33.13, executor 2, partition 242, ANY, 4614 bytes)
18/09/26 14:24:32 INFO TaskSetManager: Starting task 86.0 in stage 1.2 (TID 1208, 192.168.33.13, executor 2, partition 245, ANY, 4614 bytes)
18/09/26 14:24:32 INFO TaskSetManager: Finished task 52.0 in stage 1.2 (TID 1172) in 198837 ms on 192.168.33.13 (executor 2) (9/111)
18/09/26 14:24:49 INFO TaskSetManager: Starting task 87.0 in stage 1.2 (TID 1209, 192.168.33.11, executor 5, partition 247, ANY, 4614 bytes)
18/09/26 14:24:49 INFO TaskSetManager: Finished task 54.0 in stage 1.2 (TID 1174) in 216328 ms on 192.168.33.11 (executor 5) (10/111)
18/09/26 14:24:57 INFO TaskSetManager: Starting task 95.0 in stage 1.2 (TID 1210, 192.168.33.14, executor 4, partition 281, NODE_LOCAL, 4614 bytes)
18/09/26 14:24:57 INFO TaskSetManager: Finished task 9.0 in stage 1.2 (TID 1127) in 228175 ms on 192.168.33.14 (executor 4) (11/111)
18/09/26 14:24:58 INFO TaskSetManager: Finished task 56.0 in stage 1.2 (TID 1176) in 225455 ms on 192.168.33.13 (executor 2) (12/111)
18/09/26 14:25:01 INFO TaskSetManager: Starting task 89.0 in stage 1.2 (TID 1211, 192.168.33.13, executor 2, partition 253, ANY, 4614 bytes)
18/09/26 14:25:08 INFO TaskSetManager: Starting task 90.0 in stage 1.2 (TID 1212, 192.168.33.12, executor 3, partition 267, ANY, 4614 bytes)
18/09/26 14:25:08 INFO TaskSetManager: Finished task 39.0 in stage 1.2 (TID 1159) in 235338 ms on 192.168.33.12 (executor 3) (13/111)
18/09/26 14:25:12 INFO TaskSetManager: Starting task 99.0 in stage 1.2 (TID 1213, 192.168.33.14, executor 4, partition 302, NODE_LOCAL, 4614 bytes)
18/09/26 14:25:12 INFO TaskSetManager: Finished task 10.0 in stage 1.2 (TID 1129) in 243136 ms on 192.168.33.14 (executor 4) (14/111)
18/09/26 14:25:17 INFO TaskSetManager: Starting task 91.0 in stage 1.2 (TID 1214, 192.168.33.13, executor 2, partition 268, ANY, 4614 bytes)
18/09/26 14:25:17 INFO TaskSetManager: Finished task 36.0 in stage 1.2 (TID 1156) in 244348 ms on 192.168.33.13 (executor 2) (15/111)
18/09/26 14:25:18 INFO TaskSetManager: Starting task 92.0 in stage 1.2 (TID 1215, 192.168.33.13, executor 2, partition 275, ANY, 4614 bytes)
18/09/26 14:25:18 INFO TaskSetManager: Finished task 60.0 in stage 1.2 (TID 1180) in 245703 ms on 192.168.33.13 (executor 2) (16/111)
18/09/26 14:25:22 INFO TaskSetManager: Starting task 94.0 in stage 1.2 (TID 1216, 192.168.33.11, executor 5, partition 277, ANY, 4614 bytes)
18/09/26 14:25:22 INFO TaskSetManager: Finished task 46.0 in stage 1.2 (TID 1166) in 249736 ms on 192.168.33.11 (executor 5) (17/111)
18/09/26 14:25:26 INFO TaskSetManager: Starting task 96.0 in stage 1.2 (TID 1217, 192.168.33.12, executor 3, partition 289, ANY, 4614 bytes)
18/09/26 14:25:26 INFO TaskSetManager: Finished task 59.0 in stage 1.2 (TID 1179) in 253657 ms on 192.168.33.12 (executor 3) (18/111)
18/09/26 14:25:29 INFO TaskSetManager: Starting task 97.0 in stage 1.2 (TID 1218, 192.168.33.11, executor 5, partition 297, ANY, 4614 bytes)
18/09/26 14:25:29 INFO TaskSetManager: Finished task 62.0 in stage 1.2 (TID 1182) in 255963 ms on 192.168.33.11 (executor 5) (19/111)
18/09/26 14:25:36 INFO TaskSetManager: Starting task 100.0 in stage 1.2 (TID 1219, 192.168.33.14, executor 4, partition 303, NODE_LOCAL, 4614 bytes)
18/09/26 14:25:36 INFO TaskSetManager: Finished task 20.0 in stage 1.2 (TID 1133) in 267275 ms on 192.168.33.14 (executor 4) (20/111)
18/09/26 14:25:37 INFO TaskSetManager: Finished task 35.0 in stage 1.2 (TID 1155) in 264546 ms on 192.168.33.12 (executor 3) (21/111)
18/09/26 14:25:39 INFO TaskSetManager: Finished task 47.0 in stage 1.2 (TID 1167) in 265964 ms on 192.168.33.12 (executor 3) (22/111)
18/09/26 14:25:40 INFO TaskSetManager: Starting task 98.0 in stage 1.2 (TID 1220, 192.168.33.12, executor 3, partition 300, ANY, 4614 bytes)
18/09/26 14:25:40 INFO TaskSetManager: Starting task 101.0 in stage 1.2 (TID 1221, 192.168.33.12, executor 3, partition 304, ANY, 4614 bytes)
18/09/26 14:25:41 INFO TaskSetManager: Starting task 104.0 in stage 1.2 (TID 1222, 192.168.33.14, executor 4, partition 311, NODE_LOCAL, 4614 bytes)
18/09/26 14:25:41 INFO TaskSetManager: Finished task 23.0 in stage 1.2 (TID 1135) in 272031 ms on 192.168.33.14 (executor 4) (23/111)
18/09/26 14:26:04 INFO TaskSetManager: Starting task 102.0 in stage 1.2 (TID 1223, 192.168.33.11, executor 5, partition 308, ANY, 4614 bytes)
18/09/26 14:26:04 INFO TaskSetManager: Finished task 42.0 in stage 1.2 (TID 1162) in 291435 ms on 192.168.33.11 (executor 5) (24/111)
18/09/26 14:26:06 INFO TaskSetManager: Starting task 103.0 in stage 1.2 (TID 1224, 192.168.33.12, executor 3, partition 309, ANY, 4614 bytes)
18/09/26 14:26:06 INFO TaskSetManager: Finished task 43.0 in stage 1.2 (TID 1163) in 293511 ms on 192.168.33.12 (executor 3) (25/111)
18/09/26 14:26:09 INFO TaskSetManager: Starting task 106.0 in stage 1.2 (TID 1225, 192.168.33.14, executor 4, partition 318, NODE_LOCAL, 4614 bytes)
18/09/26 14:26:09 INFO TaskSetManager: Finished task 4.0 in stage 1.2 (TID 1121) in 299554 ms on 192.168.33.14 (executor 4) (26/111)
18/09/26 14:26:16 INFO TaskSetManager: Starting task 105.0 in stage 1.2 (TID 1226, 192.168.33.11, executor 5, partition 312, ANY, 4614 bytes)
18/09/26 14:26:16 INFO TaskSetManager: Finished task 81.0 in stage 1.2 (TID 1201) in 140358 ms on 192.168.33.11 (executor 5) (27/111)
18/09/26 14:26:18 INFO TaskSetManager: Starting task 107.0 in stage 1.2 (TID 1227, 192.168.33.12, executor 3, partition 319, ANY, 4614 bytes)
18/09/26 14:26:18 INFO TaskSetManager: Finished task 55.0 in stage 1.2 (TID 1175) in 305126 ms on 192.168.33.12 (executor 3) (28/111)
18/09/26 14:26:28 INFO TaskSetManager: Starting task 108.0 in stage 1.2 (TID 1228, 192.168.33.11, executor 5, partition 320, ANY, 4614 bytes)
18/09/26 14:26:28 INFO TaskSetManager: Finished task 83.0 in stage 1.2 (TID 1203) in 137993 ms on 192.168.33.11 (executor 5) (29/111)
18/09/26 14:26:36 INFO TaskSetManager: Starting task 109.0 in stage 1.2 (TID 1229, 192.168.33.13, executor 2, partition 321, ANY, 4614 bytes)
18/09/26 14:26:36 INFO TaskSetManager: Finished task 44.0 in stage 1.2 (TID 1164) in 323064 ms on 192.168.33.13 (executor 2) (30/111)
18/09/26 14:26:44 INFO TaskSetManager: Starting task 110.0 in stage 1.2 (TID 1230, 192.168.33.12, executor 3, partition 324, ANY, 4614 bytes)
18/09/26 14:26:44 INFO TaskSetManager: Finished task 63.0 in stage 1.2 (TID 1183) in 330947 ms on 192.168.33.12 (executor 3) (31/111)
18/09/26 14:26:55 INFO TaskSetManager: Finished task 48.0 in stage 1.2 (TID 1168) in 342228 ms on 192.168.33.13 (executor 2) (32/111)
18/09/26 14:27:13 INFO TaskSetManager: Finished task 51.0 in stage 1.2 (TID 1171) in 360301 ms on 192.168.33.12 (executor 3) (33/111)
18/09/26 14:27:22 INFO TaskSetManager: Finished task 82.0 in stage 1.2 (TID 1202) in 197257 ms on 192.168.33.11 (executor 5) (34/111)
18/09/26 14:27:37 INFO TaskSetManager: Finished task 93.0 in stage 1.2 (TID 1206) in 193469 ms on 192.168.33.14 (executor 4) (35/111)
18/09/26 14:27:41 INFO TaskSetManager: Finished task 84.0 in stage 1.2 (TID 1204) in 199849 ms on 192.168.33.14 (executor 4) (36/111)
18/09/26 14:27:47 INFO TaskSetManager: Finished task 88.0 in stage 1.2 (TID 1205) in 205051 ms on 192.168.33.14 (executor 4) (37/111)
18/09/26 14:28:02 INFO TaskSetManager: Finished task 97.0 in stage 1.2 (TID 1218) in 153205 ms on 192.168.33.11 (executor 5) (38/111)
18/09/26 14:28:21 INFO TaskSetManager: Finished task 104.0 in stage 1.2 (TID 1222) in 160297 ms on 192.168.33.14 (executor 4) (39/111)
18/09/26 14:28:23 INFO TaskSetManager: Finished task 98.0 in stage 1.2 (TID 1220) in 162839 ms on 192.168.33.12 (executor 3) (40/111)
18/09/26 14:28:37 INFO TaskSetManager: Finished task 103.0 in stage 1.2 (TID 1224) in 150660 ms on 192.168.33.12 (executor 3) (41/111)
18/09/26 14:28:38 INFO TaskSetManager: Finished task 21.0 in stage 1.2 (TID 1142) in 449229 ms on 192.168.33.15 (executor 6) (42/111)
18/09/26 14:28:41 INFO TaskSetManager: Finished task 15.0 in stage 1.2 (TID 1137) in 451574 ms on 192.168.33.15 (executor 6) (43/111)
18/09/26 14:28:43 INFO TaskSetManager: Finished task 17.0 in stage 1.2 (TID 1139) in 454368 ms on 192.168.33.15 (executor 6) (44/111)
18/09/26 14:28:47 INFO TaskSetManager: Finished task 90.0 in stage 1.2 (TID 1212) in 218437 ms on 192.168.33.12 (executor 3) (45/111)
18/09/26 14:28:53 INFO TaskSetManager: Finished task 87.0 in stage 1.2 (TID 1209) in 243652 ms on 192.168.33.11 (executor 5) (46/111)
18/09/26 14:28:54 INFO TaskSetManager: Finished task 86.0 in stage 1.2 (TID 1208) in 262473 ms on 192.168.33.13 (executor 2) (47/111)
18/09/26 14:28:55 INFO TaskSetManager: Finished task 85.0 in stage 1.2 (TID 1207) in 268155 ms on 192.168.33.13 (executor 2) (48/111)
18/09/26 14:28:56 INFO TaskSetManager: Finished task 13.0 in stage 1.2 (TID 1134) in 467136 ms on 192.168.33.15 (executor 6) (49/111)
18/09/26 14:29:04 INFO TaskSetManager: Finished task 80.0 in stage 1.2 (TID 1200) in 341018 ms on 192.168.33.11 (executor 5) (50/111)
18/09/26 14:29:07 INFO TaskSetManager: Finished task 96.0 in stage 1.2 (TID 1217) in 221085 ms on 192.168.33.12 (executor 3) (51/111)
18/09/26 14:29:08 INFO TaskSetManager: Finished task 101.0 in stage 1.2 (TID 1221) in 208538 ms on 192.168.33.12 (executor 3) (52/111)
18/09/26 14:29:15 INFO TaskSetManager: Finished task 95.0 in stage 1.2 (TID 1210) in 257856 ms on 192.168.33.14 (executor 4) (53/111)
18/09/26 14:29:20 INFO TaskSetManager: Finished task 105.0 in stage 1.2 (TID 1226) in 184421 ms on 192.168.33.11 (executor 5) (54/111)
18/09/26 14:29:23 INFO TaskSetManager: Finished task 107.0 in stage 1.2 (TID 1227) in 185362 ms on 192.168.33.12 (executor 3) (55/111)
18/09/26 14:29:31 INFO TaskSetManager: Finished task 92.0 in stage 1.2 (TID 1215) in 252781 ms on 192.168.33.13 (executor 2) (56/111)
18/09/26 14:29:39 INFO TaskSetManager: Finished task 106.0 in stage 1.2 (TID 1225) in 210081 ms on 192.168.33.14 (executor 4) (57/111)
18/09/26 14:29:47 INFO TaskSetManager: Finished task 110.0 in stage 1.2 (TID 1230) in 183284 ms on 192.168.33.12 (executor 3) (58/111)
18/09/26 14:29:50 INFO TaskSetManager: Finished task 31.0 in stage 1.2 (TID 1151) in 520864 ms on 192.168.33.15 (executor 6) (59/111)
18/09/26 14:29:55 INFO TaskSetManager: Finished task 24.0 in stage 1.2 (TID 1144) in 526380 ms on 192.168.33.15 (executor 6) (60/111)
18/09/26 14:29:55 INFO TaskSetManager: Finished task 91.0 in stage 1.2 (TID 1214) in 278355 ms on 192.168.33.13 (executor 2) (61/111)
18/09/26 14:29:58 INFO TaskSetManager: Finished task 89.0 in stage 1.2 (TID 1211) in 297134 ms on 192.168.33.13 (executor 2) (62/111)
18/09/26 14:30:01 INFO TaskSetManager: Finished task 109.0 in stage 1.2 (TID 1229) in 204922 ms on 192.168.33.13 (executor 2) (63/111)
18/09/26 14:30:02 INFO TaskSetManager: Finished task 102.0 in stage 1.2 (TID 1223) in 237914 ms on 192.168.33.11 (executor 5) (64/111)
18/09/26 14:30:14 INFO TaskSetManager: Finished task 94.0 in stage 1.2 (TID 1216) in 291609 ms on 192.168.33.11 (executor 5) (65/111)
18/09/26 14:30:25 INFO TaskSetManager: Finished task 29.0 in stage 1.2 (TID 1149) in 555735 ms on 192.168.33.15 (executor 6) (66/111)
18/09/26 14:30:25 INFO TaskSetManager: Finished task 0.0 in stage 1.2 (TID 1120) in 556441 ms on 192.168.33.15 (executor 6) (67/111)
18/09/26 14:30:38 INFO TaskSetManager: Finished task 26.0 in stage 1.2 (TID 1146) in 568933 ms on 192.168.33.15 (executor 6) (68/111)
18/09/26 14:30:43 INFO TaskSetManager: Finished task 3.0 in stage 1.2 (TID 1126) in 573831 ms on 192.168.33.15 (executor 6) (69/111)
18/09/26 14:31:04 INFO TaskSetManager: Finished task 30.0 in stage 1.2 (TID 1150) in 595277 ms on 192.168.33.15 (executor 6) (70/111)
18/09/26 14:31:24 INFO TaskSetManager: Finished task 108.0 in stage 1.2 (TID 1228) in 295854 ms on 192.168.33.11 (executor 5) (71/111)
18/09/26 14:31:30 INFO TaskSetManager: Finished task 16.0 in stage 1.2 (TID 1138) in 620753 ms on 192.168.33.15 (executor 6) (72/111)
18/09/26 14:31:34 INFO TaskSetManager: Finished task 22.0 in stage 1.2 (TID 1143) in 624832 ms on 192.168.33.15 (executor 6) (73/111)
18/09/26 14:32:00 INFO TaskSetManager: Finished task 12.0 in stage 1.2 (TID 1132) in 650745 ms on 192.168.33.15 (executor 6) (74/111)
18/09/26 14:32:13 INFO TaskSetManager: Finished task 14.0 in stage 1.2 (TID 1136) in 663617 ms on 192.168.33.15 (executor 6) (75/111)
18/09/26 14:32:21 INFO TaskSetManager: Finished task 19.0 in stage 1.2 (TID 1141) in 671629 ms on 192.168.33.15 (executor 6) (76/111)
18/09/26 14:32:34 INFO TaskSetManager: Finished task 1.0 in stage 1.2 (TID 1122) in 684640 ms on 192.168.33.15 (executor 6) (77/111)
18/09/26 14:32:40 INFO TaskSetManager: Finished task 28.0 in stage 1.2 (TID 1148) in 691244 ms on 192.168.33.15 (executor 6) (78/111)
18/09/26 14:32:44 INFO TaskSetManager: Finished task 18.0 in stage 1.2 (TID 1140) in 694896 ms on 192.168.33.15 (executor 6) (79/111)
18/09/26 14:33:10 INFO TaskSetManager: Finished task 2.0 in stage 1.2 (TID 1124) in 720963 ms on 192.168.33.15 (executor 6) (80/111)
18/09/26 14:33:20 INFO TaskSetManager: Finished task 8.0 in stage 1.2 (TID 1130) in 731148 ms on 192.168.33.15 (executor 6) (81/111)
18/09/26 14:33:37 INFO TaskSetManager: Finished task 27.0 in stage 1.2 (TID 1147) in 748256 ms on 192.168.33.15 (executor 6) (82/111)
18/09/26 14:33:40 INFO TaskSetManager: Finished task 7.0 in stage 1.2 (TID 1128) in 751361 ms on 192.168.33.15 (executor 6) (83/111)
18/09/26 14:34:51 INFO TaskSetManager: Finished task 25.0 in stage 1.2 (TID 1145) in 821659 ms on 192.168.33.15 (executor 6) (84/111)
18/09/26 14:38:02 INFO TaskSetManager: Finished task 32.0 in stage 1.2 (TID 1152) in 1009233 ms on 192.168.33.13 (executor 2) (85/111)
18/09/26 14:43:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.13:33570 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:43:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.11:38333 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:43:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.10:43403 in memory (size: 2.5 KB, free: 366.3 MB)
18/09/26 14:43:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.15:41164 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:43:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.14:34961 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.10:38790 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.15:41164 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.12:35074 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.11:38333 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.10:43403 in memory (size: 1836.0 B, free: 366.3 MB)
18/09/26 14:45:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.14:34961 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.13:33570 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.10:43403 in memory (size: 1836.0 B, free: 366.3 MB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.15:41164 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.12:35074 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.14:34961 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.11:38333 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 14:45:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.13:33570 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 15:18:26 INFO TaskSetManager: Finished task 68.0 in stage 1.2 (TID 1188) in 3433460 ms on 192.168.33.10 (executor 7) (86/111)
18/09/26 15:18:28 INFO TaskSetManager: Finished task 67.0 in stage 1.2 (TID 1187) in 3435118 ms on 192.168.33.10 (executor 7) (87/111)
18/09/26 15:18:49 INFO TaskSetManager: Finished task 76.0 in stage 1.2 (TID 1196) in 3456065 ms on 192.168.33.10 (executor 7) (88/111)
18/09/26 15:21:55 INFO TaskSetManager: Finished task 70.0 in stage 1.2 (TID 1190) in 3642132 ms on 192.168.33.10 (executor 7) (89/111)
18/09/26 15:21:55 INFO TaskSetManager: Finished task 65.0 in stage 1.2 (TID 1185) in 3642754 ms on 192.168.33.10 (executor 7) (90/111)
18/09/26 15:22:18 INFO TaskSetManager: Finished task 53.0 in stage 1.2 (TID 1173) in 3665076 ms on 192.168.33.10 (executor 7) (91/111)
18/09/26 15:22:30 INFO TaskSetManager: Finished task 79.0 in stage 1.2 (TID 1199) in 3677338 ms on 192.168.33.10 (executor 7) (92/111)
18/09/26 15:25:52 INFO TaskSetManager: Finished task 61.0 in stage 1.2 (TID 1181) in 3878849 ms on 192.168.33.10 (executor 7) (93/111)
18/09/26 15:27:05 INFO TaskSetManager: Finished task 45.0 in stage 1.2 (TID 1165) in 3951898 ms on 192.168.33.10 (executor 7) (94/111)
18/09/26 15:27:16 INFO TaskSetManager: Finished task 73.0 in stage 1.2 (TID 1193) in 3963665 ms on 192.168.33.10 (executor 7) (95/111)
18/09/26 15:28:17 INFO TaskSetManager: Finished task 77.0 in stage 1.2 (TID 1197) in 4024173 ms on 192.168.33.10 (executor 7) (96/111)
18/09/26 15:28:31 INFO TaskSetManager: Finished task 75.0 in stage 1.2 (TID 1195) in 4037998 ms on 192.168.33.10 (executor 7) (97/111)
18/09/26 15:28:42 INFO TaskSetManager: Finished task 57.0 in stage 1.2 (TID 1177) in 4048847 ms on 192.168.33.10 (executor 7) (98/111)
18/09/26 15:28:49 INFO TaskSetManager: Finished task 74.0 in stage 1.2 (TID 1194) in 4055993 ms on 192.168.33.10 (executor 7) (99/111)
18/09/26 15:29:28 INFO TaskSetManager: Finished task 99.0 in stage 1.2 (TID 1213) in 3855738 ms on 192.168.33.14 (executor 4) (100/111)
18/09/26 15:29:30 INFO TaskSetManager: Finished task 71.0 in stage 1.2 (TID 1191) in 4096847 ms on 192.168.33.10 (executor 7) (101/111)
18/09/26 15:29:45 INFO TaskSetManager: Finished task 72.0 in stage 1.2 (TID 1192) in 4112461 ms on 192.168.33.10 (executor 7) (102/111)
18/09/26 15:29:51 INFO TaskSetManager: Finished task 100.0 in stage 1.2 (TID 1219) in 3854565 ms on 192.168.33.14 (executor 4) (103/111)
18/09/26 15:29:59 INFO TaskSetManager: Finished task 69.0 in stage 1.2 (TID 1189) in 4126613 ms on 192.168.33.10 (executor 7) (104/111)
18/09/26 15:30:36 INFO TaskSetManager: Finished task 41.0 in stage 1.2 (TID 1161) in 4163359 ms on 192.168.33.10 (executor 7) (105/111)
18/09/26 15:30:37 INFO TaskSetManager: Finished task 64.0 in stage 1.2 (TID 1184) in 4164516 ms on 192.168.33.10 (executor 7) (106/111)
18/09/26 15:30:46 INFO TaskSetManager: Finished task 49.0 in stage 1.2 (TID 1169) in 4173088 ms on 192.168.33.10 (executor 7) (107/111)
18/09/26 15:30:47 INFO TaskSetManager: Finished task 33.0 in stage 1.2 (TID 1153) in 4173831 ms on 192.168.33.10 (executor 7) (108/111)
18/09/26 15:30:49 INFO TaskSetManager: Finished task 78.0 in stage 1.2 (TID 1198) in 4176520 ms on 192.168.33.10 (executor 7) (109/111)
18/09/26 15:32:02 INFO TaskSetManager: Finished task 37.0 in stage 1.2 (TID 1157) in 4249674 ms on 192.168.33.10 (executor 7) (110/111)
18/09/26 15:53:17 INFO TaskSetManager: Finished task 66.0 in stage 1.2 (TID 1186) in 5524084 ms on 192.168.33.10 (executor 7) (111/111)
18/09/26 15:53:17 INFO TaskSchedulerImpl: Removed TaskSet 1.2, whose tasks have all completed, from pool 
18/09/26 15:53:17 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) finished in 5527,781 s
18/09/26 15:53:17 INFO DAGScheduler: looking for newly runnable stages
18/09/26 15:53:17 INFO DAGScheduler: running: Set()
18/09/26 15:53:17 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 15:53:17 INFO DAGScheduler: failed: Set()
18/09/26 15:53:17 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16), which has no missing parents
18/09/26 15:53:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.2 KB, free 365.9 MB)
18/09/26 15:53:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1881.0 B, free 365.9 MB)
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.10:43403 (size: 1881.0 B, free: 366.3 MB)
18/09/26 15:53:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/09/26 15:53:17 INFO DAGScheduler: Submitting 409 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
18/09/26 15:53:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 409 tasks
18/09/26 15:53:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1231, 192.168.33.15, executor 6, partition 0, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 25.0 in stage 2.0 (TID 1232, 192.168.33.12, executor 3, partition 25, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 1233, 192.168.33.14, executor 4, partition 4, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 65.0 in stage 2.0 (TID 1234, 192.168.33.10, executor 7, partition 65, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 28.0 in stage 2.0 (TID 1235, 192.168.33.13, executor 2, partition 28, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 27.0 in stage 2.0 (TID 1236, 192.168.33.11, executor 5, partition 27, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 1237, 192.168.33.15, executor 6, partition 1, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 30.0 in stage 2.0 (TID 1238, 192.168.33.12, executor 3, partition 30, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 1239, 192.168.33.14, executor 4, partition 5, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 69.0 in stage 2.0 (TID 1240, 192.168.33.10, executor 7, partition 69, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 33.0 in stage 2.0 (TID 1241, 192.168.33.13, executor 2, partition 33, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 32.0 in stage 2.0 (TID 1242, 192.168.33.11, executor 5, partition 32, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 1243, 192.168.33.15, executor 6, partition 2, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 35.0 in stage 2.0 (TID 1244, 192.168.33.12, executor 3, partition 35, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 1245, 192.168.33.14, executor 4, partition 6, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 73.0 in stage 2.0 (TID 1246, 192.168.33.10, executor 7, partition 73, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 38.0 in stage 2.0 (TID 1247, 192.168.33.13, executor 2, partition 38, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 37.0 in stage 2.0 (TID 1248, 192.168.33.11, executor 5, partition 37, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 1249, 192.168.33.15, executor 6, partition 3, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 40.0 in stage 2.0 (TID 1250, 192.168.33.12, executor 3, partition 40, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 1251, 192.168.33.14, executor 4, partition 9, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 77.0 in stage 2.0 (TID 1252, 192.168.33.10, executor 7, partition 77, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 43.0 in stage 2.0 (TID 1253, 192.168.33.13, executor 2, partition 43, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 42.0 in stage 2.0 (TID 1254, 192.168.33.11, executor 5, partition 42, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 1255, 192.168.33.15, executor 6, partition 7, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 45.0 in stage 2.0 (TID 1256, 192.168.33.12, executor 3, partition 45, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 1257, 192.168.33.14, executor 4, partition 10, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 114.0 in stage 2.0 (TID 1258, 192.168.33.10, executor 7, partition 114, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 48.0 in stage 2.0 (TID 1259, 192.168.33.13, executor 2, partition 48, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 47.0 in stage 2.0 (TID 1260, 192.168.33.11, executor 5, partition 47, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 1261, 192.168.33.15, executor 6, partition 8, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 50.0 in stage 2.0 (TID 1262, 192.168.33.12, executor 3, partition 50, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 1263, 192.168.33.14, executor 4, partition 11, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 127.0 in stage 2.0 (TID 1264, 192.168.33.10, executor 7, partition 127, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 53.0 in stage 2.0 (TID 1265, 192.168.33.13, executor 2, partition 53, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 52.0 in stage 2.0 (TID 1266, 192.168.33.11, executor 5, partition 52, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 12.0 in stage 2.0 (TID 1267, 192.168.33.15, executor 6, partition 12, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 55.0 in stage 2.0 (TID 1268, 192.168.33.12, executor 3, partition 55, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 20.0 in stage 2.0 (TID 1269, 192.168.33.14, executor 4, partition 20, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 150.0 in stage 2.0 (TID 1270, 192.168.33.10, executor 7, partition 150, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 58.0 in stage 2.0 (TID 1271, 192.168.33.13, executor 2, partition 58, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 57.0 in stage 2.0 (TID 1272, 192.168.33.11, executor 5, partition 57, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 13.0 in stage 2.0 (TID 1273, 192.168.33.15, executor 6, partition 13, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 60.0 in stage 2.0 (TID 1274, 192.168.33.12, executor 3, partition 60, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 23.0 in stage 2.0 (TID 1275, 192.168.33.14, executor 4, partition 23, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 159.0 in stage 2.0 (TID 1276, 192.168.33.10, executor 7, partition 159, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 63.0 in stage 2.0 (TID 1277, 192.168.33.13, executor 2, partition 63, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 62.0 in stage 2.0 (TID 1278, 192.168.33.11, executor 5, partition 62, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 14.0 in stage 2.0 (TID 1279, 192.168.33.15, executor 6, partition 14, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 170.0 in stage 2.0 (TID 1280, 192.168.33.10, executor 7, partition 170, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 15.0 in stage 2.0 (TID 1281, 192.168.33.15, executor 6, partition 15, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 171.0 in stage 2.0 (TID 1282, 192.168.33.10, executor 7, partition 171, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 16.0 in stage 2.0 (TID 1283, 192.168.33.15, executor 6, partition 16, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 172.0 in stage 2.0 (TID 1284, 192.168.33.10, executor 7, partition 172, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 17.0 in stage 2.0 (TID 1285, 192.168.33.15, executor 6, partition 17, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 182.0 in stage 2.0 (TID 1286, 192.168.33.10, executor 7, partition 182, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 18.0 in stage 2.0 (TID 1287, 192.168.33.15, executor 6, partition 18, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 190.0 in stage 2.0 (TID 1288, 192.168.33.10, executor 7, partition 190, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 19.0 in stage 2.0 (TID 1289, 192.168.33.15, executor 6, partition 19, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 197.0 in stage 2.0 (TID 1290, 192.168.33.10, executor 7, partition 197, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 21.0 in stage 2.0 (TID 1291, 192.168.33.15, executor 6, partition 21, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 203.0 in stage 2.0 (TID 1292, 192.168.33.10, executor 7, partition 203, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 22.0 in stage 2.0 (TID 1293, 192.168.33.15, executor 6, partition 22, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 204.0 in stage 2.0 (TID 1294, 192.168.33.10, executor 7, partition 204, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 24.0 in stage 2.0 (TID 1295, 192.168.33.15, executor 6, partition 24, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 206.0 in stage 2.0 (TID 1296, 192.168.33.10, executor 7, partition 206, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 29.0 in stage 2.0 (TID 1297, 192.168.33.15, executor 6, partition 29, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 208.0 in stage 2.0 (TID 1298, 192.168.33.10, executor 7, partition 208, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 34.0 in stage 2.0 (TID 1299, 192.168.33.15, executor 6, partition 34, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 212.0 in stage 2.0 (TID 1300, 192.168.33.10, executor 7, partition 212, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 39.0 in stage 2.0 (TID 1301, 192.168.33.15, executor 6, partition 39, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 218.0 in stage 2.0 (TID 1302, 192.168.33.10, executor 7, partition 218, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 44.0 in stage 2.0 (TID 1303, 192.168.33.15, executor 6, partition 44, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 220.0 in stage 2.0 (TID 1304, 192.168.33.10, executor 7, partition 220, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 49.0 in stage 2.0 (TID 1305, 192.168.33.15, executor 6, partition 49, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 221.0 in stage 2.0 (TID 1306, 192.168.33.10, executor 7, partition 221, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 54.0 in stage 2.0 (TID 1307, 192.168.33.15, executor 6, partition 54, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 224.0 in stage 2.0 (TID 1308, 192.168.33.10, executor 7, partition 224, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 59.0 in stage 2.0 (TID 1309, 192.168.33.15, executor 6, partition 59, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO TaskSetManager: Starting task 227.0 in stage 2.0 (TID 1310, 192.168.33.10, executor 7, partition 227, NODE_LOCAL, 4614 bytes)
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.11:38333 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.15:41164 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.13:33570 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.10:38790 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.15:57102
18/09/26 15:53:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 2997 bytes
18/09/26 15:53:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.10:41482
18/09/26 15:53:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.12:35074 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.13:43042
18/09/26 15:53:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.11:43502
18/09/26 15:53:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.12:37794
18/09/26 15:53:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.14:34961 (size: 1881.0 B, free: 15.8 GB)
18/09/26 15:53:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.14:37206
18/09/26 16:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.10:43403 in memory (size: 1836.0 B, free: 366.3 MB)
18/09/26 16:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.12:35074 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.11:38333 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.13:33570 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:13:32 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.14:34961 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:13:54 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.15:41164 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:16:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.10:38790 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:25:02 INFO TaskSetManager: Starting task 66.0 in stage 2.0 (TID 1311, 192.168.33.11, executor 5, partition 66, NODE_LOCAL, 4614 bytes)
18/09/26 16:25:02 INFO TaskSetManager: Finished task 32.0 in stage 2.0 (TID 1242) in 1905055 ms on 192.168.33.11 (executor 5) (1/409)
18/09/26 16:31:21 INFO TaskSetManager: Starting task 64.0 in stage 2.0 (TID 1312, 192.168.33.13, executor 2, partition 64, NODE_LOCAL, 4614 bytes)
18/09/26 16:31:21 INFO TaskSetManager: Finished task 58.0 in stage 2.0 (TID 1271) in 2284567 ms on 192.168.33.13 (executor 2) (2/409)
18/09/26 16:34:16 INFO TaskSetManager: Starting task 26.0 in stage 2.0 (TID 1313, 192.168.33.10, executor 7, partition 26, ANY, 4614 bytes)
18/09/26 16:34:16 WARN TaskSetManager: Lost task 182.0 in stage 2.0 (TID 1286, 192.168.33.10, executor 7): java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:163)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)

18/09/26 16:35:33 ERROR TaskSchedulerImpl: Lost executor 7 on 192.168.33.10: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 221.0 in stage 2.0 (TID 1306, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 73.0 in stage 2.0 (TID 1246, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 212.0 in stage 2.0 (TID 1300, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 171.0 in stage 2.0 (TID 1282, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 127.0 in stage 2.0 (TID 1264, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 159.0 in stage 2.0 (TID 1276, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 69.0 in stage 2.0 (TID 1240, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 204.0 in stage 2.0 (TID 1294, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 114.0 in stage 2.0 (TID 1258, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 190.0 in stage 2.0 (TID 1288, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 65.0 in stage 2.0 (TID 1234, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 150.0 in stage 2.0 (TID 1270, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 77.0 in stage 2.0 (TID 1252, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 206.0 in stage 2.0 (TID 1296, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 224.0 in stage 2.0 (TID 1308, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 197.0 in stage 2.0 (TID 1290, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 172.0 in stage 2.0 (TID 1284, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 218.0 in stage 2.0 (TID 1302, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 203.0 in stage 2.0 (TID 1292, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 227.0 in stage 2.0 (TID 1310, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 26.0 in stage 2.0 (TID 1313, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 220.0 in stage 2.0 (TID 1304, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 208.0 in stage 2.0 (TID 1298, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 WARN TaskSetManager: Lost task 170.0 in stage 2.0 (TID 1280, 192.168.33.10, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
18/09/26 16:35:33 INFO DAGScheduler: Executor lost: 7 (epoch 103)
18/09/26 16:35:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
18/09/26 16:35:33 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(7, 192.168.33.10, 38790, None)
18/09/26 16:35:33 INFO BlockManagerMaster: Removed 7 successfully in removeExecutor
18/09/26 16:35:33 INFO DAGScheduler: Shuffle files lost for executor: 7 (epoch 103)
18/09/26 16:35:33 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 7 (385/409, false)
18/09/26 16:35:33 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 7 (385/409, false)
18/09/26 16:35:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/7 is now EXITED (Command exited with code 52)
18/09/26 16:35:33 INFO StandaloneSchedulerBackend: Executor app-20180926111330-0006/7 removed: Command exited with code 52
18/09/26 16:35:33 INFO BlockManagerMaster: Removal of executor 7 requested
18/09/26 16:35:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
18/09/26 16:35:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 7
18/09/26 16:35:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180926111330-0006/8 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/26 16:35:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20180926111330-0006/8 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/26 16:35:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180926111330-0006/8 is now RUNNING
18/09/26 16:35:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:44126) with ID 8
18/09/26 16:35:35 INFO TaskSetManager: Starting task 170.1 in stage 2.0 (TID 1314, 192.168.33.10, executor 8, partition 170, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 208.1 in stage 2.0 (TID 1315, 192.168.33.10, executor 8, partition 208, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 220.1 in stage 2.0 (TID 1316, 192.168.33.10, executor 8, partition 220, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 227.1 in stage 2.0 (TID 1317, 192.168.33.10, executor 8, partition 227, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 203.1 in stage 2.0 (TID 1318, 192.168.33.10, executor 8, partition 203, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 218.1 in stage 2.0 (TID 1319, 192.168.33.10, executor 8, partition 218, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 172.1 in stage 2.0 (TID 1320, 192.168.33.10, executor 8, partition 172, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 197.1 in stage 2.0 (TID 1321, 192.168.33.10, executor 8, partition 197, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 224.1 in stage 2.0 (TID 1322, 192.168.33.10, executor 8, partition 224, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 206.1 in stage 2.0 (TID 1323, 192.168.33.10, executor 8, partition 206, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 77.1 in stage 2.0 (TID 1324, 192.168.33.10, executor 8, partition 77, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 150.1 in stage 2.0 (TID 1325, 192.168.33.10, executor 8, partition 150, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 65.1 in stage 2.0 (TID 1326, 192.168.33.10, executor 8, partition 65, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 190.1 in stage 2.0 (TID 1327, 192.168.33.10, executor 8, partition 190, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 114.1 in stage 2.0 (TID 1328, 192.168.33.10, executor 8, partition 114, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 204.1 in stage 2.0 (TID 1329, 192.168.33.10, executor 8, partition 204, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 69.1 in stage 2.0 (TID 1330, 192.168.33.10, executor 8, partition 69, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 159.1 in stage 2.0 (TID 1331, 192.168.33.10, executor 8, partition 159, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 127.1 in stage 2.0 (TID 1332, 192.168.33.10, executor 8, partition 127, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 171.1 in stage 2.0 (TID 1333, 192.168.33.10, executor 8, partition 171, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 212.1 in stage 2.0 (TID 1334, 192.168.33.10, executor 8, partition 212, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 73.1 in stage 2.0 (TID 1335, 192.168.33.10, executor 8, partition 73, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 221.1 in stage 2.0 (TID 1336, 192.168.33.10, executor 8, partition 221, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO TaskSetManager: Starting task 182.1 in stage 2.0 (TID 1337, 192.168.33.10, executor 8, partition 182, NODE_LOCAL, 4614 bytes)
18/09/26 16:35:35 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:40404 with 15.8 GB RAM, BlockManagerId(8, 192.168.33.10, 40404, None)
18/09/26 16:35:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.10:40404 (size: 1881.0 B, free: 15.8 GB)
18/09/26 16:35:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.10:44126
18/09/26 16:35:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 2856 bytes
18/09/26 16:35:37 WARN TaskSetManager: Lost task 69.1 in stage 2.0 (TID 1330, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=69, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 69.1 in stage 2.0 (TID 1330) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 INFO DAGScheduler: Marking ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) as failed due to a fetch failure from ShuffleMapStage 1 (flatMap at Partitioning.scala:78)
18/09/26 16:35:37 INFO DAGScheduler: ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) failed in 2540,290 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/26 16:35:37 INFO DAGScheduler: Resubmitting ShuffleMapStage 1 (flatMap at Partitioning.scala:78) and ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) due to fetch failure
18/09/26 16:35:37 WARN TaskSetManager: Lost task 182.1 in stage 2.0 (TID 1337, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=182, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 182.1 in stage 2.0 (TID 1337) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 203.1 in stage 2.0 (TID 1318, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=203, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 203.1 in stage 2.0 (TID 1318) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 114.1 in stage 2.0 (TID 1328, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=114, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 114.1 in stage 2.0 (TID 1328) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 73.1 in stage 2.0 (TID 1335, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=73, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 73.1 in stage 2.0 (TID 1335) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 171.1 in stage 2.0 (TID 1333, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=171, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 171.1 in stage 2.0 (TID 1333) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 170.1 in stage 2.0 (TID 1314, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=170, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 170.1 in stage 2.0 (TID 1314) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 150.1 in stage 2.0 (TID 1325, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=150, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 150.1 in stage 2.0 (TID 1325) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 204.1 in stage 2.0 (TID 1329, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=204, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 204.1 in stage 2.0 (TID 1329) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 77.1 in stage 2.0 (TID 1324, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=77, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 77.1 in stage 2.0 (TID 1324) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 208.1 in stage 2.0 (TID 1315, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=208, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 208.1 in stage 2.0 (TID 1315) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 127.1 in stage 2.0 (TID 1332, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=127, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 127.1 in stage 2.0 (TID 1332) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 197.1 in stage 2.0 (TID 1321, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=197, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 197.1 in stage 2.0 (TID 1321) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 224.1 in stage 2.0 (TID 1322, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=224, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 224.1 in stage 2.0 (TID 1322) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 227.1 in stage 2.0 (TID 1317, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=227, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 227.1 in stage 2.0 (TID 1317) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 212.1 in stage 2.0 (TID 1334, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=212, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 212.1 in stage 2.0 (TID 1334) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 172.1 in stage 2.0 (TID 1320, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=172, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 172.1 in stage 2.0 (TID 1320) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 221.1 in stage 2.0 (TID 1336, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=221, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 221.1 in stage 2.0 (TID 1336) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 65.1 in stage 2.0 (TID 1326, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=65, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 65.1 in stage 2.0 (TID 1326) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 218.1 in stage 2.0 (TID 1319, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=218, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 218.1 in stage 2.0 (TID 1319) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 206.1 in stage 2.0 (TID 1323, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=206, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 206.1 in stage 2.0 (TID 1323) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 220.1 in stage 2.0 (TID 1316, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=220, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 220.1 in stage 2.0 (TID 1316) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 159.1 in stage 2.0 (TID 1331, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=159, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 159.1 in stage 2.0 (TID 1331) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 WARN TaskSetManager: Lost task 190.1 in stage 2.0 (TID 1327, 192.168.33.10, executor 8): FetchFailed(null, shuffleId=4, mapId=-1, reduceId=190, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
18/09/26 16:35:37 INFO TaskSetManager: Task 190.1 in stage 2.0 (TID 1327) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
18/09/26 16:35:37 INFO DAGScheduler: Resubmitting failed stages
18/09/26 16:35:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/26 16:35:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 4.3 KB, free 365.9 MB)
18/09/26 16:35:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/26 16:35:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.33.10:43403 (size: 2.5 KB, free: 366.3 MB)
18/09/26 16:35:37 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/09/26 16:35:37 INFO DAGScheduler: Submitting 24 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75))
18/09/26 16:35:37 INFO TaskSchedulerImpl: Adding task set 0.3 with 24 tasks
18/09/26 16:35:37 INFO TaskSetManager: Starting task 0.0 in stage 0.3 (TID 1338, 192.168.33.10, executor 8, partition 47, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 1.0 in stage 0.3 (TID 1339, 192.168.33.10, executor 8, partition 49, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 2.0 in stage 0.3 (TID 1340, 192.168.33.10, executor 8, partition 51, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 3.0 in stage 0.3 (TID 1341, 192.168.33.10, executor 8, partition 53, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 4.0 in stage 0.3 (TID 1342, 192.168.33.10, executor 8, partition 55, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 5.0 in stage 0.3 (TID 1343, 192.168.33.10, executor 8, partition 57, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 6.0 in stage 0.3 (TID 1344, 192.168.33.10, executor 8, partition 59, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 7.0 in stage 0.3 (TID 1345, 192.168.33.10, executor 8, partition 61, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 8.0 in stage 0.3 (TID 1346, 192.168.33.10, executor 8, partition 63, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 9.0 in stage 0.3 (TID 1347, 192.168.33.10, executor 8, partition 65, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 10.0 in stage 0.3 (TID 1348, 192.168.33.10, executor 8, partition 67, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 11.0 in stage 0.3 (TID 1349, 192.168.33.10, executor 8, partition 69, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 12.0 in stage 0.3 (TID 1350, 192.168.33.10, executor 8, partition 71, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 13.0 in stage 0.3 (TID 1351, 192.168.33.10, executor 8, partition 73, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 14.0 in stage 0.3 (TID 1352, 192.168.33.10, executor 8, partition 75, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 15.0 in stage 0.3 (TID 1353, 192.168.33.10, executor 8, partition 77, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 16.0 in stage 0.3 (TID 1354, 192.168.33.10, executor 8, partition 79, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 17.0 in stage 0.3 (TID 1355, 192.168.33.10, executor 8, partition 157, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 18.0 in stage 0.3 (TID 1356, 192.168.33.10, executor 8, partition 168, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 19.0 in stage 0.3 (TID 1357, 192.168.33.10, executor 8, partition 169, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 20.0 in stage 0.3 (TID 1358, 192.168.33.10, executor 8, partition 171, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 21.0 in stage 0.3 (TID 1359, 192.168.33.10, executor 8, partition 172, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 22.0 in stage 0.3 (TID 1360, 192.168.33.10, executor 8, partition 173, ANY, 4879 bytes)
18/09/26 16:35:37 INFO TaskSetManager: Starting task 23.0 in stage 0.3 (TID 1361, 192.168.33.10, executor 8, partition 174, ANY, 4879 bytes)
18/09/26 16:35:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.33.10:40404 (size: 2.5 KB, free: 15.8 GB)
18/09/26 16:35:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:40404 (size: 27.9 KB, free: 15.8 GB)
18/09/26 16:36:13 INFO TaskSetManager: Finished task 2.0 in stage 0.3 (TID 1340) in 35616 ms on 192.168.33.10 (executor 8) (1/24)
18/09/26 16:36:14 INFO TaskSetManager: Finished task 4.0 in stage 0.3 (TID 1342) in 36549 ms on 192.168.33.10 (executor 8) (2/24)
18/09/26 16:36:14 INFO TaskSetManager: Finished task 19.0 in stage 0.3 (TID 1357) in 36962 ms on 192.168.33.10 (executor 8) (3/24)
18/09/26 16:36:16 INFO TaskSetManager: Finished task 17.0 in stage 0.3 (TID 1355) in 38781 ms on 192.168.33.10 (executor 8) (4/24)
18/09/26 16:36:17 INFO TaskSetManager: Finished task 9.0 in stage 0.3 (TID 1347) in 39484 ms on 192.168.33.10 (executor 8) (5/24)
18/09/26 16:36:17 INFO TaskSetManager: Finished task 3.0 in stage 0.3 (TID 1341) in 39500 ms on 192.168.33.10 (executor 8) (6/24)
18/09/26 16:36:17 INFO TaskSetManager: Finished task 10.0 in stage 0.3 (TID 1348) in 39956 ms on 192.168.33.10 (executor 8) (7/24)
18/09/26 16:36:18 INFO TaskSetManager: Finished task 8.0 in stage 0.3 (TID 1346) in 40416 ms on 192.168.33.10 (executor 8) (8/24)
18/09/26 16:36:18 INFO TaskSetManager: Finished task 7.0 in stage 0.3 (TID 1345) in 40476 ms on 192.168.33.10 (executor 8) (9/24)
18/09/26 16:36:18 INFO TaskSetManager: Finished task 23.0 in stage 0.3 (TID 1361) in 40890 ms on 192.168.33.10 (executor 8) (10/24)
18/09/26 16:36:18 INFO TaskSetManager: Finished task 11.0 in stage 0.3 (TID 1349) in 41027 ms on 192.168.33.10 (executor 8) (11/24)
18/09/26 16:36:18 INFO TaskSetManager: Finished task 5.0 in stage 0.3 (TID 1343) in 41028 ms on 192.168.33.10 (executor 8) (12/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 16.0 in stage 0.3 (TID 1354) in 41113 ms on 192.168.33.10 (executor 8) (13/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 15.0 in stage 0.3 (TID 1353) in 41370 ms on 192.168.33.10 (executor 8) (14/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 6.0 in stage 0.3 (TID 1344) in 41452 ms on 192.168.33.10 (executor 8) (15/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 22.0 in stage 0.3 (TID 1360) in 41472 ms on 192.168.33.10 (executor 8) (16/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 0.0 in stage 0.3 (TID 1338) in 41656 ms on 192.168.33.10 (executor 8) (17/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 1.0 in stage 0.3 (TID 1339) in 41696 ms on 192.168.33.10 (executor 8) (18/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 12.0 in stage 0.3 (TID 1350) in 41694 ms on 192.168.33.10 (executor 8) (19/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 20.0 in stage 0.3 (TID 1358) in 41879 ms on 192.168.33.10 (executor 8) (20/24)
18/09/26 16:36:19 INFO TaskSetManager: Finished task 18.0 in stage 0.3 (TID 1356) in 41950 ms on 192.168.33.10 (executor 8) (21/24)
18/09/26 16:36:20 INFO TaskSetManager: Finished task 21.0 in stage 0.3 (TID 1359) in 42175 ms on 192.168.33.10 (executor 8) (22/24)
18/09/26 16:36:20 INFO TaskSetManager: Finished task 13.0 in stage 0.3 (TID 1351) in 42723 ms on 192.168.33.10 (executor 8) (23/24)
18/09/26 16:36:21 INFO TaskSetManager: Finished task 14.0 in stage 0.3 (TID 1352) in 43241 ms on 192.168.33.10 (executor 8) (24/24)
18/09/26 16:36:21 INFO TaskSchedulerImpl: Removed TaskSet 0.3, whose tasks have all completed, from pool 
18/09/26 16:36:21 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 43,244 s
18/09/26 16:36:21 INFO DAGScheduler: looking for newly runnable stages
18/09/26 16:36:21 INFO DAGScheduler: running: Set()
18/09/26 16:36:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 16:36:21 INFO DAGScheduler: failed: Set()
18/09/26 16:36:21 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/26 16:36:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/26 16:36:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1836.0 B, free 365.9 MB)
18/09/26 16:36:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.33.10:43403 (size: 1836.0 B, free: 366.3 MB)
18/09/26 16:36:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/09/26 16:36:21 INFO DAGScheduler: Submitting 24 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(65, 69, 73, 77, 114, 127, 150, 159, 170, 171, 172, 182, 190, 197, 203))
18/09/26 16:36:21 INFO TaskSchedulerImpl: Adding task set 1.3 with 24 tasks
18/09/26 16:36:24 INFO TaskSetManager: Starting task 0.0 in stage 1.3 (TID 1362, 192.168.33.10, executor 8, partition 65, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 1.0 in stage 1.3 (TID 1363, 192.168.33.10, executor 8, partition 69, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 2.0 in stage 1.3 (TID 1364, 192.168.33.10, executor 8, partition 73, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 3.0 in stage 1.3 (TID 1365, 192.168.33.10, executor 8, partition 77, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 4.0 in stage 1.3 (TID 1366, 192.168.33.10, executor 8, partition 114, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 5.0 in stage 1.3 (TID 1367, 192.168.33.10, executor 8, partition 127, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 6.0 in stage 1.3 (TID 1368, 192.168.33.10, executor 8, partition 150, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 7.0 in stage 1.3 (TID 1369, 192.168.33.10, executor 8, partition 159, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 8.0 in stage 1.3 (TID 1370, 192.168.33.10, executor 8, partition 170, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 9.0 in stage 1.3 (TID 1371, 192.168.33.10, executor 8, partition 171, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 10.0 in stage 1.3 (TID 1372, 192.168.33.10, executor 8, partition 172, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 11.0 in stage 1.3 (TID 1373, 192.168.33.10, executor 8, partition 182, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 12.0 in stage 1.3 (TID 1374, 192.168.33.10, executor 8, partition 190, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 13.0 in stage 1.3 (TID 1375, 192.168.33.10, executor 8, partition 197, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 14.0 in stage 1.3 (TID 1376, 192.168.33.10, executor 8, partition 203, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 15.0 in stage 1.3 (TID 1377, 192.168.33.10, executor 8, partition 204, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 16.0 in stage 1.3 (TID 1378, 192.168.33.10, executor 8, partition 206, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 17.0 in stage 1.3 (TID 1379, 192.168.33.10, executor 8, partition 208, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 18.0 in stage 1.3 (TID 1380, 192.168.33.10, executor 8, partition 212, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 19.0 in stage 1.3 (TID 1381, 192.168.33.10, executor 8, partition 218, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 20.0 in stage 1.3 (TID 1382, 192.168.33.10, executor 8, partition 220, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 21.0 in stage 1.3 (TID 1383, 192.168.33.10, executor 8, partition 221, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 22.0 in stage 1.3 (TID 1384, 192.168.33.10, executor 8, partition 224, ANY, 4614 bytes)
18/09/26 16:36:24 INFO TaskSetManager: Starting task 23.0 in stage 1.3 (TID 1385, 192.168.33.10, executor 8, partition 227, ANY, 4614 bytes)
18/09/26 16:36:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.33.10:40404 (size: 1836.0 B, free: 15.8 GB)
18/09/26 16:36:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.10:44126
18/09/26 16:36:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 92486 bytes
18/09/26 16:42:22 INFO TaskSetManager: Finished task 9.0 in stage 1.3 (TID 1371) in 358712 ms on 192.168.33.10 (executor 8) (1/24)
18/09/26 16:43:32 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.33.10:43403 in memory (size: 2.5 KB, free: 366.3 MB)
18/09/26 16:43:32 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.33.10:40404 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/26 16:43:41 INFO TaskSetManager: Finished task 5.0 in stage 1.3 (TID 1367) in 437080 ms on 192.168.33.10 (executor 8) (2/24)
18/09/26 16:44:03 INFO TaskSetManager: Finished task 2.0 in stage 1.3 (TID 1364) in 459619 ms on 192.168.33.10 (executor 8) (3/24)
18/09/26 16:45:00 INFO TaskSetManager: Finished task 20.0 in stage 1.3 (TID 1382) in 516387 ms on 192.168.33.10 (executor 8) (4/24)
18/09/26 16:45:19 INFO TaskSetManager: Finished task 0.0 in stage 1.3 (TID 1362) in 535333 ms on 192.168.33.10 (executor 8) (5/24)
18/09/26 16:48:03 INFO TaskSetManager: Finished task 13.0 in stage 1.3 (TID 1375) in 698951 ms on 192.168.33.10 (executor 8) (6/24)
18/09/26 16:49:39 INFO TaskSetManager: Finished task 12.0 in stage 1.3 (TID 1374) in 795688 ms on 192.168.33.10 (executor 8) (7/24)
18/09/26 16:50:26 INFO TaskSetManager: Finished task 3.0 in stage 1.3 (TID 1365) in 841818 ms on 192.168.33.10 (executor 8) (8/24)
18/09/26 16:50:31 INFO TaskSetManager: Finished task 11.0 in stage 1.3 (TID 1373) in 847649 ms on 192.168.33.10 (executor 8) (9/24)
18/09/26 16:52:44 INFO TaskSetManager: Finished task 23.0 in stage 1.3 (TID 1385) in 980699 ms on 192.168.33.10 (executor 8) (10/24)
18/09/26 16:53:05 INFO TaskSetManager: Finished task 21.0 in stage 1.3 (TID 1383) in 1001763 ms on 192.168.33.10 (executor 8) (11/24)
18/09/26 16:54:08 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 1245) in 3651163 ms on 192.168.33.14 (executor 4) (27/409)
18/09/26 16:55:23 INFO TaskSetManager: Finished task 4.0 in stage 1.3 (TID 1366) in 1139463 ms on 192.168.33.10 (executor 8) (12/24)
18/09/26 16:55:30 INFO TaskSetManager: Finished task 14.0 in stage 1.3 (TID 1376) in 1146169 ms on 192.168.33.10 (executor 8) (13/24)
18/09/26 16:57:46 INFO TaskSetManager: Finished task 17.0 in stage 1.3 (TID 1379) in 1282061 ms on 192.168.33.10 (executor 8) (14/24)
18/09/26 17:01:27 INFO TaskSetManager: Finished task 22.0 in stage 1.3 (TID 1384) in 1503078 ms on 192.168.33.10 (executor 8) (15/24)
18/09/26 17:02:24 INFO TaskSetManager: Finished task 1.0 in stage 1.3 (TID 1363) in 1560506 ms on 192.168.33.10 (executor 8) (16/24)
18/09/26 17:02:43 INFO TaskSetManager: Finished task 6.0 in stage 1.3 (TID 1368) in 1579407 ms on 192.168.33.10 (executor 8) (17/24)
18/09/26 17:04:11 INFO TaskSetManager: Finished task 19.0 in stage 1.3 (TID 1381) in 1667403 ms on 192.168.33.10 (executor 8) (18/24)
18/09/26 17:08:39 INFO TaskSetManager: Finished task 7.0 in stage 1.3 (TID 1369) in 1935209 ms on 192.168.33.10 (executor 8) (19/24)
18/09/26 17:08:57 INFO TaskSetManager: Finished task 18.0 in stage 1.3 (TID 1380) in 1952903 ms on 192.168.33.10 (executor 8) (20/24)
18/09/26 17:09:16 INFO TaskSetManager: Finished task 8.0 in stage 1.3 (TID 1370) in 1972673 ms on 192.168.33.10 (executor 8) (21/24)
18/09/26 17:10:43 INFO TaskSetManager: Finished task 16.0 in stage 1.3 (TID 1378) in 2059470 ms on 192.168.33.10 (executor 8) (22/24)
18/09/26 17:11:02 INFO TaskSetManager: Finished task 15.0 in stage 1.3 (TID 1377) in 2078492 ms on 192.168.33.10 (executor 8) (23/24)
18/09/26 17:32:51 INFO TaskSetManager: Finished task 10.0 in stage 1.3 (TID 1372) in 3387037 ms on 192.168.33.10 (executor 8) (24/24)
18/09/26 17:32:51 INFO TaskSchedulerImpl: Removed TaskSet 1.3, whose tasks have all completed, from pool 
18/09/26 17:32:51 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) finished in 3390,087 s
18/09/26 17:32:51 INFO DAGScheduler: looking for newly runnable stages
18/09/26 17:32:51 INFO DAGScheduler: running: Set()
18/09/26 17:32:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/26 17:32:51 INFO DAGScheduler: failed: Set()
18/09/26 17:32:51 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16), which has no missing parents
18/09/26 17:32:51 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.2 KB, free 365.9 MB)
18/09/26 17:32:51 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1881.0 B, free 365.9 MB)
18/09/26 17:32:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.10:43403 (size: 1881.0 B, free: 366.3 MB)
18/09/26 17:32:51 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/09/26 17:32:51 INFO DAGScheduler: Submitting 406 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15))
18/09/26 17:32:51 INFO TaskSchedulerImpl: Adding task set 2.1 with 406 tasks
18/09/26 17:32:51 INFO TaskSetManager: Starting task 4.0 in stage 2.1 (TID 1386, 192.168.33.14, executor 4, partition 4, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 62.0 in stage 2.1 (TID 1387, 192.168.33.10, executor 8, partition 65, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 66.0 in stage 2.1 (TID 1388, 192.168.33.10, executor 8, partition 69, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 70.0 in stage 2.1 (TID 1389, 192.168.33.10, executor 8, partition 73, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 74.0 in stage 2.1 (TID 1390, 192.168.33.10, executor 8, partition 77, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 111.0 in stage 2.1 (TID 1391, 192.168.33.10, executor 8, partition 114, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 124.0 in stage 2.1 (TID 1392, 192.168.33.10, executor 8, partition 127, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 147.0 in stage 2.1 (TID 1393, 192.168.33.10, executor 8, partition 150, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 156.0 in stage 2.1 (TID 1394, 192.168.33.10, executor 8, partition 159, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 167.0 in stage 2.1 (TID 1395, 192.168.33.10, executor 8, partition 170, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 168.0 in stage 2.1 (TID 1396, 192.168.33.10, executor 8, partition 171, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 169.0 in stage 2.1 (TID 1397, 192.168.33.10, executor 8, partition 172, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 179.0 in stage 2.1 (TID 1398, 192.168.33.10, executor 8, partition 182, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 187.0 in stage 2.1 (TID 1399, 192.168.33.10, executor 8, partition 190, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 194.0 in stage 2.1 (TID 1400, 192.168.33.10, executor 8, partition 197, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 200.0 in stage 2.1 (TID 1401, 192.168.33.10, executor 8, partition 203, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 201.0 in stage 2.1 (TID 1402, 192.168.33.10, executor 8, partition 204, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 203.0 in stage 2.1 (TID 1403, 192.168.33.10, executor 8, partition 206, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 205.0 in stage 2.1 (TID 1404, 192.168.33.10, executor 8, partition 208, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 209.0 in stage 2.1 (TID 1405, 192.168.33.10, executor 8, partition 212, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 215.0 in stage 2.1 (TID 1406, 192.168.33.10, executor 8, partition 218, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 217.0 in stage 2.1 (TID 1407, 192.168.33.10, executor 8, partition 220, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 218.0 in stage 2.1 (TID 1408, 192.168.33.10, executor 8, partition 221, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 221.0 in stage 2.1 (TID 1409, 192.168.33.10, executor 8, partition 224, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO TaskSetManager: Starting task 224.0 in stage 2.1 (TID 1410, 192.168.33.10, executor 8, partition 227, NODE_LOCAL, 4614 bytes)
18/09/26 17:32:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.10:40404 (size: 1881.0 B, free: 15.8 GB)
18/09/26 17:32:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.10:44126
18/09/26 17:32:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 2998 bytes
18/09/26 17:32:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.14:34961 (size: 1881.0 B, free: 15.8 GB)
18/09/26 17:32:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.14:37206
18/09/26 17:37:01 INFO TaskSetManager: Starting task 5.0 in stage 2.1 (TID 1411, 192.168.33.14, executor 4, partition 5, NODE_LOCAL, 4614 bytes)
18/09/26 17:37:01 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 1239) in 6224043 ms on 192.168.33.14 (executor 4) (28/409)
18/09/26 17:41:32 INFO TaskSetManager: Starting task 27.0 in stage 2.1 (TID 1412, 192.168.33.13, executor 2, partition 28, NODE_LOCAL, 4614 bytes)
18/09/26 17:41:32 INFO TaskSetManager: Finished task 63.0 in stage 2.0 (TID 1277) in 6495541 ms on 192.168.33.13 (executor 2) (29/409)
18/09/26 17:41:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.13:33570 (size: 1881.0 B, free: 15.8 GB)
18/09/26 17:41:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.13:43042
18/09/26 17:43:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.33.10:43403 in memory (size: 1836.0 B, free: 366.3 MB)
18/09/26 17:43:49 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.33.10:40404 in memory (size: 1836.0 B, free: 15.8 GB)
18/09/26 17:53:20 INFO SparkContext: Invoking stop() from shutdown hook
18/09/26 17:53:20 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/26 17:53:20 INFO DAGScheduler: ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) failed in 1228,948 s due to Stage cancelled because SparkContext was shut down
18/09/26 17:53:20 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 23987,523175 s
18/09/26 17:53:20 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/26 17:53:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/26 17:53:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/26 17:53:20 INFO MemoryStore: MemoryStore cleared
18/09/26 17:53:20 INFO BlockManager: BlockManager stopped
18/09/26 17:53:20 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/26 17:53:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/26 17:53:20 INFO SparkContext: Successfully stopped SparkContext
18/09/26 17:53:20 INFO ShutdownHookManager: Shutdown hook called
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-922269ea-9a25-4509-8118-f043b8b442b0
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-b8b8111f-68cc-4cf1-b36e-7d4a979e2282
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-db6ee078-c2fd-468c-8ab2-31b82abb5c71
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-e2555a45-a7a2-4f3a-be0d-4e90e83c0618
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-ff970934-3dc8-427b-98c4-384873bc1384
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-fe5e8efc-4574-48c9-bc1c-8d0e922be690
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-e8078c63-a545-4b37-90f4-90e71c2b4860
18/09/26 17:53:20 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-dde5f2c9-a298-4dc2-84be-e9c19f01e947
18/09/28 10:02:21 INFO SparkContext: Running Spark version 2.2.1
18/09/28 10:02:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/28 10:02:22 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/28 10:02:22 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/28 10:02:22 INFO SecurityManager: Changing view acls to: redouane
18/09/28 10:02:22 INFO SecurityManager: Changing modify acls to: redouane
18/09/28 10:02:22 INFO SecurityManager: Changing view acls groups to: 
18/09/28 10:02:22 INFO SecurityManager: Changing modify acls groups to: 
18/09/28 10:02:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/28 10:02:22 INFO Utils: Successfully started service 'sparkDriver' on port 44894.
18/09/28 10:02:22 INFO SparkEnv: Registering MapOutputTracker
18/09/28 10:02:22 INFO SparkEnv: Registering BlockManagerMaster
18/09/28 10:02:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/28 10:02:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-88879c5e-ff5e-4719-b403-54586fead530
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-7d7d1bf6-3892-4667-b408-0395234d1ffd
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-079fa011-c91c-4967-97c0-a9d358f44614
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-948039b8-8827-485f-a96d-061e554ed209
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-023f7492-12dc-4b1f-abcb-e036424a0df0
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-3e80c97f-db9e-4c84-9cac-ca93bdcd1856
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-fe5b9f15-feca-447b-84f9-7754fa8b6192
18/09/28 10:02:22 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-afaab427-487b-4e7a-ba45-9ea6de07895e
18/09/28 10:02:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/28 10:02:22 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/28 10:02:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/28 10:02:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/28 10:02:22 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:44894/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1538121742994
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/28 10:02:23 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 27 ms (0 ms spent in bootstraps)
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180928100223-0011
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/28 10:02:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34899.
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/28 10:02:23 INFO NettyBlockTransferService: Server created on 192.168.33.10:34899
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/28 10:02:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100223-0011/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/28 10:02:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100223-0011/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/28 10:02:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 34899, None)
18/09/28 10:02:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:34899 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 34899, None)
18/09/28 10:02:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 34899, None)
18/09/28 10:02:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 34899, None)
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/0 is now RUNNING
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/3 is now RUNNING
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/2 is now RUNNING
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/4 is now RUNNING
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/5 is now RUNNING
18/09/28 10:02:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100223-0011/1 is now RUNNING
18/09/28 10:02:24 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180928100223-0011
18/09/28 10:02:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/28 10:02:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/28 10:02:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/28 10:02:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:34899 (size: 27.9 KB, free: 366.3 MB)
18/09/28 10:02:24 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/28 10:02:25 INFO FileInputFormat: Total input files to process : 1
18/09/28 10:02:25 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/28 10:02:25 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/28 10:02:25 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/28 10:02:25 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/28 10:02:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/28 10:02:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:43136) with ID 2
18/09/28 10:02:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:40416) with ID 4
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:57698) with ID 5
18/09/28 10:02:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/28 10:02:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/28 10:02:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:34899 (size: 2.5 KB, free: 366.3 MB)
18/09/28 10:02:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:54134) with ID 3
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:46190 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.13, 46190, None)
18/09/28 10:02:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:02:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:44901 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.14, 44901, None)
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:40333 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.11, 40333, None)
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:35496 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.12, 35496, None)
18/09/28 10:02:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.12, executor 3, partition 0, ANY, 4873 bytes)
18/09/28 10:02:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.14, executor 4, partition 1, ANY, 4873 bytes)
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:50920) with ID 0
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:42006 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 42006, None)
18/09/28 10:02:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:55542) with ID 1
18/09/28 10:02:25 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:39680 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 39680, None)
18/09/28 10:02:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.12:35496 (size: 2.5 KB, free: 15.8 GB)
18/09/28 10:02:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.12:35496 (size: 27.9 KB, free: 15.8 GB)
18/09/28 10:02:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:44901 (size: 2.5 KB, free: 15.8 GB)
18/09/28 10:02:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:44901 (size: 27.9 KB, free: 15.8 GB)
18/09/28 10:02:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11196 ms on 192.168.33.12 (executor 3) (1/2)
18/09/28 10:02:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11888 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:02:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/09/28 10:02:37 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 11,914 s
18/09/28 10:02:37 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:02:37 INFO DAGScheduler: running: Set()
18/09/28 10:02:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/28 10:02:37 INFO DAGScheduler: failed: Set()
18/09/28 10:02:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/28 10:02:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/28 10:02:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1838.0 B, free 365.9 MB)
18/09/28 10:02:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.10:34899 (size: 1838.0 B, free: 366.3 MB)
18/09/28 10:02:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/09/28 10:02:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:02:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
18/09/28 10:02:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, 192.168.33.12, executor 3, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:02:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:02:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.14:44901 (size: 1838.0 B, free: 15.8 GB)
18/09/28 10:02:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.12:35496 (size: 1838.0 B, free: 15.8 GB)
18/09/28 10:02:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:40416
18/09/28 10:02:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 163 bytes
18/09/28 10:02:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.12:54134
18/09/28 10:03:06 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 29231 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:03:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 29677 ms on 192.168.33.12 (executor 3) (2/2)
18/09/28 10:03:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/09/28 10:03:07 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) finished in 29,681 s
18/09/28 10:03:07 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:03:07 INFO DAGScheduler: running: Set()
18/09/28 10:03:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/28 10:03:07 INFO DAGScheduler: failed: Set()
18/09/28 10:03:07 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16), which has no missing parents
18/09/28 10:03:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.2 KB, free 365.9 MB)
18/09/28 10:03:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1883.0 B, free 365.9 MB)
18/09/28 10:03:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.10:34899 (size: 1883.0 B, free: 366.3 MB)
18/09/28 10:03:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/09/28 10:03:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:03:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
18/09/28 10:03:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.33.12, executor 3, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:03:07 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:03:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.12:35496 (size: 1883.0 B, free: 15.8 GB)
18/09/28 10:03:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.14:44901 (size: 1883.0 B, free: 15.8 GB)
18/09/28 10:03:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.12:54134
18/09/28 10:03:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 166 bytes
18/09/28 10:03:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.14:40416
18/09/28 10:03:41 INFO SparkContext: Invoking stop() from shutdown hook
18/09/28 10:03:41 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/28 10:03:41 INFO DAGScheduler: Job 0 failed: foreach at GlobalMerging.scala:59, took 76,530573 s
18/09/28 10:03:41 INFO DAGScheduler: ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) failed in 34,746 s due to Stage cancelled because SparkContext was shut down
18/09/28 10:03:41 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/28 10:03:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/28 10:03:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/28 10:03:41 INFO MemoryStore: MemoryStore cleared
18/09/28 10:03:41 INFO BlockManager: BlockManager stopped
18/09/28 10:03:41 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/28 10:03:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/28 10:03:41 INFO SparkContext: Successfully stopped SparkContext
18/09/28 10:03:41 INFO ShutdownHookManager: Shutdown hook called
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-21735c28-7847-4738-b63c-dc948c2eea3c
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-1ed9c6e5-e1e8-47b8-8014-bdb764ee2ceb
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-3701d435-8a58-43d6-997f-ddde1d914bda
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-b6ee0e24-865b-4351-bc62-2c760491a6f6
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-5f4e8a8e-eea0-4b91-aed3-9eb45e545a7f
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-bb8966e2-f8b0-4c1c-a578-8a49bbd65bb1
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-54410333-25b2-40d7-bf07-70e34b4e4d63
18/09/28 10:03:41 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-0c753e4a-f94d-4f45-93be-e4ec8195b271
18/09/28 10:03:51 INFO SparkContext: Running Spark version 2.2.1
18/09/28 10:03:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/28 10:03:52 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
18/09/28 10:03:52 INFO SparkContext: Submitted application: SC_DBSCAN
18/09/28 10:03:52 INFO SecurityManager: Changing view acls to: redouane
18/09/28 10:03:52 INFO SecurityManager: Changing modify acls to: redouane
18/09/28 10:03:52 INFO SecurityManager: Changing view acls groups to: 
18/09/28 10:03:52 INFO SecurityManager: Changing modify acls groups to: 
18/09/28 10:03:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(redouane); groups with view permissions: Set(); users  with modify permissions: Set(redouane); groups with modify permissions: Set()
18/09/28 10:03:52 INFO Utils: Successfully started service 'sparkDriver' on port 41751.
18/09/28 10:03:52 INFO SparkEnv: Registering MapOutputTracker
18/09/28 10:03:52 INFO SparkEnv: Registering BlockManagerMaster
18/09/28 10:03:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/28 10:03:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data0/store/spark-local/blockmgr-4dac2214-9d4b-48c6-89c4-494f2dc2af1f
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data1/store/spark-local/blockmgr-b9369810-0ce3-4a5f-a94a-18e1c1063ed8
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data2/store/spark-local/blockmgr-f1ce402e-9a92-4edb-9540-675d937adf34
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data3/store/spark-local/blockmgr-ad016df1-f3ea-4d37-9ac7-c94d7b7835c5
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data4/store/spark-local/blockmgr-17b720c6-7861-444e-863e-6a9e373628fd
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data5/store/spark-local/blockmgr-6b382215-d44d-43d3-971c-b41833400ef1
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data6/store/spark-local/blockmgr-89752cef-3ae6-4955-b63e-f00258fa0e8c
18/09/28 10:03:53 INFO DiskBlockManager: Created local directory at /data7/store/spark-local/blockmgr-7619637d-8309-430d-b04c-6d1ab59e7d0a
18/09/28 10:03:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/28 10:03:53 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/28 10:03:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/28 10:03:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.33.10:4040
18/09/28 10:03:53 INFO SparkContext: Added JAR file:/home/redouane/programmes/tests/SC_DBSCAN-master/target/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar at spark://192.168.33.10:41751/jars/sc_dbscan-0.0.1-SNAPSHOT-jar-with-dependencies.jar with timestamp 1538121833471
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://sc-spark.adam.uvsq.fr:7077...
18/09/28 10:03:53 INFO TransportClientFactory: Successfully created connection to sc-spark.adam.uvsq.fr/192.168.33.10:7077 after 30 ms (0 ms spent in bootstraps)
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20180928100353-0012
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/0 on worker-20180926101829-192.168.33.15-39979 (192.168.33.15:39979) with 24 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/0 on hostPort 192.168.33.15:39979 with 24 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/1 on worker-20180926101829-192.168.33.10-37214 (192.168.33.10:37214) with 24 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/1 on hostPort 192.168.33.10:37214 with 24 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/2 on worker-20180926101829-192.168.33.13-37617 (192.168.33.13:37617) with 8 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/2 on hostPort 192.168.33.13:37617 with 8 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/3 on worker-20180926101828-192.168.33.12-42538 (192.168.33.12:42538) with 8 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/3 on hostPort 192.168.33.12:42538 with 8 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/4 on worker-20180926101829-192.168.33.14-40938 (192.168.33.14:40938) with 8 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/4 on hostPort 192.168.33.14:40938 with 8 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20180928100353-0012/5 on worker-20180926101829-192.168.33.11-37947 (192.168.33.11:37947) with 8 cores
18/09/28 10:03:53 INFO StandaloneSchedulerBackend: Granted executor ID app-20180928100353-0012/5 on hostPort 192.168.33.11:37947 with 8 cores, 30.0 GB RAM
18/09/28 10:03:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37041.
18/09/28 10:03:53 INFO NettyBlockTransferService: Server created on 192.168.33.10:37041
18/09/28 10:03:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/28 10:03:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.33.10, 37041, None)
18/09/28 10:03:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:37041 with 366.3 MB RAM, BlockManagerId(driver, 192.168.33.10, 37041, None)
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/5 is now RUNNING
18/09/28 10:03:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.33.10, 37041, None)
18/09/28 10:03:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.33.10, 37041, None)
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/1 is now RUNNING
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/4 is now RUNNING
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/3 is now RUNNING
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/2 is now RUNNING
18/09/28 10:03:53 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180928100353-0012/0 is now RUNNING
18/09/28 10:03:54 INFO EventLoggingListener: Logging events to hdfs://sc-hdfs.adam.uvsq.fr/tmp/logs/spark-logs/app-20180928100353-0012
18/09/28 10:03:55 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
18/09/28 10:03:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 323.9 KB, free 366.0 MB)
18/09/28 10:03:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.9 KB, free 366.0 MB)
18/09/28 10:03:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.10:37041 (size: 27.9 KB, free: 366.3 MB)
18/09/28 10:03:55 INFO SparkContext: Created broadcast 0 from textFile at Main.scala:126
18/09/28 10:03:55 INFO FileInputFormat: Total input files to process : 1
18/09/28 10:03:55 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 2 (flatMap at Partitioning.scala:52)
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 8 (flatMap at Partitioning.scala:78)
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 14 (flatMap at CoresIdentification.scala:16)
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 16 (flatMap at CoresIdentification.scala:52)
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 18 (flatMap at Clustring.scala:16)
18/09/28 10:03:55 INFO DAGScheduler: Registering RDD 20 (map at GlobalMerging.scala:37)
18/09/28 10:03:55 INFO DAGScheduler: Got job 0 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/28 10:03:55 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at GlobalMerging.scala:59)
18/09/28 10:03:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/09/28 10:03:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/09/28 10:03:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52), which has no missing parents
18/09/28 10:03:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 366.0 MB)
18/09/28 10:03:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 365.9 MB)
18/09/28 10:03:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.10:37041 (size: 2.5 KB, free: 366.3 MB)
18/09/28 10:03:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
18/09/28 10:03:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at flatMap at Partitioning.scala:52) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:03:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
18/09/28 10:03:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.14:42964) with ID 4
18/09/28 10:03:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.33.14, executor 4, partition 0, ANY, 4873 bytes)
18/09/28 10:03:55 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.33.14, executor 4, partition 1, ANY, 4873 bytes)
18/09/28 10:03:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.13:58724) with ID 2
18/09/28 10:03:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.11:33432) with ID 5
18/09/28 10:03:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.12:51074) with ID 3
18/09/28 10:03:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.15:54870) with ID 0
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.14:44520 with 15.8 GB RAM, BlockManagerId(4, 192.168.33.14, 44520, None)
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.12:41115 with 15.8 GB RAM, BlockManagerId(3, 192.168.33.12, 41115, None)
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.13:42153 with 15.8 GB RAM, BlockManagerId(2, 192.168.33.13, 42153, None)
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.15:39679 with 15.8 GB RAM, BlockManagerId(0, 192.168.33.15, 39679, None)
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.11:37100 with 15.8 GB RAM, BlockManagerId(5, 192.168.33.11, 37100, None)
18/09/28 10:03:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.33.10:50722) with ID 1
18/09/28 10:03:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.33.10:45203 with 15.8 GB RAM, BlockManagerId(1, 192.168.33.10, 45203, None)
18/09/28 10:03:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.33.14:44520 (size: 2.5 KB, free: 15.8 GB)
18/09/28 10:03:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.33.14:44520 (size: 27.9 KB, free: 15.8 GB)
18/09/28 10:04:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 11181 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:04:07 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 11167 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:04:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/09/28 10:04:07 INFO DAGScheduler: ShuffleMapStage 0 (flatMap at Partitioning.scala:52) finished in 11,206 s
18/09/28 10:04:07 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:04:07 INFO DAGScheduler: running: Set()
18/09/28 10:04:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/28 10:04:07 INFO DAGScheduler: failed: Set()
18/09/28 10:04:07 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78), which has no missing parents
18/09/28 10:04:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
18/09/28 10:04:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1838.0 B, free 365.9 MB)
18/09/28 10:04:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.10:37041 (size: 1838.0 B, free: 366.3 MB)
18/09/28 10:04:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
18/09/28 10:04:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at flatMap at Partitioning.scala:78) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:04:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
18/09/28 10:04:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:04:07 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:04:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.33.14:44520 (size: 1838.0 B, free: 15.8 GB)
18/09/28 10:04:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:42964
18/09/28 10:04:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 153 bytes
18/09/28 10:05:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 93516 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:05:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 99581 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:05:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/09/28 10:05:46 INFO DAGScheduler: ShuffleMapStage 1 (flatMap at Partitioning.scala:78) finished in 99,585 s
18/09/28 10:05:46 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:05:46 INFO DAGScheduler: running: Set()
18/09/28 10:05:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/28 10:05:46 INFO DAGScheduler: failed: Set()
18/09/28 10:05:46 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16), which has no missing parents
18/09/28 10:05:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.2 KB, free 365.9 MB)
18/09/28 10:05:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1883.0 B, free 365.9 MB)
18/09/28 10:05:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.10:37041 (size: 1883.0 B, free: 366.3 MB)
18/09/28 10:05:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
18/09/28 10:05:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at flatMap at CoresIdentification.scala:16) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:05:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
18/09/28 10:05:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:05:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:05:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.33.14:44520 (size: 1883.0 B, free: 15.8 GB)
18/09/28 10:05:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.14:42964
18/09/28 10:05:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 156 bytes
18/09/28 10:15:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 571673 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:15:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 587129 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:15:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/09/28 10:15:33 INFO DAGScheduler: ShuffleMapStage 2 (flatMap at CoresIdentification.scala:16) finished in 587,131 s
18/09/28 10:15:33 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:15:33 INFO DAGScheduler: running: Set()
18/09/28 10:15:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 3, ShuffleMapStage 4)
18/09/28 10:15:33 INFO DAGScheduler: failed: Set()
18/09/28 10:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at flatMap at CoresIdentification.scala:52), which has no missing parents
18/09/28 10:15:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.4 KB, free 365.9 MB)
18/09/28 10:15:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2007.0 B, free 365.9 MB)
18/09/28 10:15:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.10:37041 (size: 2007.0 B, free: 366.3 MB)
18/09/28 10:15:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
18/09/28 10:15:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at flatMap at CoresIdentification.scala:52) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:15:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
18/09/28 10:15:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:15:33 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:15:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.33.14:44520 (size: 2007.0 B, free: 15.8 GB)
18/09/28 10:15:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.33.14:42964
18/09/28 10:15:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 153 bytes
18/09/28 10:16:07 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 33595 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:16:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 33736 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:16:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/09/28 10:16:07 INFO DAGScheduler: ShuffleMapStage 3 (flatMap at CoresIdentification.scala:52) finished in 33,737 s
18/09/28 10:16:07 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:16:07 INFO DAGScheduler: running: Set()
18/09/28 10:16:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
18/09/28 10:16:07 INFO DAGScheduler: failed: Set()
18/09/28 10:16:07 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at flatMap at Clustring.scala:16), which has no missing parents
18/09/28 10:16:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.2 KB, free 365.9 MB)
18/09/28 10:16:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1865.0 B, free 365.9 MB)
18/09/28 10:16:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.10:37041 (size: 1865.0 B, free: 366.3 MB)
18/09/28 10:16:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
18/09/28 10:16:07 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at flatMap at Clustring.scala:16) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:16:07 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
18/09/28 10:16:07 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:16:07 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:16:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.33.14:44520 (size: 1865.0 B, free: 15.8 GB)
18/09/28 10:16:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.33.14:42964
18/09/28 10:16:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 153 bytes
18/09/28 10:17:10 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 63099 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:17:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 63743 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:17:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/09/28 10:17:11 INFO DAGScheduler: ShuffleMapStage 4 (flatMap at Clustring.scala:16) finished in 63,744 s
18/09/28 10:17:11 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:17:11 INFO DAGScheduler: running: Set()
18/09/28 10:17:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
18/09/28 10:17:11 INFO DAGScheduler: failed: Set()
18/09/28 10:17:11 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at map at GlobalMerging.scala:37), which has no missing parents
18/09/28 10:17:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.3 KB, free 365.9 MB)
18/09/28 10:17:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1941.0 B, free 365.9 MB)
18/09/28 10:17:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.10:37041 (size: 1941.0 B, free: 366.3 MB)
18/09/28 10:17:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
18/09/28 10:17:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at map at GlobalMerging.scala:37) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:17:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
18/09/28 10:17:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4614 bytes)
18/09/28 10:17:11 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4614 bytes)
18/09/28 10:17:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.33.14:44520 (size: 1941.0 B, free: 15.8 GB)
18/09/28 10:17:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.33.14:42964
18/09/28 10:17:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 153 bytes
18/09/28 10:17:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 1575 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:17:13 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 1597 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:17:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/09/28 10:17:13 INFO DAGScheduler: ShuffleMapStage 5 (map at GlobalMerging.scala:37) finished in 1,599 s
18/09/28 10:17:13 INFO DAGScheduler: looking for newly runnable stages
18/09/28 10:17:13 INFO DAGScheduler: running: Set()
18/09/28 10:17:13 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/09/28 10:17:13 INFO DAGScheduler: failed: Set()
18/09/28 10:17:13 INFO DAGScheduler: Submitting ResultStage 6 (ShuffledRDD[21] at reduceByKey at GlobalMerging.scala:51), which has no missing parents
18/09/28 10:17:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
18/09/28 10:17:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1689.0 B, free 365.9 MB)
18/09/28 10:17:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.10:37041 (size: 1689.0 B, free: 366.3 MB)
18/09/28 10:17:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
18/09/28 10:17:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[21] at reduceByKey at GlobalMerging.scala:51) (first 15 tasks are for partitions Vector(0))
18/09/28 10:17:13 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/09/28 10:17:13 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.33.14:44520 (size: 1689.0 B, free: 15.8 GB)
18/09/28 10:17:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.33.14:42964
18/09/28 10:17:13 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 156 bytes
18/09/28 10:17:14 INFO BlockManagerInfo: Added taskresult_12 in memory on 192.168.33.14:44520 (size: 3.1 MB, free: 15.8 GB)
18/09/28 10:17:14 INFO TransportClientFactory: Successfully created connection to /192.168.33.14:44520 after 2 ms (0 ms spent in bootstraps)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.10:37041 in memory (size: 1838.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.33.14:44520 in memory (size: 1838.0 B, free: 15.8 GB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.10:37041 in memory (size: 1883.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.33.14:44520 in memory (size: 1883.0 B, free: 15.8 GB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.10:37041 in memory (size: 1941.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.33.14:44520 in memory (size: 1941.0 B, free: 15.8 GB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.10:37041 in memory (size: 2007.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.33.14:44520 in memory (size: 2007.0 B, free: 15.8 GB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.10:37041 in memory (size: 1865.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.33.14:44520 in memory (size: 1865.0 B, free: 15.8 GB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.10:37041 in memory (size: 2.5 KB, free: 366.3 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.33.14:44520 in memory (size: 2.5 KB, free: 15.8 GB)
18/09/28 10:17:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 1659 ms on 192.168.33.14 (executor 4) (1/1)
18/09/28 10:17:14 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/09/28 10:17:14 INFO DAGScheduler: ResultStage 6 (foreach at GlobalMerging.scala:59) finished in 1,660 s
18/09/28 10:17:14 INFO BlockManagerInfo: Removed taskresult_12 on 192.168.33.14:44520 in memory (size: 3.1 MB, free: 15.8 GB)
18/09/28 10:17:14 INFO DAGScheduler: Job 0 finished: foreach at GlobalMerging.scala:59, took 798,953684 s
18/09/28 10:17:14 INFO SparkContext: Starting job: foreach at GlobalMerging.scala:59
18/09/28 10:17:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 153 bytes
18/09/28 10:17:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 156 bytes
18/09/28 10:17:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 153 bytes
18/09/28 10:17:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 153 bytes
18/09/28 10:17:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 153 bytes
18/09/28 10:17:14 INFO DAGScheduler: Got job 1 (foreach at GlobalMerging.scala:59) with 1 output partitions
18/09/28 10:17:14 INFO DAGScheduler: Final stage: ResultStage 13 (foreach at GlobalMerging.scala:59)
18/09/28 10:17:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/09/28 10:17:14 INFO DAGScheduler: Missing parents: List()
18/09/28 10:17:14 INFO DAGScheduler: Submitting ResultStage 13 (ShuffledRDD[21] at reduceByKey at GlobalMerging.scala:51), which has no missing parents
18/09/28 10:17:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
18/09/28 10:17:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1689.0 B, free 365.9 MB)
18/09/28 10:17:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.33.10:37041 (size: 1689.0 B, free: 366.3 MB)
18/09/28 10:17:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
18/09/28 10:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[21] at reduceByKey at GlobalMerging.scala:51) (first 15 tasks are for partitions Vector(1))
18/09/28 10:17:14 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/09/28 10:17:14 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.33.14:44520 (size: 1689.0 B, free: 15.8 GB)
18/09/28 10:17:15 INFO BlockManagerInfo: Added taskresult_13 in memory on 192.168.33.14:44520 (size: 4.1 MB, free: 15.8 GB)
18/09/28 10:17:16 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 1385 ms on 192.168.33.14 (executor 4) (1/1)
18/09/28 10:17:16 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/09/28 10:17:16 INFO DAGScheduler: ResultStage 13 (foreach at GlobalMerging.scala:59) finished in 1,386 s
18/09/28 10:17:16 INFO DAGScheduler: Job 1 finished: foreach at GlobalMerging.scala:59, took 1,403804 s
18/09/28 10:17:16 INFO BlockManagerInfo: Removed taskresult_13 on 192.168.33.14:44520 in memory (size: 4.1 MB, free: 15.8 GB)
18/09/28 10:17:17 INFO SparkContext: Starting job: count at Main.scala:143
18/09/28 10:17:17 INFO DAGScheduler: Got job 2 (count at Main.scala:143) with 2 output partitions
18/09/28 10:17:17 INFO DAGScheduler: Final stage: ResultStage 15 (count at Main.scala:143)
18/09/28 10:17:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/09/28 10:17:17 INFO DAGScheduler: Missing parents: List()
18/09/28 10:17:17 INFO DAGScheduler: Submitting ResultStage 15 (ShuffledRDD[3] at reduceByKey at Partitioning.scala:68), which has no missing parents
18/09/28 10:17:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 2.6 KB, free 365.9 MB)
18/09/28 10:17:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1589.0 B, free 365.9 MB)
18/09/28 10:17:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.33.10:37041 (size: 1589.0 B, free: 366.3 MB)
18/09/28 10:17:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
18/09/28 10:17:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[3] at reduceByKey at Partitioning.scala:68) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:17:17 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
18/09/28 10:17:17 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 14, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:17 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 15, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.33.14:44520 (size: 1589.0 B, free: 15.8 GB)
18/09/28 10:17:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.33.14:42964
18/09/28 10:17:36 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 14) in 18498 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:17:37 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 15) in 19455 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:17:37 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/09/28 10:17:37 INFO DAGScheduler: ResultStage 15 (count at Main.scala:143) finished in 19,457 s
18/09/28 10:17:37 INFO DAGScheduler: Job 2 finished: count at Main.scala:143, took 19,469304 s
18/09/28 10:17:37 INFO SparkContext: Starting job: count at Main.scala:144
18/09/28 10:17:37 INFO DAGScheduler: Got job 3 (count at Main.scala:144) with 2 output partitions
18/09/28 10:17:37 INFO DAGScheduler: Final stage: ResultStage 18 (count at Main.scala:144)
18/09/28 10:17:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/09/28 10:17:37 INFO DAGScheduler: Missing parents: List()
18/09/28 10:17:37 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRDD[9] at reduceByKey at Partitioning.scala:95), which has no missing parents
18/09/28 10:17:37 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 2.6 KB, free 365.9 MB)
18/09/28 10:17:37 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1591.0 B, free 365.9 MB)
18/09/28 10:17:37 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.10:37041 (size: 1591.0 B, free: 366.3 MB)
18/09/28 10:17:37 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
18/09/28 10:17:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (ShuffledRDD[9] at reduceByKey at Partitioning.scala:95) (first 15 tasks are for partitions Vector(0, 1))
18/09/28 10:17:37 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
18/09/28 10:17:37 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, 192.168.33.14, executor 4, partition 0, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:37 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 17, 192.168.33.14, executor 4, partition 1, NODE_LOCAL, 4625 bytes)
18/09/28 10:17:37 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.33.14:44520 (size: 1591.0 B, free: 15.8 GB)
18/09/28 10:17:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.33.14:42964
18/09/28 10:18:40 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 17) in 63219 ms on 192.168.33.14 (executor 4) (1/2)
18/09/28 10:18:41 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 64278 ms on 192.168.33.14 (executor 4) (2/2)
18/09/28 10:18:41 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/09/28 10:18:41 INFO DAGScheduler: ResultStage 18 (count at Main.scala:144) finished in 64,279 s
18/09/28 10:18:41 INFO DAGScheduler: Job 3 finished: count at Main.scala:144, took 64,290858 s
18/09/28 10:18:41 INFO SparkUI: Stopped Spark web UI at http://192.168.33.10:4040
18/09/28 10:18:41 INFO StandaloneSchedulerBackend: Shutting down all executors
18/09/28 10:18:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
18/09/28 10:18:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/09/28 10:18:41 INFO MemoryStore: MemoryStore cleared
18/09/28 10:18:41 INFO BlockManager: BlockManager stopped
18/09/28 10:18:41 INFO BlockManagerMaster: BlockManagerMaster stopped
18/09/28 10:18:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/09/28 10:18:41 INFO SparkContext: Successfully stopped SparkContext
18/09/28 10:18:41 INFO SparkContext: SparkContext already stopped.
18/09/28 10:18:41 INFO ShutdownHookManager: Shutdown hook called
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data5/store/spark-local/spark-5f56f86e-b44c-4931-8a89-05d0ddd6a8db
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data2/store/spark-local/spark-9a7e8612-be93-4406-adf1-15eae4f5f6ad
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data6/store/spark-local/spark-a53b1b4a-4844-4b57-b7f0-dca9639b3f22
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data1/store/spark-local/spark-e8e57c9d-9838-440b-8481-90071eff1d5f
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data0/store/spark-local/spark-8b38fae1-5d06-4bfb-8650-29e975bd2c6d
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data4/store/spark-local/spark-cf14c6b5-ba6d-4812-ad80-b4629de55e0e
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data3/store/spark-local/spark-e220636e-d98f-475c-91ea-f3804ff37693
18/09/28 10:18:41 INFO ShutdownHookManager: Deleting directory /data7/store/spark-local/spark-c81924d2-3cf9-48ff-a875-e20375f564e2
